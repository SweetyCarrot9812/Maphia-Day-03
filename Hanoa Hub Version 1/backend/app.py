"""
Hanoa RAG System - Streamlit Main Application
"""
import json
import uuid
from datetime import datetime
from pathlib import Path

import streamlit as st
import pandas as pd

from config import validate_config, JOBS_DIR, OBSIDIAN_VAULT_PATH
from rag_engine import rag_engine
from jobs_worker import jobs_worker
from analyzers.learning_analyzer import learning_analyzer
from generators.rag_generator import rag_generator
from analyzers.problem_analyzer import problem_analyzer
from models.problem_schema import ProblemData, create_sample_problems
from api_usage_tracker import api_tracker
from services.firebase_service import firebase_service

# Page configuration
st.set_page_config(
    page_title="Hanoa RAG System",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded"
)

def main():
    """Main Streamlit application"""

    # Initialize session state
    if 'initialized' not in st.session_state:
        try:
            validate_config()
            st.session_state.initialized = True
        except Exception as e:
            st.error(f"Configuration error: {e}")
            st.stop()

    # Header
    st.title("ğŸ“š Hanoa RAG System")
    st.markdown("ê°„í˜¸í•™ ë¬¸ì œ/ê°œë… ê´€ë¦¬ ë° RAG ê²€ìƒ‰ ì‹œìŠ¤í…œ")

    # Sidebar - System Status
    with st.sidebar:
        st.header("ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ")

        # RAG Stats
        try:
            stats = rag_engine.get_stats()
            st.metric("ì´ ë¬¸ì œ", stats['questions'])
            st.metric("ì´ ê°œë…", stats['concepts'])
            st.metric("ì „ì²´ ë°ì´í„°", stats['total'])
        except Exception as e:
            st.error(f"RAG ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")

        # Jobs Status
        st.subheader("ğŸ”„ Jobs ìƒíƒœ")
        try:
            jobs_status = jobs_worker.get_status()
            col1, col2 = st.columns(2)
            with col1:
                st.metric("ëŒ€ê¸°", jobs_status['pending'])
                st.metric("ì²˜ë¦¬ì¤‘", jobs_status['processing'])
            with col2:
                st.metric("ì™„ë£Œ", jobs_status['completed'])
                st.metric("ì‹¤íŒ¨", jobs_status['failed'])
        except Exception as e:
            st.error(f"Jobs ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")

        st.divider()

        # Obsidian Path
        st.subheader("ğŸ“ Obsidian Vault")
        st.text(OBSIDIAN_VAULT_PATH)

        if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨"):
            st.rerun()

    # Main content tabs - ë¬¸ì œ ê²€ìƒ‰ íƒ­ ì œê±° (6ê°œ â†’ 5ê°œ)
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ“ ë°ì´í„° ì…ë ¥", "ğŸ¤– ë¬¸ì œ ë¶„ì„", "ğŸ“š RAG ìƒì„±", "ğŸ“Š í•™ìŠµ ë¶„ì„", "âš™ï¸ ì‹œìŠ¤í…œ ê´€ë¦¬"])

    with tab1:
        data_input_tab()

    with tab2:
        problem_analysis_tab()

    with tab3:
        rag_generation_tab()

    with tab4:
        learning_analysis_tab()

    with tab5:
        system_management_tab()


def data_input_tab():
    """Data input tab for questions and concepts"""
    st.header("ğŸ“ ë°ì´í„° ì…ë ¥")

    input_type = st.selectbox("ì…ë ¥ íƒ€ì…", ["ë¬¸ì œ", "ê°œë…"])

    if input_type == "ë¬¸ì œ":
        question_input_form()
    else:
        concept_input_form()


def question_input_form():
    """Form for inputting nursing questions"""
    st.subheader("ğŸ“‹ ê°„í˜¸ ë¬¸ì œ ì…ë ¥")

    with st.form("question_form"):
        col1, col2 = st.columns([2, 1])

        with col1:
            question_text = st.text_area("ë¬¸ì œ", height=100, help="ê°„í˜¸ ë¬¸ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”")
            explanation = st.text_area("í•´ì„¤", height=80, help="ì •ë‹µ í•´ì„¤ì„ ì…ë ¥í•˜ì„¸ìš”")

        with col2:
            subject = st.selectbox("ê³¼ëª©", [
                "ê¸°ë³¸ê°„í˜¸í•™", "ì„±ì¸ê°„í˜¸í•™", "ì•„ë™ê°„í˜¸í•™", "ëª¨ì„±ê°„í˜¸í•™",
                "ì •ì‹ ê°„í˜¸í•™", "ì§€ì—­ì‚¬íšŒê°„í˜¸í•™", "ê°„í˜¸ê´€ë¦¬í•™"
            ])
            tags = st.text_input("íƒœê·¸", help="ì‰¼í‘œë¡œ êµ¬ë¶„ (ì„ íƒì‚¬í•­)")

        # Choices
        st.subheader("ì„ íƒì§€ (í•„ìˆ˜ 5ê°œ)")
        choices = []
        for i in range(1, 6):
            choice = st.text_input(f"ì„ íƒì§€ {i} *", key=f"choice_{i}", help="í•„ìˆ˜ ì…ë ¥")
            choices.append(choice)

        # Filter out empty choices for validation
        non_empty_choices = [c for c in choices if c.strip()]

        # Always show all 5 number options for answer selection
        st.subheader("ì •ë‹µ ì„ íƒ")
        answer_options = ["1ë²ˆ", "2ë²ˆ", "3ë²ˆ", "4ë²ˆ", "5ë²ˆ"]
        correct_answer_number = st.selectbox("ì •ë‹µ", answer_options)

        # Get the actual answer based on selection
        if correct_answer_number:
            answer_index = int(correct_answer_number.replace("ë²ˆ", "")) - 1
            if answer_index < len(choices) and choices[answer_index].strip():
                correct_answer = choices[answer_index]
            else:
                correct_answer = ""
        else:
            correct_answer = ""

        submitted = st.form_submit_button("ğŸ“¥ ë¬¸ì œ ì €ì¥")

        if submitted:
            # Validate all 5 choices are filled
            if question_text and len(non_empty_choices) == 5 and correct_answer and correct_answer != "ì„ íƒì§€ë¥¼ ë¨¼ì € ì…ë ¥í•˜ì„¸ìš”":
                try:
                    question_data = {
                        'id': str(uuid.uuid4()),
                        'questionText': question_text,
                        'choices': non_empty_choices,  # Use only non-empty choices
                        'correctAnswer': correct_answer,
                        'explanation': explanation,
                        'subject': subject,
                        'difficulty': 'ë¯¸ë¶„ë¥˜',  # AIê°€ ë‚˜ì¤‘ì— ë¶„ì„
                        'tags': [tag.strip() for tag in tags.split(',') if tag.strip()],
                        'createdBy': 'streamlit_user',
                        'createdAt': datetime.now().isoformat(),
                        'status': 'pending_analysis'  # ë¶„ì„ ëŒ€ê¸° ìƒíƒœ
                    }

                    # Save to Jobs/pending folder for AI processing
                    jobs_path = Path("Jobs/pending")
                    jobs_path.mkdir(parents=True, exist_ok=True)

                    job_file = jobs_path / f"problem_{question_data['id']}.json"
                    with open(job_file, 'w', encoding='utf-8') as f:
                        json.dump(question_data, f, ensure_ascii=False, indent=2)

                    st.success(f"[SUCCESS] ë¬¸ì œê°€ Jobs/pending í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.info("[INFO] AI ë¶„ì„ ëŒ€ê¸° ì¤‘... (ê°œë… ì¶”ì¶œ, íƒœê¹…, ë‚œì´ë„ í‰ê°€)")
                    st.info(f"[INFO] íŒŒì¼ ìœ„ì¹˜: {job_file}")

                    # Update session state to show status
                    if 'saved_problems' not in st.session_state:
                        st.session_state.saved_problems = []
                    st.session_state.saved_problems.append(question_data['id'])

                except Exception as e:
                    st.error(f"[ERROR] ì €ì¥ ì‹¤íŒ¨: {e}")
                    st.error(f"ìƒì„¸ ì˜¤ë¥˜: {str(e)}")
            else:
                missing = []
                if not question_text:
                    missing.append("ë¬¸ì œ")
                if len(non_empty_choices) != 5:
                    missing.append(f"ì„ íƒì§€ (í˜„ì¬ {len(non_empty_choices)}/5)")
                if not correct_answer or correct_answer == "ì„ íƒì§€ë¥¼ ë¨¼ì € ì…ë ¥í•˜ì„¸ìš”":
                    missing.append("ì •ë‹µ")
                st.warning(f"[WARNING] ë‹¤ìŒ í•„ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”: {', '.join(missing)}")


def concept_input_form():
    """Form for inputting nursing concepts"""
    st.subheader("[INFO] ê°„í˜¸ ê°œë… ì…ë ¥")

    with st.form("concept_form"):
        col1, col2 = st.columns([2, 1])

        with col1:
            title = st.text_input("ê°œë…ëª…", help="ê°œë…ì˜ ì œëª©ì„ ì…ë ¥í•˜ì„¸ìš”")
            description = st.text_area("ì„¤ëª…", height=150, help="ê°œë…ì— ëŒ€í•œ ìì„¸í•œ ì„¤ëª…")

        with col2:
            category = st.selectbox("ì¹´í…Œê³ ë¦¬", [
                "í•´ë¶€í•™", "ìƒë¦¬í•™", "ë³‘ë¦¬í•™", "ì•½ë¦¬í•™", "ë¯¸ìƒë¬¼í•™",
                "ê°„í˜¸ê¸°ìˆ ", "ê°„í˜¸ì´ë¡ ", "ìœ¤ë¦¬", "ë²•ê·œ"
            ])
            tags = st.text_input("íƒœê·¸", help="ì‰¼í‘œë¡œ êµ¬ë¶„")

        submitted = st.form_submit_button("ğŸ“¥ ê°œë… ì €ì¥")

        if submitted:
            if title and description:
                try:
                    concept_data = {
                        'id': str(uuid.uuid4()),
                        'title': title,
                        'description': description,
                        'category': category,
                        'tags': [tag.strip() for tag in tags.split(',') if tag.strip()],
                        'createdAt': datetime.now().isoformat()
                    }

                    # Add to RAG system
                    concept_id = rag_engine.add_concept(concept_data)
                    st.success(f"[SUCCESS] ê°œë…ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤! ID: {concept_id}")

                except Exception as e:
                    st.error(f"[ERROR] ì €ì¥ ì‹¤íŒ¨: {e}")
            else:
                st.warning("[WARNING] ì œëª©ê³¼ ì„¤ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”")


def rag_generation_tab():
    """RAG-based problem generation tab"""
    st.header("ğŸ“š RAG ë¬¸ì œ ìƒì„±")

    col1, col2 = st.columns([2, 1])

    with col1:
        concept = st.text_input("ì•½ì  ê°œë…", value="í™œë ¥ì§•í›„", help="ìƒì„±í•  ë¬¸ì œì˜ í•µì‹¬ ê°œë…ì„ ì…ë ¥í•˜ì„¸ìš”")
        subject = st.selectbox("ê³¼ëª©", ["ê¸°ë³¸ê°„í˜¸í•™", "ì„±ì¸ê°„í˜¸í•™", "ì•„ë™ê°„í˜¸í•™", "ëª¨ì„±ê°„í˜¸í•™", "ì •ì‹ ê°„í˜¸í•™"])

    with col2:
        difficulty = st.selectbox("ë‚œì´ë„", ["ìƒ", "ì¤‘", "í•˜"])
        count = st.number_input("ìƒì„±í•  ë¬¸ì œ ìˆ˜", min_value=1, max_value=5, value=2)

    if st.button("ğŸ¯ ë¬¸ì œ ìƒì„±"):
        if concept:
            with st.spinner(f"'{concept}' ê°œë… ë¬¸ì œ {count}ê°œ ìƒì„± ì¤‘..."):
                try:
                    generated_problems = rag_generator.generate_problems_for_weakness(
                        weak_concept=concept,
                        count=count,
                        difficulty=difficulty,
                        subject=subject
                    )

                    if generated_problems:
                        st.success(f"âœ… {len(generated_problems)}ê°œ ë¬¸ì œ ìƒì„± ì™„ë£Œ!")

                        for i, problem in enumerate(generated_problems):
                            with st.expander(f"ğŸ“ ìƒì„±ëœ ë¬¸ì œ {i+1}"):
                                st.write("**ë¬¸ì œ:**", problem['question_text'])
                                st.write("**ì„ íƒì§€:**")
                                for j, choice in enumerate(problem['choices']):
                                    marker = "âœ”ï¸" if choice == problem['correct_answer'] else "â—‹"
                                    st.write(f"{marker} {j+1}. {choice}")

                                if st.button(f"ğŸ’¾ ë¬¸ì œ {i+1} ì €ì¥", key=f"save_gen_{i}"):
                                    save_generated_problem(problem)
                    else:
                        st.warning("ë¬¸ì œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê°œë…ìœ¼ë¡œ ì‹œë„í•´ë³´ì„¸ìš”.")

                except Exception as e:
                    st.error(f"ë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        else:
            st.warning("ê°œë…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")


def learning_analysis_tab():
    """í•™ìŠµ ë¶„ì„ íƒ­"""
    st.header("ğŸ“Š í•™ìŠµ ë¶„ì„")

    st.info("ì‚¬ìš©ìì˜ ë¬¸ì œ í’€ì´ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì•½ì  ê°œë…ì„ ì‹ë³„í•˜ê³  í•™ìŠµ ì¶”ì²œì„ ì œê³µí•©ë‹ˆë‹¤")

    if st.button("ğŸ“ˆ ìƒ˜í”Œ ë°ì´í„°ë¡œ ë¶„ì„ ì‹¤í–‰"):
        with st.spinner("í•™ìŠµ ë°ì´í„° ë¶„ì„ ì¤‘..."):
            try:
                # Create sample problems with stats
                problems = create_sample_problems()

                # Add some realistic stats
                problems[0].update_stats(True, 35.0)
                problems[0].update_stats(False, 45.0)
                problems[0].update_stats(True, 30.0)

                problems[1].update_stats(False, 120.0)
                problems[1].update_stats(False, 90.0)
                problems[1].update_stats(True, 60.0)

                # Run analysis
                analysis = learning_analyzer.analyze_user_performance(problems, "demo_user")

                # Display results
                st.success("âœ… ë¶„ì„ ì™„ë£Œ!")

                # Basic stats
                st.subheader("ğŸ“¢ ê¸°ë³¸ í†µê³„")
                stats = analysis['basic_stats']

                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("ì „ì²´ ì •ë‹µë¥ ", f"{stats['overall_accuracy']:.1%}")
                with col2:
                    st.metric("ì‹œë„í•œ ë¬¸ì œ", f"{stats['attempted_problems']}")
                with col3:
                    st.metric("í‰ê·  ì‹œë„ íšŒìˆ˜", f"{stats['avg_attempts_per_problem']:.1f}")
                with col4:
                    st.metric("í‰ê·  ì†Œìš” ì‹œê°„", f"{stats['avg_time_per_problem']:.0f}ì´ˆ")

                # Weak concepts
                if analysis['weak_concepts']:
                    st.subheader("âš ï¸ ì•½ì  ê°œë…")
                    weak_df = pd.DataFrame(analysis['weak_concepts'])
                    st.dataframe(weak_df[['concept', 'weakness_score', 'accuracy', 'avg_time', 'priority']], use_container_width=True)

                # Recommendations
                if analysis['recommendations']:
                    st.subheader("ğŸ’¡ í•™ìŠµ ì¶”ì²œì‚¬í•­")
                    for rec in analysis['recommendations']:
                        priority_color = {
                            "high": "ğŸ”´",
                            "medium": "ğŸŸ¡",
                            "low": "ğŸŸ¢"
                        }.get(rec['priority'], "âšª")
                        st.write(f"{priority_color} **{rec['title']}**: {rec['description']}")

                # Summary
                st.subheader("ğŸ“ ë¶„ì„ ìš”ì•½")
                st.info(analysis['summary'])

            except Exception as e:
                st.error(f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}")

def rag_search_tab():
    """RAG search tab"""
    st.header("[SEARCH] RAG ê²€ìƒ‰")

    # Search form
    col1, col2 = st.columns([3, 1])
    with col1:
        query = st.text_input("ê²€ìƒ‰ì–´", placeholder="ê°„í˜¸ ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...")
    with col2:
        search_type = st.selectbox("ê²€ìƒ‰ ëŒ€ìƒ", ["ì „ì²´", "ë¬¸ì œë§Œ", "ê°œë…ë§Œ"])

    if st.button("[SEARCH] ê²€ìƒ‰") and query:
        with st.spinner("ê²€ìƒ‰ ì¤‘..."):
            try:
                # Map search type
                collection_map = {
                    "ì „ì²´": "both",
                    "ë¬¸ì œë§Œ": "questions",
                    "ê°œë…ë§Œ": "concepts"
                }

                # Perform search
                results = rag_engine.search(
                    query=query,
                    collection_type=collection_map[search_type],
                    n_results=5
                )

                # Display results
                st.subheader("ğŸ“‹ ê²€ìƒ‰ ê²°ê³¼")

                # Questions results
                if results['questions']:
                    st.subheader("ğŸ“ ë¬¸ì œ")
                    for i, result in enumerate(results['questions']):
                        with st.expander(f"ë¬¸ì œ {i+1} (ìœ ì‚¬ë„: {1-result['distance']:.3f})"):
                            st.write(result['content'])
                            st.json(result['metadata'])

                # Concepts results
                if results['concepts']:
                    st.subheader("[INFO] ê°œë…")
                    for i, result in enumerate(results['concepts']):
                        with st.expander(f"ê°œë… {i+1} (ìœ ì‚¬ë„: {1-result['distance']:.3f})"):
                            st.write(result['content'])
                            st.json(result['metadata'])

                # Generate AI answer
                if results['questions'] or results['concepts']:
                    st.subheader("ğŸ¤– AI ë‹µë³€")
                    with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                        context = results['questions'] + results['concepts']
                        answer = rag_engine.generate_answer(query, context[:3])
                        st.write(answer)

                if not results['questions'] and not results['concepts']:
                    st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì‹œë„í•´ë³´ì„¸ìš”.")

            except Exception as e:
                st.error(f"[ERROR] ê²€ìƒ‰ ì‹¤íŒ¨: {e}")


def clintest_ai_tab():
    """Advanced Clintest AI features tab - kept for legacy compatibility"""
    # This function is kept for backward compatibility but functionality moved to other tabs
    pass


def learning_analysis_section():
    """Learning analysis section"""
    st.subheader("ğŸ“Š í•™ìŠµ ì„±ê³¼ ë¶„ì„")

    # Sample data setup
    col1, col2 = st.columns([2, 1])

    with col1:
        st.info("[INFO] **ê¸°ëŠ¥ ì„¤ëª…**\n\nì´ ì„¹ì…˜ì—ì„œëŠ” ì‚¬ìš©ìì˜ ë¬¸ì œ í’€ì´ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬:\n- ì•½ì  ê°œë… ì‹ë³„\n- ê°œë…ë³„ ì„±ê³¼ ë¶„ì„\n- ë§ì¶¤í˜• í•™ìŠµ ì¶”ì²œì‚¬í•­ ì œê³µ")

    with col2:
        if st.button("ğŸ“ˆ ìƒ˜í”Œ ë°ì´í„°ë¡œ ë¶„ì„ ì‹¤í–‰"):
            st.session_state.run_analysis = True

    if st.session_state.get('run_analysis', False):
        with st.spinner("í•™ìŠµ ë°ì´í„° ë¶„ì„ ì¤‘..."):
            try:
                # Create sample problems with stats
                problems = create_sample_problems()

                # Add some realistic stats
                problems[0].update_stats(True, 35.0)
                problems[0].update_stats(False, 45.0)
                problems[0].update_stats(True, 30.0)

                problems[1].update_stats(False, 120.0)
                problems[1].update_stats(False, 90.0)
                problems[1].update_stats(True, 60.0)

                # Run analysis
                analysis = learning_analyzer.analyze_user_performance(problems, "demo_user")

                # Display results
                st.success("[SUCCESS] ë¶„ì„ ì™„ë£Œ!")

                # Basic stats
                st.subheader("ğŸ“ˆ ê¸°ë³¸ í†µê³„")
                stats = analysis['basic_stats']

                metric_col1, metric_col2, metric_col3, metric_col4 = st.columns(4)
                with metric_col1:
                    st.metric("ì „ì²´ ì •ë‹µë¥ ", f"{stats['overall_accuracy']:.1%}")
                with metric_col2:
                    st.metric("ì‹œë„í•œ ë¬¸ì œ", f"{stats['attempted_problems']}")
                with metric_col3:
                    st.metric("í‰ê·  ì‹œë„ íšŸìˆ˜", f"{stats['avg_attempts_per_problem']:.1f}")
                with metric_col4:
                    st.metric("í‰ê·  ì†Œìš” ì‹œê°„", f"{stats['avg_time_per_problem']:.0f}ì´ˆ")

                # Weak concepts
                if analysis['weak_concepts']:
                    st.subheader("[WARNING] ì•½ì  ê°œë…")
                    weak_df = pd.DataFrame(analysis['weak_concepts'])
                    st.dataframe(weak_df[['concept', 'weakness_score', 'accuracy', 'avg_time', 'priority']], use_container_width=True)

                # Concept analysis
                if analysis['concept_analysis']:
                    st.subheader("ğŸ“š ê°œë…ë³„ ì„±ê³¼")
                    concept_data = []
                    for concept, data in analysis['concept_analysis'].items():
                        concept_data.append({
                            'ê°œë…': concept,
                            'ì •ë‹µë¥ ': f"{data['accuracy']:.1%}",
                            'í‰ê·  ì‹œê°„': f"{data['avg_time']:.0f}ì´ˆ",
                            'ì‹œë„ íšŸìˆ˜': data['total_attempts'],
                            'ì•½ì  ì ìˆ˜': f"{data['weakness_score']:.2f}"
                        })
                    concept_df = pd.DataFrame(concept_data)
                    st.dataframe(concept_df, use_container_width=True)

                # Recommendations
                if analysis['recommendations']:
                    st.subheader("[INFO] í•™ìŠµ ì¶”ì²œì‚¬í•­")
                    for i, rec in enumerate(analysis['recommendations']):
                        priority_color = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}.get(rec['priority'], "âšª")
                        st.write(f"{priority_color} **{rec['title']}**: {rec['description']}")

                # Summary
                st.subheader("ğŸ“‹ ë¶„ì„ ìš”ì•½")
                st.info(analysis['summary'])

            except Exception as e:
                st.error(f"[ERROR] ë¶„ì„ ì‹¤íŒ¨: {e}")
                st.exception(e)


def problem_generation_section():
    """Problem generation section using RAG"""
    st.subheader("ğŸ¯ ì•½ì  ê¸°ë°˜ ë¬¸ì œ ìƒì„±")

    col1, col2 = st.columns([2, 1])

    with col1:
        concept = st.text_input("ì•½ì  ê°œë…", value="í™œë ¥ì§•í›„", help="ìƒì„±í•  ë¬¸ì œì˜ í•µì‹¬ ê°œë…ì„ ì…ë ¥í•˜ì„¸ìš”")
        subject = st.selectbox("ê³¼ëª©", ["ê¸°ë³¸ê°„í˜¸í•™", "ì„±ì¸ê°„í˜¸í•™", "ì•„ë™ê°„í˜¸í•™", "ëª¨ì„±ê°„í˜¸í•™", "ì •ì‹ ê°„í˜¸í•™"])

    with col2:
        difficulty = st.selectbox("ë‚œì´ë„", ["ìƒ", "ì¤‘", "í•˜"])
        count = st.number_input("ìƒì„±í•  ë¬¸ì œ ìˆ˜", min_value=1, max_value=5, value=2)

    if st.button("ğŸ¯ ë¬¸ì œ ìƒì„±"):
        if concept:
            with st.spinner(f"'{concept}' ê°œë… ë¬¸ì œ {count}ê°œ ìƒì„± ì¤‘..."):
                try:
                    generated_problems = rag_generator.generate_problems_for_weakness(
                        weak_concept=concept,
                        count=count,
                        difficulty=difficulty,
                        subject=subject
                    )

                    if generated_problems:
                        st.success(f"[SUCCESS] {len(generated_problems)}ê°œ ë¬¸ì œ ìƒì„± ì™„ë£Œ!")

                        for i, problem in enumerate(generated_problems):
                            with st.expander(f"ğŸ“ ìƒì„±ëœ ë¬¸ì œ {i+1}"):
                                st.write("**ë¬¸ì œ:**", problem['question_text'])
                                st.write("**ì„ íƒì§€:**")
                                for j, choice in enumerate(problem['choices']):
                                    marker = "[SUCCESS]" if choice == problem['correct_answer'] else "[O]"
                                    st.write(f"{marker} {j+1}. {choice}")

                                st.write("**ë©”íƒ€ë°ì´í„°:**")
                                metadata_col1, metadata_col2 = st.columns(2)
                                with metadata_col1:
                                    st.write(f"- ê³¼ëª©: {problem['subject']}")
                                    st.write(f"- ë‚œì´ë„: {problem['difficulty']}")
                                with metadata_col2:
                                    st.write(f"- ê°œë…: {', '.join(problem['concepts'])}")
                                    st.write(f"- í‚¤ì›Œë“œ: {', '.join(problem['keywords'])}")

                                # Option to save to Jobs folder
                                if st.button(f"ğŸ’¾ ë¬¸ì œ {i+1} ì €ì¥", key=f"save_prob_{i}"):
                                    save_generated_problem(problem)

                    else:
                        st.warning("[WARNING] ë¬¸ì œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê°œë…ìœ¼ë¡œ ì‹œë„í•´ë³´ì„¸ìš”.")

                except Exception as e:
                    st.error(f"[ERROR] ë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {e}")
                    st.exception(e)
        else:
            st.warning("[WARNING] ê°œë…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    # Study plan generation
    st.divider()
    st.subheader("ğŸ“š í•™ìŠµ ê³„íš ìƒì„±")

    if st.button("ğŸ“‹ ìƒ˜í”Œ ì•½ì  ê¸°ë°˜ í•™ìŠµ ê³„íš ìƒì„±"):
        with st.spinner("í•™ìŠµ ê³„íš ìƒì„± ì¤‘..."):
            try:
                # Sample weak concepts
                sample_weak_concepts = [
                    {'concept': 'í™œë ¥ì§•í›„', 'priority': 0.8, 'accuracy': 0.4, 'avg_time': 90},
                    {'concept': 'ê°ì—¼ê´€ë¦¬', 'priority': 0.6, 'accuracy': 0.5, 'avg_time': 75},
                    {'concept': 'íˆ¬ì•½ê´€ë¦¬', 'priority': 0.7, 'accuracy': 0.3, 'avg_time': 120}
                ]

                study_plan = rag_generator.generate_study_plan(sample_weak_concepts)

                st.success("[SUCCESS] í•™ìŠµ ê³„íš ìƒì„± ì™„ë£Œ!")

                # Display study plan
                plan_col1, plan_col2 = st.columns([2, 1])

                with plan_col1:
                    st.write("**ğŸ“Š í•™ìŠµ ê°œìš”**")
                    st.write(f"- ì´ ì•½ì  ê°œë…: {study_plan['total_concepts']}ê°œ")
                    st.write(f"- ì˜ˆìƒ í•™ìŠµ ì‹œê°„: {study_plan['estimated_time']}ë¶„")
                    st.write(f"- í•™ìŠµ ì„¸ì…˜: {len(study_plan['study_sessions'])}ê°œ")

                with plan_col2:
                    st.info("[INFO] ì²´ê³„ì ì¸ í•™ìŠµì„ ìœ„í•´ ìš°ì„ ìˆœìœ„ ìˆœìœ¼ë¡œ ì§„í–‰í•˜ì„¸ìš”.")

                # Study sessions
                if study_plan['study_sessions']:
                    st.write("**ğŸ“‹ í•™ìŠµ ì„¸ì…˜ ê³„íš**")
                    sessions_df = pd.DataFrame(study_plan['study_sessions'])
                    st.dataframe(sessions_df[['session_id', 'concept', 'problem_count', 'estimated_time', 'priority']], use_container_width=True)

                # Recommendations
                if study_plan['recommendations']:
                    st.write("**[INFO] í•™ìŠµ ì¶”ì²œì‚¬í•­**")
                    for rec in study_plan['recommendations']:
                        st.write(f"- {rec}")

            except Exception as e:
                st.error(f"[ERROR] í•™ìŠµ ê³„íš ìƒì„± ì‹¤íŒ¨: {e}")


def problem_processing_section():
    """Problem processing with AI analysis"""
    st.subheader("ğŸ“‹ ë¬¸ì œ AI ë¶„ì„ ì²˜ë¦¬")

    st.info("[INFO] **ê¸°ëŠ¥ ì„¤ëª…**\n\nì´ ì„¹ì…˜ì—ì„œëŠ” ì›ë¬¸ ë¬¸ì œë¥¼ AIë¡œ ë¶„ì„í•˜ì—¬:\n- í•µì‹¬ ê°œë… ì¶”ì¶œ\n- ê´€ë ¨ í‚¤ì›Œë“œ ì‹ë³„\n- ë‚œì´ë„ ë¶„ë¥˜\n- í’ˆì§ˆ ê²€ì¦")

    # Input form for problem analysis
    with st.form("problem_analysis_form"):
        col1, col2 = st.columns([3, 1])

        with col1:
            question_text = st.text_area(
                "ë¬¸ì œ í…ìŠ¤íŠ¸",
                height=100,
                placeholder="ê°„í˜¸í•™ ë¬¸ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”...",
                help="í•´ì„ì´ í•„ìš”í•œ ì›ë¬¸ ë¬¸ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”"
            )

        with col2:
            subject = st.selectbox("ê³¼ëª©", [
                "ê¸°ë³¸ê°„í˜¸í•™", "ì„±ì¸ê°„í˜¸í•™", "ì•„ë™ê°„í˜¸í•™", "ëª¨ì„±ê°„í˜¸í•™",
                "ì •ì‹ ê°„í˜¸í•™", "ì§€ì—­ì‚¬íšŒê°„í˜¸í•™", "ê°„í˜¸ê´€ë¦¬í•™"
            ])

        # Choices input
        st.subheader("ì„ íƒì§€")
        choices = []
        choice_cols = st.columns(2)

        for i in range(4):
            with choice_cols[i % 2]:
                choice = st.text_input(f"ì„ íƒì§€ {i+1}", key=f"analysis_choice_{i}")
                if choice:
                    choices.append(choice)

        correct_answer = st.selectbox("ì •ë‹µ", choices if choices else ["ì„ íƒì§€ë¥¼ ë¨¼ì € ì…ë ¥í•˜ì„¸ìš”"])
        user_tags = st.text_input("ì¶”ê°€ íƒœê·¸", help="ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ì…ë ¥")

        submitted = st.form_submit_button("[SEARCH] AI ë¶„ì„ ì‹¤í–‰")

        if submitted:
            if question_text and choices and correct_answer:
                with st.spinner("AI ë¶„ì„ ì¤‘..."):
                    try:
                        # Process problem with AI analyzer
                        tags_list = [tag.strip() for tag in user_tags.split(',') if tag.strip()] if user_tags else []

                        processed_problem = problem_analyzer.process_problem(
                            question_text=question_text,
                            choices=choices,
                            correct_answer=correct_answer,
                            explanation="",  # No auto-explanation as requested
                            subject=subject,
                            user_tags=tags_list
                        )

                        st.success("[SUCCESS] AI ë¶„ì„ ì™„ë£Œ!")

                        # Display analysis results
                        result_col1, result_col2 = st.columns(2)

                        with result_col1:
                            st.subheader("[AI] AI ë¶„ì„ ê²°ê³¼")
                            st.write(f"**ì¶”ì¶œëœ ê°œë…:** {', '.join(processed_problem['concepts'])}")
                            st.write(f"**í‚¤ì›Œë“œ:** {', '.join(processed_problem['keywords'])}")
                            st.write(f"**AI ë‚œì´ë„ ë¶„ë¥˜:** {processed_problem['difficulty']}")
                            st.write(f"**ì‹ ë¢°ë„ ì ìˆ˜:** {processed_problem['confidence_score']:.2f}")
                            st.write(f"**ê²€ì¦ ë°©ë²•:** {processed_problem['verified_by']}")

                        with result_col2:
                            st.subheader("ğŸ“Š í’ˆì§ˆ ê²€ì¦")
                            validation = processed_problem['validation']
                            status_color = {"valid": "ğŸŸ¢", "warning": "ğŸŸ¡", "invalid": "ğŸ”´"}.get(validation['status'], "âšª")
                            st.write(f"**ìƒíƒœ:** {status_color} {validation['status']}")
                            st.write(f"**í’ˆì§ˆ ì ìˆ˜:** {validation['score']:.2f}")

                            if validation['issues']:
                                st.write("**ë°œê²¬ëœ ë¬¸ì œ:**")
                                for issue in validation['issues']:
                                    st.write(f"- [WARNING] {issue}")

                        # Full processed data
                        with st.expander("ğŸ“„ ì „ì²´ ì²˜ë¦¬ ê²°ê³¼ (JSON)"):
                            st.json(processed_problem)

                        # Option to save
                        if st.button("ğŸ’¾ ë¶„ì„ ê²°ê³¼ ì €ì¥"):
                            save_processed_problem(processed_problem)

                    except Exception as e:
                        st.error(f"[ERROR] AI ë¶„ì„ ì‹¤íŒ¨: {e}")
                        st.exception(e)
            else:
                st.warning("[WARNING] í•„ìˆ˜ í•„ë“œë¥¼ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")


def ai_testing_section():
    """AI system testing section"""
    st.subheader("ğŸ§ª AI ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")

    test_col1, test_col2 = st.columns(2)

    with test_col1:
        st.write("**[SEARCH] ê³„ì¸µì  ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸**")
        if st.button("Test Hierarchical Analyzer"):
            with st.spinner("Testing hierarchical analyzer..."):
                try:
                    from analyzers.hierarchical_analyzer import hierarchical_analyzer

                    test_question = "í˜ˆì•• ì¸¡ì • ì‹œ ê°€ì¥ ì¤‘ìš”í•œ ì£¼ì˜ì‚¬í•­ì€?"
                    test_choices = ["í™˜ìë¥¼ í¸ì•ˆí•˜ê²Œ ì•‰íŒë‹¤", "ì¸¡ì • ì „ 30ë¶„ê°„ ê¸ˆì—°í•œë‹¤"]
                    test_answer = "ì¸¡ì • ì „ 30ë¶„ê°„ ê¸ˆì—°í•œë‹¤"

                    result = hierarchical_analyzer.analyze_problem(test_question, test_choices, test_answer)
                    st.success("[SUCCESS] í…ŒìŠ¤íŠ¸ ì„±ê³µ")
                    st.json(result)

                except Exception as e:
                    st.error(f"[ERROR] í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

    with test_col2:
        st.write("**ğŸ“Š í•™ìŠµ ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸**")
        if st.button("Test Learning Analyzer"):
            with st.spinner("Testing learning analyzer..."):
                try:
                    problems = create_sample_problems()
                    problems[0].update_stats(True, 45.0)
                    problems[1].update_stats(False, 90.0)

                    analysis = learning_analyzer.analyze_user_performance(problems)
                    st.success("[SUCCESS] í…ŒìŠ¤íŠ¸ ì„±ê³µ")
                    st.write(f"ë¶„ì„ëœ ë¬¸ì œ ìˆ˜: {len(problems)}")
                    st.write(f"ì•½ì  ê°œë… ìˆ˜: {len(analysis['weak_concepts'])}")

                except Exception as e:
                    st.error(f"[ERROR] í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

    # System integration test
    st.divider()
    st.write("**ğŸ”— í†µí•© ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸**")
    if st.button("ğŸš€ ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"):
        with st.spinner("ì „ì²´ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì¤‘..."):
            try:
                # Test complete pipeline
                st.write("[1] ìƒ˜í”Œ ë¬¸ì œ ìƒì„±...")
                problems = create_sample_problems()

                st.write("[2] í•™ìŠµ ë°ì´í„° ë¶„ì„...")
                analysis = learning_analyzer.analyze_user_performance(problems)

                st.write("[3] ì•½ì  ê¸°ë°˜ ë¬¸ì œ ìƒì„±...")
                if analysis['weak_concepts']:
                    weak_concept = analysis['weak_concepts'][0]['concept']
                    generated = rag_generator.generate_problems_for_weakness(weak_concept, count=1)

                    st.success("[SUCCESS] ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
                    st.write(f"- ë¶„ì„ëœ ë¬¸ì œ: {len(problems)}ê°œ")
                    st.write(f"- ì‹ë³„ëœ ì•½ì : {len(analysis['weak_concepts'])}ê°œ")
                    st.write(f"- ìƒì„±ëœ ë¬¸ì œ: {len(generated)}ê°œ")
                else:
                    st.warning("[WARNING] ì•½ì  ê°œë…ì´ ì‹ë³„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

            except Exception as e:
                st.error(f"[ERROR] í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                st.exception(e)


def save_generated_problem(problem_data):
    """Save generated problem to Jobs folder"""
    try:
        # Save to pending folder for processing
        filename = f"generated_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{problem_data['id'][:8]}.json"
        file_path = JOBS_DIR / "pending" / filename

        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(problem_data, f, ensure_ascii=False, indent=2)

        st.success(f"[SUCCESS] ë¬¸ì œê°€ Jobs í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filename}")

    except Exception as e:
        st.error(f"[ERROR] ì €ì¥ ì‹¤íŒ¨: {e}")


def save_processed_problem(problem_data):
    """Save processed problem to Jobs folder"""
    try:
        # Save to completed folder
        filename = f"processed_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{problem_data['id'][:8]}.json"
        file_path = JOBS_DIR / "completed" / filename

        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(problem_data, f, ensure_ascii=False, indent=2)

        st.success(f"[SUCCESS] ì²˜ë¦¬ëœ ë¬¸ì œê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filename}")

    except Exception as e:
        st.error(f"[ERROR] ì €ì¥ ì‹¤íŒ¨: {e}")


def jobs_management_tab():
    """Jobs management tab"""
    st.header("[FILES] Jobs ê´€ë¦¬")

    # Current status
    try:
        status = jobs_worker.get_status()

        # Status cards
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ëŒ€ê¸° ì¤‘", status['pending'])
        with col2:
            st.metric("ì²˜ë¦¬ ì¤‘", status['processing'])
        with col3:
            st.metric("ì™„ë£Œ", status['completed'])
        with col4:
            st.metric("ì‹¤íŒ¨", status['failed'])

        # Job folders content
        st.subheader("ğŸ“‚ í´ë” ë‚´ìš©")

        folder_tab1, folder_tab2, folder_tab3, folder_tab4 = st.tabs(["ëŒ€ê¸°", "ì²˜ë¦¬ì¤‘", "ì™„ë£Œ", "ì‹¤íŒ¨"])

        with folder_tab1:
            show_folder_contents(JOBS_DIR / "pending")

        with folder_tab2:
            show_folder_contents(JOBS_DIR / "processing")

        with folder_tab3:
            show_folder_contents(JOBS_DIR / "completed")

        with folder_tab4:
            show_folder_contents(JOBS_DIR / "failed")

    except Exception as e:
        st.error(f"[ERROR] Jobs ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")

    # Test job creation
    st.subheader("ğŸ§ª í…ŒìŠ¤íŠ¸ ì‘ì—… ìƒì„±")
    if st.button("ğŸ“¥ í…ŒìŠ¤íŠ¸ ë¬¸ì œ ìƒì„±"):
        create_test_job()


def show_folder_contents(folder_path: Path):
    """Show contents of a jobs folder"""
    try:
        json_files = list(folder_path.glob("*.json"))

        if json_files:
            st.write(f"ğŸ“„ {len(json_files)}ê°œ íŒŒì¼")

            for file_path in json_files[:10]:  # Show max 10 files
                with st.expander(f"ğŸ“„ {file_path.name}"):
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            data = json.load(f)
                        st.json(data)
                    except Exception as e:
                        st.error(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")

            if len(json_files) > 10:
                st.info(f"... ë° {len(json_files) - 10}ê°œ ì¶”ê°€ íŒŒì¼")
        else:
            st.info("í´ë”ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")

    except Exception as e:
        st.error(f"í´ë” ì½ê¸° ì‹¤íŒ¨: {e}")


def create_test_job():
    """Create a test job for testing"""
    try:
        test_data = {
            'id': str(uuid.uuid4()),
            'questionText': 'í˜ˆì•• ì¸¡ì • ì‹œ ì£¼ì˜ì‚¬í•­ìœ¼ë¡œ ì˜³ì€ ê²ƒì€?',
            'choices': [
                'ì¸¡ì • ì „ 30ë¶„ê°„ ê¸ˆì—°í•œë‹¤',
                'íŒ”ê¿ˆì¹˜ë³´ë‹¤ ë†’ê²Œ ì»¤í”„ë¥¼ ìœ„ì¹˜ì‹œí‚¨ë‹¤',
                'ì»¤í”„ í¬ê¸°ëŠ” ìƒê´€ì—†ë‹¤',
                'ì¸¡ì • ì§ì „ì— ìš´ë™ì„ í•œë‹¤'
            ],
            'correctAnswer': 'ì¸¡ì • ì „ 30ë¶„ê°„ ê¸ˆì—°í•œë‹¤',
            'explanation': 'í˜ˆì•• ì¸¡ì • ì „ 30ë¶„ê°„ì€ í¡ì—°, ì¹´í˜ì¸ ì„­ì·¨, ìš´ë™ì„ í”¼í•´ì•¼ ì •í™•í•œ ì¸¡ì •ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.',
            'subject': 'ê¸°ë³¸ê°„í˜¸í•™',
            'difficulty': 'ë³´í†µ',
            'tags': ['í˜ˆì••', 'ì¸¡ì •', 'ê¸°ë³¸ê°„í˜¸'],
            'createdBy': 'test_user',
            'createdAt': datetime.now().isoformat()
        }

        # Save to pending folder
        test_file = JOBS_DIR / "pending" / f"test_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(test_file, 'w', encoding='utf-8') as f:
            json.dump(test_data, f, ensure_ascii=False, indent=2)

        st.success(f"[SUCCESS] í…ŒìŠ¤íŠ¸ ì‘ì—… ìƒì„±ë¨: {test_file.name}")

    except Exception as e:
        st.error(f"[ERROR] í…ŒìŠ¤íŠ¸ ì‘ì—… ìƒì„± ì‹¤íŒ¨: {e}")


def problem_analysis_tab():
    """Problem analysis tab with AI model information"""
    st.header("ğŸ¤– ë¬¸ì œ ë¶„ì„")
    st.info("Jobs í´ë”ì˜ ë¬¸ì œë¥¼ AIê°€ ë¶„ì„í•©ë‹ˆë‹¤")

    # Session state ì´ˆê¸°í™” - í•¨ìˆ˜ ì‹œì‘ ë¶€ë¶„ì—ì„œ í•­ìƒ ì‹¤í–‰
    if 'analysis_result' not in st.session_state:
        st.session_state.analysis_result = None
    if 'analyzed_problem_id' not in st.session_state:
        st.session_state.analyzed_problem_id = None
    if 'analyzed_problem_data' not in st.session_state:
        st.session_state.analyzed_problem_data = None

    # AI ëª¨ë¸ ì •ë³´ í‘œì‹œ (Updated: 2025.09.22)
    with st.expander("ğŸ¤– ì‚¬ìš©ë˜ëŠ” AI ëª¨ë¸ ì •ë³´ (ìµœì‹  2025.09.22)", expanded=False):
        st.markdown("""
        ### ğŸš€ ê³„ì¸µì  AI ë¶„ì„ ì‹œìŠ¤í…œ (2025 ìµœì‹  ëª¨ë¸)

        **1ë‹¨ê³„: GPT-5 Mini** `gpt-5-mini`
        - ë¹ ë¥´ê³  ë¹„ìš© íš¨ìœ¨ì ì¸ ì´ˆê¸° ë¶„ì„
        - ì…ë ¥: $0.65/1M í† í° | ì¶œë ¥: $5.00/1M í† í°
        - ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°: 200,000 í† í°
        - ì‹ ë¢°ë„ 70% ì´ìƒ ì‹œ ìµœì¢… ê²°ê³¼ë¡œ ì±„íƒ

        **2ë‹¨ê³„: GPT-5** `gpt-5`
        - ì‹ ë¢°ë„ 70% ë¯¸ë§Œì¼ ë•Œë§Œ ì‹¤í–‰
        - ì…ë ¥: $1.25/1M í† í° | ì¶œë ¥: $10.00/1M í† í°
        - ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°: 400,000 í† í°
        - ë³µì¡í•œ ë¬¸ì œì— ëŒ€í•œ ì‹¬ì¸µ ë¶„ì„

        **ê²½ëŸ‰ íƒœìŠ¤í¬: GPT-5 Nano** `gpt-5-nano`
        - ë‹¨ìˆœ ì‘ì—… ë° ëŒ€ëŸ‰ ì²˜ë¦¬ìš©
        - ì…ë ¥: $0.40/1M í† í° | ì¶œë ¥: $2.50/1M í† í°
        - ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°: 100,000 í† í°

        **ë³´ì¡° ëª¨ë¸: Gemini 2.5 Flash** `gemini-2.5-flash`
        - ì‹¤ì‹œê°„ ì²˜ë¦¬, ì €ê°€í˜•
        - ì…ë ¥: $0.10/1M í† í° | ì¶œë ¥: $0.40/1M í† í°
        - í† í° ìœˆë„ìš°: 128,000 í† í°

        **ì„ë² ë”©: Gemini text-embedding-004**
        - ìµœì‹  Gemini ì„ë² ë”© ëª¨ë¸
        - ChromaDB ì €ì¥ìš© ì‹œë§¨í‹± ê²€ìƒ‰ ìµœì í™”
        - ë¹„ìš©: $0.10/1M í† í°

        **ğŸ’° ë¹„ìš© ì ˆê° íš¨ê³¼**
        - í‰ê·  65% ë¹„ìš© ì ˆê° (ê³„ì¸µì  ì ‘ê·¼ë²•)
        - 80% ì´ìƒì˜ ë¬¸ì œëŠ” GPT-5 Minië¡œ ì¶©ë¶„
        - ë‹¨ìˆœ ì‘ì—…ì€ GPT-5 Nanoë¡œ ì²˜ë¦¬
        """)

    # Jobs í´ë” ìŠ¤ìº”
    jobs_path = Path("Jobs/pending")
    if jobs_path.exists():
        job_files = list(jobs_path.glob("*.json"))
        if job_files:
            st.success(f"ğŸ“ ë¶„ì„ ëŒ€ê¸° ì¤‘ì¸ ë¬¸ì œ: {len(job_files)}ê°œ")

            selected_file = st.selectbox(
                "ë¶„ì„í•  ë¬¸ì œ ì„ íƒ",
                options=job_files,
                format_func=lambda x: x.name
            )

            if st.button("ğŸ”¬ AI ë¶„ì„ ì‹œì‘"):
                with st.spinner("ë¬¸ì œ ë¶„ì„ ì¤‘..."):
                    # íŒŒì¼ ì½ê¸°
                    with open(selected_file, 'r', encoding='utf-8') as f:
                        problem_data = json.load(f)

                    # AI ë¶„ì„
                    try:
                        from analyzers.hierarchical_analyzer import HierarchicalAnalyzer
                        analyzer = HierarchicalAnalyzer()

                        # ë¬¸ì œ ID ìƒì„± (íŒŒì¼ëª… ê¸°ë°˜)
                        import uuid
                        problem_id = selected_file.stem if selected_file else str(uuid.uuid4())

                        # ë¶„ì„ ìƒíƒœ í‘œì‹œ
                        status_placeholder = st.empty()
                        status_placeholder.info("ğŸ”„ GPT-5 Minië¡œ 1ì°¨ ë¶„ì„ ì¤‘...")

                        analysis = analyzer.analyze_problem(
                            problem_data['questionText'],
                            problem_data.get('choices', []),
                            problem_data.get('correctAnswer', '')
                        )

                        # ì‚¬ìš©ëœ ëª¨ë¸ í‘œì‹œ (confidence_score ì‚¬ìš©)
                        confidence_score = analysis.get('confidence_score', 0.0)
                        if confidence_score >= 0.7:
                            status_placeholder.success(f"âœ… GPT-5 Minië¡œ ë¶„ì„ ì™„ë£Œ (ì‹ ë¢°ë„: {confidence_score:.1%})")
                        else:
                            status_placeholder.warning(f"âš ï¸ GPT-5ë¡œ 2ì°¨ ì •ë°€ ë¶„ì„ ì‹¤í–‰ (ì‹ ë¢°ë„: {confidence_score:.1%})")

                        # ë¶„ì„ ê²°ê³¼ í‘œì‹œ (ê°œì„ ëœ UI)
                        with st.expander("ğŸ“Š ìƒì„¸ ë¶„ì„ ê²°ê³¼", expanded=True):
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("ë‚œì´ë„", analysis.get('difficulty', 'ë³´í†µ'))
                                verified_by = analysis.get('verified_by', 'gpt5_mini')
                                display_model = 'GPT-5 Mini' if verified_by == 'gpt5_mini' else 'GPT-5'
                                st.metric("ì‚¬ìš© ëª¨ë¸", display_model)
                            with col2:
                                st.metric("ì‹ ë¢°ë„", f"{confidence_score:.1%}")
                                process_time = datetime.now().timestamp() - datetime.fromisoformat(analysis.get('processed_at', datetime.now().isoformat())).timestamp()
                                st.metric("ë¶„ì„ ì‹œê°„", f"{abs(process_time):.2f}ì´ˆ")
                            with col3:
                                st.metric("ê°œë… ìˆ˜", len(analysis.get('concepts', [])))
                                # Updated pricing based on 2025.09.22 rates
                                if verified_by == 'gpt5_mini':
                                    cost_estimate = 0.00065  # $0.65 per 1M tokens
                                elif verified_by == 'gpt5_enhanced':
                                    cost_estimate = 0.00125  # $1.25 per 1M tokens
                                else:
                                    cost_estimate = 0.0004  # GPT-5 Nano
                                st.metric("ì˜ˆìƒ ë¹„ìš©", f"${cost_estimate:.5f}")

                            # í•µì‹¬ ê°œë… í‘œì‹œ
                            st.markdown("### ğŸ” í•µì‹¬ ê°œë…")
                            concepts = analysis.get('concepts', [])
                            if concepts:
                                for i, concept in enumerate(concepts, 1):
                                    st.markdown(f"**{i}.** {concept}")
                            else:
                                st.info("ì¶”ì¶œëœ ê°œë…ì´ ì—†ìŠµë‹ˆë‹¤.")

                            # í‚¤ì›Œë“œ í‘œì‹œ
                            st.markdown("### ğŸ”‘ í‚¤ì›Œë“œ")
                            keywords = analysis.get('keywords', [])
                            if keywords:
                                # í‚¤ì›Œë“œë¥¼ ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ë¡œ í‘œì‹œ
                                st.write(", ".join(keywords))
                            else:
                                st.info("ì¶”ì¶œëœ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")


                        # ë¶„ì„ ê²°ê³¼ë¥¼ session stateì— ì €ì¥
                        st.session_state.analysis_result = analysis
                        st.session_state.analyzed_problem_id = problem_id
                        st.session_state.analyzed_problem_data = problem_data

                        # ë¶„ì„ ì™„ë£Œëœ íŒŒì¼ ì´ë™
                        completed_path = Path("Jobs/completed")
                        completed_path.mkdir(exist_ok=True)

                        # ë¶„ì„ ê²°ê³¼ ì¶”ê°€
                        problem_data['analysis'] = analysis

                        # ì €ì¥
                        new_file = completed_path / selected_file.name
                        with open(new_file, 'w', encoding='utf-8') as f:
                            json.dump(problem_data, f, ensure_ascii=False, indent=2)

                        # ì›ë³¸ ì‚­ì œ
                        selected_file.unlink()

                        st.success("âœ… ë¶„ì„ ì™„ë£Œ! ChromaDBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.rerun()

                    except Exception as e:
                        st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        else:
            st.warning("ë¶„ì„í•  ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë¬¸ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        st.warning("Jobs í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë¬¸ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    # Session State ê¸°ë°˜ Firebase ì—…ë¡œë“œ ì„¹ì…˜ (AI ë¶„ì„ ì™„ë£Œ í›„ í‘œì‹œ)
    if hasattr(st.session_state, 'analysis_result') and st.session_state.analysis_result is not None:
        st.divider()
        st.subheader("â˜ï¸ ë¶„ì„ ì™„ë£Œ - ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™")

        # ì„¸ì…˜ì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        problem_id = st.session_state.analyzed_problem_id
        problem_data = st.session_state.analyzed_problem_data
        analysis = st.session_state.analysis_result

        # ë¶„ì„ ê²°ê³¼ ìš”ì•½ í‘œì‹œ
        with st.expander("ğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½", expanded=False):
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ë¬¸ì œ ID", problem_id[:8] + "...")
                st.metric("ë‚œì´ë„", analysis.get('difficulty', 'ë³´í†µ'))
            with col2:
                st.metric("ì‹ ë¢°ë„", f"{analysis.get('confidence_score', 0):.1%}")
                st.metric("ì‚¬ìš© ëª¨ë¸", 'GPT-5 Mini' if analysis.get('verified_by') == 'gpt5_mini' else 'GPT-5')
            with col3:
                st.metric("ê°œë… ìˆ˜", len(analysis.get('concepts', [])))
                st.metric("í‚¤ì›Œë“œ ìˆ˜", len(analysis.get('keywords', [])))

        # ì—…ë¡œë“œ ë²„íŠ¼ ì„¹ì…˜
        st.info("ë¶„ì„ ê²°ê³¼ë¥¼ ChromaDBì™€ Firebaseì— ì €ì¥í•˜ì—¬ Clintest ì•±ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        col1, col2 = st.columns(2)

        with col1:
            if st.button("ğŸ’¾ ChromaDBì— ì €ì¥", key="session_chroma_save", type="primary"):
                with st.spinner("ChromaDBì— ì €ì¥ ì¤‘..."):
                    try:
                        question_id = rag_engine.add_question({
                            'id': problem_id,
                            'questionText': problem_data['questionText'],
                            'choices': problem_data.get('choices', []),
                            'correctAnswer': problem_data.get('correctAnswer', ''),
                            'subject': 'ê°„í˜¸í•™',
                            'difficulty': analysis.get('difficulty', 'ë³´í†µ'),
                            'tags': analysis.get('keywords', []),
                            'createdBy': 'hierarchical_analyzer'
                        })
                        st.success(f"âœ… ChromaDB ì €ì¥ ì™„ë£Œ! (ID: {question_id})")
                        st.info("ğŸ“Š ì„ë² ë”© ë²¡í„°ì™€ ë©”íƒ€ë°ì´í„°ê°€ ChromaDBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤")
                    except Exception as e:
                        import traceback
                        error_details = traceback.format_exc()
                        print(f"[ERROR] ChromaDB ì €ì¥ ì‹¤íŒ¨: {error_details}")

                        st.error(f"âŒ ChromaDB ì €ì¥ ì‹¤íŒ¨: {str(e)}")
                        with st.expander("ìƒì„¸ ì˜¤ë¥˜ ì •ë³´", expanded=False):
                            st.code(error_details)

        with col2:
            if st.button("ğŸ“¤ Firebaseì— ì—…ë¡œë“œ", key="session_firebase_upload", type="primary"):
                with st.spinner("Firebaseì— ì—…ë¡œë“œ ì¤‘..."):
                    try:
                        # ë””ë²„ê·¸ ë¡œê·¸
                        print(f"[DEBUG] Session Firebase ì—…ë¡œë“œ ì‹œë„: {problem_id}")

                        # Firebase ì—…ë¡œë“œìš© ë°ì´í„° ì¤€ë¹„ (ë¶„ì„ ê²°ê³¼ í¬í•¨)
                        upload_data = {
                            **problem_data,
                            'id': problem_id,
                            'analysis': analysis,
                            'subject': 'ê°„í˜¸í•™',
                            'difficulty': analysis.get('difficulty', 'ë³´í†µ'),
                            'concepts': analysis.get('concepts', []),
                            'keywords': analysis.get('keywords', []),
                            'processed_by': analysis.get('verified_by', 'gpt5_mini'),
                            'confidence_score': analysis.get('confidence_score', 0.0)
                        }

                        print(f"[DEBUG] ì—…ë¡œë“œ ë°ì´í„° í‚¤: {list(upload_data.keys())}")
                        print(f"[DEBUG] Firebase ì´ˆê¸°í™” ìƒíƒœ: {firebase_service.initialized}")

                        # Firebase ì„œë¹„ìŠ¤ ì—…ë¡œë“œ
                        upload_result = firebase_service.upload_problem(upload_data)
                        print(f"[DEBUG] ì—…ë¡œë“œ ê²°ê³¼: {upload_result}")

                        if upload_result:
                            st.success("ğŸ‰ Firebase ì—…ë¡œë“œ ì„±ê³µ!")
                            st.info(f"ğŸ“‹ ë¬¸ì œ ID: {problem_id}")
                            st.info(f"ğŸ“± Clintest ì•±ì—ì„œ í™•ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤")
                            st.balloons()

                            # ì—…ë¡œë“œ ì„±ê³µ í›„ ì„¸ì…˜ í´ë¦¬ì–´ (ì„ íƒì‚¬í•­)
                            # st.session_state.analysis_result = None
                            # st.session_state.analyzed_problem_id = None
                            # st.session_state.analyzed_problem_data = None
                        else:
                            st.warning("âš ï¸ Firebaseê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                            st.caption("Firebase ì„œë¹„ìŠ¤ ê³„ì • í‚¤ íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                    except Exception as e:
                        import traceback
                        error_details = traceback.format_exc()
                        print(f"[ERROR] Session Firebase ì—…ë¡œë“œ ì‹¤íŒ¨: {error_details}")

                        st.error(f"âŒ Firebase ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
                        st.error(f"ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")

                        with st.expander("ìƒì„¸ ì˜¤ë¥˜ ì •ë³´", expanded=False):
                            st.code(error_details)

                        st.caption("ì½˜ì†”ì—ì„œ ìƒì„¸ ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

        # ì„¸ì…˜ í´ë¦¬ì–´ ë²„íŠ¼ (ì„ íƒì‚¬í•­)
        if st.button("ğŸ—‘ï¸ ë¶„ì„ ê²°ê³¼ ì§€ìš°ê¸°", key="clear_analysis"):
            st.session_state.analysis_result = None
            st.session_state.analyzed_problem_id = None
            st.session_state.analyzed_problem_data = None
            st.success("ë¶„ì„ ê²°ê³¼ê°€ ì§€ì›Œì¡ŒìŠµë‹ˆë‹¤.")
            st.rerun()

    # ì™„ë£Œëœ ë¶„ì„ ê²°ê³¼ ë³´ê¸° ì„¹ì…˜
    st.divider()
    st.subheader("ğŸ“‹ ì™„ë£Œëœ ë¶„ì„ ê²°ê³¼ ë³´ê¸°")

    completed_path = Path("Jobs/completed")
    if completed_path.exists():
        completed_files = list(completed_path.glob("*.json"))

        if completed_files:
            st.info(f"âœ… ì´ {len(completed_files)}ê°œì˜ ë¶„ì„ ì™„ë£Œëœ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")

            # íŒŒì¼ ì„ íƒ
            selected_completed = st.selectbox(
                "ë¶„ì„ ê²°ê³¼ë¥¼ ë³¼ ë¬¸ì œ ì„ íƒ:",
                completed_files,
                format_func=lambda x: f"{x.name} ({x.stat().st_size/1024:.1f}KB)",
                key="completed_file_selector"
            )

            col1, col2 = st.columns([3, 1])
            with col1:
                if st.button("ğŸ“Š ë¶„ì„ ê²°ê³¼ ë³´ê¸°", key="view_completed_analysis"):
                    try:
                        with open(selected_completed, 'r', encoding='utf-8') as f:
                            completed_data = json.load(f)

                        # ë¬¸ì œ ì •ë³´ í‘œì‹œ
                        with st.expander("ğŸ“ ë¬¸ì œ ì •ë³´", expanded=True):
                            st.write("**ë¬¸ì œ:**", completed_data.get('questionText', 'N/A'))
                            if 'choices' in completed_data:
                                st.write("**ì„ íƒì§€:**")
                                for i, choice in enumerate(completed_data['choices'], 1):
                                    st.write(f"{i}. {choice}")
                            st.write("**ì •ë‹µ:**", completed_data.get('correctAnswer', 'N/A'))

                        # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                        if 'analysis' in completed_data:
                            analysis = completed_data['analysis']

                            with st.expander("ğŸ” ìƒì„¸ ë¶„ì„ ê²°ê³¼", expanded=True):
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    st.metric("ë‚œì´ë„", analysis.get('difficulty', 'ë³´í†µ'))
                                    verified_by = analysis.get('verified_by', 'unknown')
                                    model_display = 'GPT-5 Mini' if verified_by == 'gpt5_mini' else 'GPT-5'
                                    st.metric("ì‚¬ìš© ëª¨ë¸", model_display)
                                with col2:
                                    st.metric("ì‹ ë¢°ë„", f"{analysis.get('confidence_score', 0):.1%}")
                                    st.metric("ê°œë… ìˆ˜", len(analysis.get('concepts', [])))
                                with col3:
                                    st.metric("í‚¤ì›Œë“œ ìˆ˜", len(analysis.get('keywords', [])))
                                    processed_at = analysis.get('processed_at', 'N/A')
                                    if processed_at != 'N/A':
                                        st.metric("ë¶„ì„ ì‹œê°", processed_at[:10])

                                st.markdown("### í•µì‹¬ ê°œë…")
                                concepts = analysis.get('concepts', [])
                                if concepts:
                                    for i, concept in enumerate(concepts, 1):
                                        st.markdown(f"**{i}.** {concept}")
                                else:
                                    st.info("ì¶”ì¶œëœ ê°œë…ì´ ì—†ìŠµë‹ˆë‹¤.")

                                st.markdown("### í‚¤ì›Œë“œ")
                                keywords = analysis.get('keywords', [])
                                if keywords:
                                    # í‚¤ì›Œë“œë¥¼ ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ë¡œ í‘œì‹œ
                                    st.write(", ".join(keywords))
                                else:
                                    st.info("ì¶”ì¶œëœ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")

                                if 'error' in analysis:
                                    st.error(f"ë¶„ì„ ì˜¤ë¥˜: {analysis['error']}")

                            # ì„ë² ë”©/Firebase ì„¹ì…˜
                            with st.expander("â˜ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™", expanded=False):
                                col1, col2 = st.columns(2)
                                with col1:
                                    if st.button("ğŸ’¾ ChromaDBì— ì €ì¥", key=f"save_completed_to_chroma_{selected_completed.name}"):
                                        with st.spinner("ChromaDBì— ì €ì¥ ì¤‘..."):
                                            try:
                                                from rag_engine import rag_engine
                                                question_id = rag_engine.add_question({
                                                    'id': str(uuid.uuid4()),
                                                    'questionText': completed_data['questionText'],
                                                    'choices': completed_data.get('choices', []),
                                                    'correctAnswer': completed_data.get('correctAnswer', ''),
                                                    'subject': 'ê°„í˜¸í•™',
                                                    'difficulty': analysis.get('difficulty', 'ë³´í†µ'),
                                                    'tags': analysis.get('keywords', []),
                                                    'createdBy': 'hierarchical_analyzer'
                                                })
                                                st.success(f"âœ… ChromaDB ì €ì¥ ì™„ë£Œ! (ID: {question_id})")
                                            except Exception as e:
                                                st.error(f"âŒ ChromaDB ì €ì¥ ì‹¤íŒ¨: {str(e)}")

                                with col2:
                                    if st.button("ğŸ“¤ Firebase ì—…ë¡œë“œ", key=f"firebase_upload_completed_{selected_completed.stem}"):
                                        with st.spinner("Firebaseì— ì—…ë¡œë“œ ì¤‘..."):
                                            try:
                                                # Firebase ì„œë¹„ìŠ¤ ì—…ë¡œë“œ
                                                upload_result = firebase_service.upload_problem(completed_data)

                                                if upload_result:
                                                    st.success("ğŸ‰ Firebase ì—…ë¡œë“œ ì„±ê³µ!")
                                                    st.info(f"ğŸ“‹ ë¬¸ì œ ID: {completed_data.get('id', 'unknown')}")
                                                    st.info(f"ğŸ“± Clintest ì•±ì—ì„œ í™•ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤")
                                                    st.balloons()
                                                else:
                                                    st.warning("âš ï¸ Firebaseê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                                                    st.caption("Firebase ì„œë¹„ìŠ¤ ê³„ì • í‚¤ íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                                            except Exception as e:
                                                st.error(f"âŒ Firebase ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
                                                st.caption("ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                        else:
                            st.warning("ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

                    except Exception as e:
                        st.error(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")

            with col2:
                if st.button("ğŸ—‘ï¸ ì„ íƒí•œ ê²°ê³¼ ì‚­ì œ", key="delete_completed"):
                    try:
                        selected_completed.unlink()
                        st.success("âœ… ì‚­ì œ ì™„ë£Œ!")
                        st.rerun()
                    except Exception as e:
                        st.error(f"ì‚­ì œ ì‹¤íŒ¨: {str(e)}")

        else:
            st.info("ì•„ì§ ì™„ë£Œëœ ë¶„ì„ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("Jobs/completed í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")


def settings_tab():
    """Settings tab"""
    st.header("âš™ï¸ ì„¤ì •")

    st.subheader("ğŸ”§ ì‹œìŠ¤í…œ ì„¤ì •")

    col1, col2 = st.columns(2)

    with col1:
        st.info("ğŸ“ Jobs ë””ë ‰í† ë¦¬")
        st.code(str(JOBS_DIR))

        st.info("ğŸ“ Obsidian Vault")
        st.code(OBSIDIAN_VAULT_PATH)

    with col2:
        st.info("[AI] AI ëª¨ë¸")
        st.code("Embedding: Gemini embedding-001")
        st.code("Chat: GPT-4o-mini")

    # Environment check
    st.subheader("[SEARCH] í™˜ê²½ í™•ì¸")

    try:
        validate_config()
        st.success("[SUCCESS] ëª¨ë“  ì„¤ì •ì´ ì˜¬ë°”ë¦…ë‹ˆë‹¤")
    except Exception as e:
        st.error(f"[ERROR] ì„¤ì • ì˜¤ë¥˜: {e}")

    # Database cleanup
    st.subheader("ğŸ§¹ ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬")
    if st.button("[CLEANUP] ì˜¤ë˜ëœ ì‘ì—… ì •ë¦¬ (7ì¼ ì´ìƒ)"):
        try:
            jobs_worker.handler.cleanup_old_jobs(days=7)
            st.success("[SUCCESS] ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            st.error(f"[ERROR] ì •ë¦¬ ì‹¤íŒ¨: {e}")


def system_management_tab():
    """System management and settings tab"""
    st.header("âš™ï¸ ì‹œìŠ¤í…œ ê´€ë¦¬")

    # Create subtabs for system management
    mgmt_tab1, mgmt_tab2, mgmt_tab3, mgmt_tab4 = st.tabs(["ğŸ“ Jobs ê´€ë¦¬", "ğŸ”§ ì‹œìŠ¤í…œ ì„¤ì •", "ğŸ’° API ì‚¬ìš©ëŸ‰", "ğŸ§ª í…ŒìŠ¤íŠ¸"])

    with mgmt_tab1:
        st.subheader("ğŸ“ Jobs í´ë” ê´€ë¦¬")

        # Current status
        try:
            status = jobs_worker.get_status()

            # Status cards
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ëŒ€ê¸° ì¤‘", status['pending'])
            with col2:
                st.metric("ì²˜ë¦¬ ì¤‘", status['processing'])
            with col3:
                st.metric("ì™„ë£Œ", status['completed'])
            with col4:
                st.metric("ì‹¤íŒ¨", status['failed'])

            # Job folders content
            st.subheader("ğŸ“‚ í´ë” ë‚´ìš©")

            folder_tab1, folder_tab2, folder_tab3, folder_tab4 = st.tabs(["ëŒ€ê¸°", "ì²˜ë¦¬ì¤‘", "ì™„ë£Œ", "ì‹¤íŒ¨"])

            with folder_tab1:
                show_folder_contents(JOBS_DIR / "pending")

            with folder_tab2:
                show_folder_contents(JOBS_DIR / "processing")

            with folder_tab3:
                show_folder_contents(JOBS_DIR / "completed")

            with folder_tab4:
                show_folder_contents(JOBS_DIR / "failed")

        except Exception as e:
            st.error(f"Jobs ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")

        # Test job creation
        st.subheader("ğŸ§ª í…ŒìŠ¤íŠ¸ ì‘ì—… ìƒì„±")
        if st.button("ğŸ“¥ í…ŒìŠ¤íŠ¸ ë¬¸ì œ ìƒì„±"):
            create_test_job()

    with mgmt_tab2:
        st.subheader("ğŸ”§ ì‹œìŠ¤í…œ ì„¤ì •")

        col1, col2 = st.columns(2)

        with col1:
            st.info("ğŸ“ Jobs ë””ë ‰í„°ë¦¬")
            st.code(str(JOBS_DIR))

            st.info("ğŸ“ Obsidian Vault")
            st.code(OBSIDIAN_VAULT_PATH)

        with col2:
            st.info("ğŸ¤– AI ëª¨ë¸ (2025.09.22)")
            st.code("Embedding: text-embedding-004 (Gemini)")
            st.code("Primary: GPT-5 Mini")
            st.code("Advanced: GPT-5")
            st.code("Fast: GPT-5 Nano")

        # Environment check
        st.subheader("ğŸ” í™˜ê²½ í™•ì¸")

        try:
            validate_config()
            st.success("âœ… ëª¨ë“  ì„¤ì •ì´ ì˜¬ë°”ë¦…ë‹ˆë‹¤")
        except Exception as e:
            st.error(f"ì„¤ì • ì˜¤ë¥˜: {e}")

        # Database cleanup
        st.subheader("ğŸ§½ ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬")
        if st.button("ğŸ§½ ì˜¤ë˜ëœ ì‘ì—… ì •ë¦¬ (7ì¼ ì´ìƒ)"):
            try:
                jobs_worker.handler.cleanup_old_jobs(days=7)
                st.success("âœ… ì •ë¦¬ ì™„ë£Œ")
            except Exception as e:
                st.error(f"ì •ë¦¬ ì‹¤íŒ¨: {e}")

    with mgmt_tab3:
        st.subheader("ğŸ’° API ì‚¬ìš©ëŸ‰ ì¶”ì ")

        # API Usage Overview
        st.info("ğŸ“ˆ OpenAI ë° Gemini API ì‚¬ìš©ëŸ‰ ë° ë¹„ìš© ì¶”ì ")

        # Time period selection
        period = st.selectbox("ê¸°ê°„ ì„ íƒ", ["ì˜¤ëŠ˜", "ì´ë²ˆ ì£¼", "ì´ë²ˆ ë‹¬", "ì „ì²´"])

        # Get usage data based on period
        if period == "ì˜¤ëŠ˜":
            usage_data = api_tracker.get_daily_usage()
            st.subheader(f"ğŸ“… ì˜¤ëŠ˜ ì‚¬ìš©ëŸ‰ ({datetime.now().strftime('%Y-%m-%d')})")
        elif period == "ì´ë²ˆ ì£¼":
            usage_data = api_tracker.get_weekly_usage()
            st.subheader("ğŸ“… ìµœê·¼ 7ì¼ ì‚¬ìš©ëŸ‰")
        elif period == "ì´ë²ˆ ë‹¬":
            now = datetime.now()
            usage_data = api_tracker.get_monthly_usage(now.year, now.month)
            st.subheader(f"ğŸ“… {now.year}ë…„ {now.month}ì›” ì‚¬ìš©ëŸ‰")
        else:  # ì „ì²´
            usage_data = api_tracker.get_total_usage()
            st.subheader("ğŸ“… ì „ì²´ ëˆ„ì  ì‚¬ìš©ëŸ‰")

        # Display metrics
        col1, col2, col3 = st.columns(3)

        if period == "ì „ì²´":
            with col1:
                st.metric("ì´ í† í° ì‚¬ìš©ëŸ‰", f"{usage_data.get('tokens', 0):,}")
            with col2:
                st.metric("ì´ ë¹„ìš©", f"${usage_data.get('cost', 0):.4f}")
            with col3:
                st.metric("ì›í™” í™˜ì‚° (1,300ì›/$)", f"â‚©{usage_data.get('cost', 0) * 1300:.0f}")
        else:
            with col1:
                st.metric("ì´ í† í° ì‚¬ìš©ëŸ‰", f"{usage_data.get('total_tokens', 0):,}")
            with col2:
                st.metric("ì´ ë¹„ìš©", f"${usage_data.get('total_cost', 0):.4f}")
            with col3:
                st.metric("ì›í™” í™˜ì‚° (1,300ì›/$)", f"â‚©{usage_data.get('total_cost', 0) * 1300:.0f}")

        # Model-wise breakdown
        if period != "ì „ì²´" and usage_data.get('by_model'):
            st.subheader("ğŸ¤– ëª¨ë¸ë³„ ì‚¬ìš©ëŸ‰")

            model_data = []
            for model, stats in usage_data['by_model'].items():
                model_data.append({
                    'ëª¨ë¸': model,
                    'ì…ë ¥ í† í°': f"{stats['input_tokens']:,}",
                    'ì¶œë ¥ í† í°': f"{stats['output_tokens']:,}",
                    'ìš”ì²­ íšŸìˆ˜': stats['requests'],
                    'ë¹„ìš© (USD)': f"${stats['cost']:.4f}",
                    'ë¹„ìš© (KRW)': f"â‚©{stats['cost'] * 1300:.0f}"
                })

            if model_data:
                model_df = pd.DataFrame(model_data)
                st.dataframe(model_df, use_container_width=True)

        # Daily breakdown for weekly/monthly view
        if period in ["ì´ë²ˆ ì£¼", "ì´ë²ˆ ë‹¬"] and usage_data.get('by_day'):
            st.subheader("ğŸ“Š ì¼ë³„ ì‚¬ìš©ëŸ‰ ì¶”ì´")

            daily_data = []
            for date, models in sorted(usage_data['by_day'].items()):
                day_tokens = sum(m['input_tokens'] + m['output_tokens'] for m in models.values())
                day_cost = sum(m['cost'] for m in models.values())
                daily_data.append({
                    'ë‚ ì§œ': date,
                    'ì´ í† í°': f"{day_tokens:,}",
                    'ë¹„ìš© (USD)': f"${day_cost:.4f}",
                    'ë¹„ìš© (KRW)': f"â‚©{day_cost * 1300:.0f}"
                })

            if daily_data:
                daily_df = pd.DataFrame(daily_data)
                st.dataframe(daily_df, use_container_width=True)

        # Model pricing reference
        with st.expander("ğŸ“‹ ëª¨ë¸ë³„ ê°€ê²©í‘œ (2025.09.22 ê¸°ì¤€)"):
            pricing_data = [
                {'ëª¨ë¸': 'GPT-5', 'ì…ë ¥ (1M tokens)': '$1.25', 'ì¶œë ¥ (1M tokens)': '$10.00'},
                {'ëª¨ë¸': 'GPT-5 Mini', 'ì…ë ¥ (1M tokens)': '$0.65', 'ì¶œë ¥ (1M tokens)': '$5.00'},
                {'ëª¨ë¸': 'GPT-5 Nano', 'ì…ë ¥ (1M tokens)': '$0.40', 'ì¶œë ¥ (1M tokens)': '$2.50'},
                {'ëª¨ë¸': 'Gemini 2.5 Pro', 'ì…ë ¥ (1M tokens)': '$1.25', 'ì¶œë ¥ (1M tokens)': '$10.00'},
                {'ëª¨ë¸': 'Gemini 2.5 Flash', 'ì…ë ¥ (1M tokens)': '$0.10', 'ì¶œë ¥ (1M tokens)': '$0.40'},
                {'ëª¨ë¸': 'Text Embedding 004', 'ì…ë ¥ (1M tokens)': '$0.10', 'ì¶œë ¥': 'N/A'},
            ]
            pricing_df = pd.DataFrame(pricing_data)
            st.dataframe(pricing_df, use_container_width=True)

    with mgmt_tab4:
        st.subheader("ğŸ§ª AI ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")

        test_col1, test_col2 = st.columns(2)

        with test_col1:
            st.write("**ğŸ” ê³„ì¸µì  ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸**")
            if st.button("Test Hierarchical Analyzer"):
                with st.spinner("Testing hierarchical analyzer..."):
                    try:
                        from analyzers.hierarchical_analyzer import HierarchicalAnalyzer
                        analyzer = HierarchicalAnalyzer()

                        test_question = "í˜ˆì•• ì¸¡ì • ì‹œ ê°€ì¥ ì¤‘ìš”í•œ ì£¼ì˜ì‚¬í•­ì€?"
                        test_choices = ["í™˜ìë¥¼ í¸ì•ˆí•˜ê²Œ ì•‰íŒë‹¤", "ì¸¡ì • ì „ 30ë¶„ê°„ ê¸ˆì—°í•œë‹¤"]
                        test_answer = "ì¸¡ì • ì „ 30ë¶„ê°„ ê¸ˆì—°í•œë‹¤"

                        result = analyzer.analyze_problem(test_question, test_choices, test_answer)
                        st.success("âœ… í…ŒìŠ¤íŠ¸ ì„±ê³µ")
                        st.json(result)

                    except Exception as e:
                        st.error(f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

        with test_col2:
            st.write("**ğŸ“Š í•™ìŠµ ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸**")
            if st.button("Test Learning Analyzer"):
                with st.spinner("Testing learning analyzer..."):
                    try:
                        problems = create_sample_problems()
                        problems[0].update_stats(True, 45.0)
                        problems[1].update_stats(False, 90.0)

                        analysis = learning_analyzer.analyze_user_performance(problems)
                        st.success("âœ… í…ŒìŠ¤íŠ¸ ì„±ê³µ")
                        st.write(f"ë¶„ì„ëœ ë¬¸ì œ ìˆ˜: {len(problems)}")
                        st.write(f"ì•½ì  ê°œë… ìˆ˜: {len(analysis['weak_concepts'])}")

                    except Exception as e:
                        st.error(f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")


if __name__ == "__main__":
    main()