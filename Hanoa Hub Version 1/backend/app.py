"""
Hanoa RAG System - Streamlit Main Application (Simplified Version)
"""
import json
import os
import uuid
from datetime import datetime
from pathlib import Path

import streamlit as st
import pandas as pd

# Streamlit í­ ê´€ë ¨ íŒŒë¼ë¯¸í„° ë³€ê²½(ì„ì‹œ í˜¸í™˜ ì…”íŒ€): use_container_width -> width
try:
    def _map_ucw(kwargs):
        if 'use_container_width' in kwargs:
            val = kwargs.pop('use_container_width')
            kwargs.setdefault('width', 'stretch' if val else 'content')
        return kwargs

    if hasattr(st, 'button'):
        _orig_button = st.button
        def _button_shim(*args, **kwargs):
            return _orig_button(*args, **_map_ucw(kwargs))
        st.button = _button_shim

    if hasattr(st, 'form_submit_button'):
        _orig_form_submit_button = st.form_submit_button
        def _form_submit_button_shim(*args, **kwargs):
            return _orig_form_submit_button(*args, **_map_ucw(kwargs))
        st.form_submit_button = _form_submit_button_shim

    if hasattr(st, 'image'):
        _orig_image = st.image
        def _image_shim(*args, **kwargs):
            return _orig_image(*args, **_map_ucw(kwargs))
        st.image = _image_shim

    if hasattr(st, 'dataframe'):
        _orig_dataframe = st.dataframe
        def _dataframe_shim(*args, **kwargs):
            return _orig_dataframe(*args, **_map_ucw(kwargs))
        st.dataframe = _dataframe_shim
except Exception:
    # ì…”íŒ€ ì ìš© ì‹¤íŒ¨ì‹œ ë¬´ì‹œ(ê¸°ë³¸ ë™ì‘ ìœ ì§€)
    pass

from config import (
    validate_config, JOBS_DIR, OBSIDIAN_VAULT_PATH,
    DOMAIN_COLLECTIONS, DEFAULT_DOMAIN, ENABLE_CROSS_DOMAIN_SEARCH,
    ENABLE_IMAGE_VECTORS, GEMINI_API_KEY, OPENAI_API_KEY,
    MAX_IMAGE_SIZE_MB
)
from rag_engine import rag_engine
from rag_engine_multi_domain import multi_domain_rag_engine
from jobs_worker import jobs_worker
from analyzers.problem_analyzer import problem_analyzer
from models.problem_schema import ProblemData, create_sample_problems
from api_usage_tracker import api_tracker
from services.firebase_service import firebase_service
from services.gemini_service import gemini_service
from analyzers.image_hierarchical_analyzer import ImageHierarchicalAnalyzer
# ê¸°ë³¸ ì¤‘ë³µ ì œê±° ì—”ì§„ ë¨¼ì € ì„í¬íŠ¸
from deduplication_engine import deduplication_engine

# ê³ ê¸‰ ê¸°ëŠ¥ë“¤ì„ ì•ˆì „í•˜ê²Œ ì„í¬íŠ¸
try:
    import deduplication_engine as _de
    # ê³ ê¸‰ ê¸°ëŠ¥ ê°€ìš©ì„± í™•ì¸
    use_advanced_deduplication = getattr(_de, 'use_advanced_deduplication', None)
    ADVANCED_DEDUP_AVAILABLE = bool(getattr(_de, 'ADVANCED_DEDUP_AVAILABLE', False)) and callable(use_advanced_deduplication)
    if not ADVANCED_DEDUP_AVAILABLE:
        # Fallback: ê³ ê¸‰ ì—”ì§„ ë¯¸ê°€ìš© ì‹œ ê¸°ë³¸ ì—”ì§„ìœ¼ë¡œ ìœ„ì„
        def use_advanced_deduplication(documents, domain='medical', **kwargs):
            return deduplication_engine.deduplicate(
                documents,
                domain=domain,
                return_pairs=kwargs.get('return_pairs', True)
            )
        ADVANCED_DEDUP_AVAILABLE = False
    pass  # ê³ ê¸‰ ì¤‘ë³µ ì œê±° ê¸°ëŠ¥ ì„í¬íŠ¸ ì„±ê³µ
except ImportError as e:
    pass  # ê³ ê¸‰ ì¤‘ë³µ ì œê±° ì„í¬íŠ¸ ì‹¤íŒ¨, ê¸°ë³¸ ì—”ì§„ ì‚¬ìš©
    # í´ë°± í•¨ìˆ˜ ì •ì˜
    def use_advanced_deduplication(documents, domain='medical', **kwargs):
        return deduplication_engine.deduplicate(
            documents,
            domain=domain,
            return_pairs=kwargs.get('return_pairs', True)
        )
    ADVANCED_DEDUP_AVAILABLE = False
from PIL import Image
import io
import os
import hashlib
import base64
import asyncio
from ai_batch_generator import BatchQuestionGenerator
from question_types import QuestionType

# ìœ ì‚¬ í•­ëª© ì—†ìŒ ì‚¬ìœ ë¥¼ ê°„ê²°íˆ í‘œê¸°í•˜ëŠ” í—¬í¼
def show_no_similarity_reason(total_docs: int, n_requested: int) -> None:
    try:
        if total_docs <= 0:
            st.caption(f"ì‚¬ìœ : ìµœì´ˆ ì €ì¥ (ì»¬ë ‰ì…˜ {total_docs}ê±´, ìš”ì²­ n={n_requested})")
        elif total_docs < n_requested:
            st.caption(f"ì‚¬ìœ : ë¹„êµ ëŒ€ìƒ ë¶€ì¡± (ì»¬ë ‰ì…˜ {total_docs}ê±´, ìš”ì²­ n={n_requested})")
        else:
            st.caption(f"ì‚¬ìœ : ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ (ì»¬ë ‰ì…˜ {total_docs}ê±´, ìš”ì²­ n={n_requested})")
    except Exception:
        pass

# Page configuration
st.set_page_config(
    page_title="Hanoa RAG System",
    page_icon="[BOOK]",
    layout="wide",
    initial_sidebar_state="expanded"
)

def main():
    """Main Streamlit application"""

    # Initialize session state
    if 'initialized' not in st.session_state:
        try:
            validate_config()
            st.session_state.initialized = True
        except Exception as e:
            st.error(f"Configuration error: {e}")
            st.stop()

    # Header
    st.title("[BOOK] Hanoa RAG System")
    st.markdown("ê°„í˜¸í•™/ì˜í•™ ë¬¸ì œ ë° ê°œë… ê´€ë¦¬ ì‹œìŠ¤í…œ")

    # Sidebar - System Status
    with st.sidebar:
        st.header("[STATUS] ì‹œìŠ¤í…œ ìƒíƒœ")

        # RAG Stats - Calculate from all collections
        try:
            from rag_engine_multi_domain import multi_domain_rag_engine

            # Count from all ChromaDB collections
            total_questions = 0
            total_concepts = 0

            collections_to_check = [
                ("nursing_questions", "question"),
                ("medical_problems", "question"),
                ("nursing_concepts", "concept"),
                ("medical_concepts", "concept"),
                ("fitness_knowledge", "concept"),
                ("lingumo_knowledge", "concept")
            ]

            for coll_name, coll_type in collections_to_check:
                try:
                    collection = multi_domain_rag_engine.chroma_client.get_or_create_collection(coll_name)
                    count = collection.count()
                    if coll_type == "question":
                        total_questions += count
                    else:
                        total_concepts += count
                except:
                    pass

            st.metric("ì´ ë¬¸ì œ", total_questions)
            st.metric("ì´ ê°œë…", total_concepts)
            st.metric("ì „ì²´ ë°ì´í„°", total_questions + total_concepts)
        except Exception as e:
            st.error(f"[ERROR] ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")

    # Main content tabs - 6ê°œ íƒ­
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "[DATA] ì˜ë£Œ ë°ì´í„° ì…ë ¥",
        "ğŸ‹ï¸ ìš´ë™/ì˜ì–‘ ì…ë ¥",
        "ğŸŒ ì–¸ì–´ í•™ìŠµ ì…ë ¥",
        "[CHECK] ë°ì´í„° í™•ì¸",
        "[AI] AI ë¬¸ì œ ìƒì„±",
        "[SYSTEM] ì‹œìŠ¤í…œ ê´€ë¦¬"
    ])

    with tab1:
        data_input_tab()

    with tab2:
        fitness_data_input_tab()

    with tab3:
        lingumo_data_input_tab()

    with tab4:
        chromadb_check_tab()

    with tab5:
        ai_generation_tab()

    with tab6:
        system_management_tab()


def data_input_tab():
    """Data input tab for questions and concepts"""
    st.header("[DATA] ì˜ë£Œ ë°ì´í„° ì…ë ¥")

    input_type = st.selectbox("ì…ë ¥ íƒ€ì…", ["ë¬¸ì œ", "ê°œë…"])

    if input_type == "ë¬¸ì œ":
        question_input_form()
    else:
        concept_input_form()


def question_input_form():
    """Manual form for inputting nursing/medical problems without AI analysis"""
    from problem_manual_form import problem_manual_input_form

    # Use the new manual input form
    problem_manual_input_form()


def concept_input_form():
    """Manual form for inputting medical concepts without AI analysis"""
    from concept_manual_form import concept_manual_input_form

    # Use the new manual input form
    concept_manual_input_form()
def ai_generation_tab():
    """AI batch question generation tab"""
    st.header("[AI] AI ë¬¸ì œ ë°°ì¹˜ ìƒì„±")

    # Create subtabs - Only AUTO and HISTORY
    gen_tab1, gen_tab2 = st.tabs([
        "[AUTO] AI ìë™ í•™ìŠµ ê³„íš",
        "[HISTORY] ìƒì„± ì´ë ¥"
    ])

    with gen_tab1:
        auto_learning_plan_section()

    with gen_tab2:
        generation_history_section()


def auto_learning_plan_section():
    """AI-powered automatic learning plan generation"""
    st.subheader("[AUTO] AI ìë™ í•™ìŠµ ê³„íš - ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§")

    # Tab for monitoring mode
    monitor_tab, manual_tab = st.tabs(["[MONITOR] ìë™ ëª¨ë‹ˆí„°ë§", "[MANUAL] ìˆ˜ë™ ìƒì„±"])

    with monitor_tab:
        st.info("[INFO] í•™ìŠµ ì¤‘ì¸ ì‚¬ìš©ìë¥¼ í™•ì¸í•˜ê³  í•„ìš”í•œ ì‚¬ìš©ìì—ê²Œ ë§ì¶¤ ë¬¸ì œë¥¼ ìƒì„±í•©ë‹ˆë‹¤")

        # Import monitoring service
        from user_monitor_service import monitor_instance

        # Display monitoring status
        col1, col2, col3 = st.columns(3)

        # Get current status
        status = monitor_instance.get_queue_status()

        with col1:
            st.metric("ì²˜ë¦¬ëœ ì‚¬ìš©ì", status['monitored_users'])
        with col2:
            st.metric("ëŒ€ê¸° ì¤‘ì¸ ì‘ì—…", status['pending'])
        with col3:
            st.metric("ì™„ë£Œëœ ì‘ì—…", status['completed'])

        # One-click automation button
        st.divider()
        if st.button("[AUTO] ì „ì²´ ìë™ ì²˜ë¦¬ ì‹¤í–‰", type="primary", use_container_width=True):
            with st.spinner("[PROCESSING] í™œë™ ì‚¬ìš©ì ë¶„ì„ ë° ë¬¸ì œ ìë™ ìƒì„± ì¤‘..."):
                try:
                    import asyncio
                    from learning_plan_engine import LearningPlanEngine

                    # Initialize engine
                    engine = LearningPlanEngine()
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)

                    # Step 1: Get active users
                    st.info("[STEP 1] í™œë™ ì‚¬ìš©ì í™•ì¸ ì¤‘...")
                    active_users = loop.run_until_complete(
                        monitor_instance.get_active_users(hours_back=24)
                    )

                    if not active_users:
                        st.warning("[EMPTY] ìµœê·¼ 24ì‹œê°„ ë™ì•ˆ í™œë™í•œ ì‚¬ìš©ìê°€ ì—†ìŠµë‹ˆë‹¤")
                        loop.close()
                    else:
                        st.success(f"[FOUND] {len(active_users)}ëª…ì˜ í™œë™ ì‚¬ìš©ì ë°œê²¬")

                        # Step 2: Process users who need help
                        users_processed = 0
                        users_helped = 0

                        progress_bar = st.progress(0)
                        status_text = st.empty()

                        for i, user in enumerate(active_users):
                            progress = (i + 1) / len(active_users)
                            progress_bar.progress(progress)
                            status_text.text(f"ì²˜ë¦¬ ì¤‘: {user['user_id']} ({i+1}/{len(active_users)})")

                            # Check if user needs help
                            needs_help = loop.run_until_complete(
                                monitor_instance.check_user_needs_help(user)
                            )

                            if needs_help:
                                st.write(f"[HELP] {user['user_id']} - ì˜¤ë‹µ {user['wrong_count']}ê°œ, ë„ì›€ í•„ìš”")

                                # Step 3: Generate learning plan for this user
                                try:
                                    # Analyze user history
                                    analysis = loop.run_until_complete(
                                        engine.analyze_user_history(user['user_id'], days_back=30)
                                    )

                                    if analysis:
                                        # Generate plan
                                        plan = loop.run_until_complete(
                                            engine.generate_learning_plan(analysis, target_count=10)
                                        )

                                        if plan:
                                            # Execute plan
                                            result = loop.run_until_complete(
                                                engine.execute_plan(plan, save_to_firebase=True)
                                            )

                                            if result['success']:
                                                st.success(f"âœ“ {user['user_id']}: {result['total_generated']}ê°œ ë¬¸ì œ ìƒì„± ì™„ë£Œ")
                                                users_helped += 1
                                            else:
                                                st.warning(f"âœ— {user['user_id']}: ë¬¸ì œ ìƒì„± ì‹¤íŒ¨")
                                        else:
                                            st.warning(f"âœ— {user['user_id']}: ê³„íš ìƒì„± ì‹¤íŒ¨")
                                    else:
                                        st.info(f"- {user['user_id']}: í•™ìŠµ ì´ë ¥ ì—†ìŒ")

                                except Exception as e:
                                    st.error(f"âœ— {user['user_id']}: ì˜¤ë¥˜ - {str(e)}")

                            users_processed += 1

                        loop.close()

                        # Final summary
                        st.divider()
                        st.subheader("[SUMMARY] ì²˜ë¦¬ ê²°ê³¼")
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("ì „ì²´ ì‚¬ìš©ì", len(active_users))
                        with col2:
                            st.metric("ë„ì›€ ì œê³µ", users_helped)
                        with col3:
                            st.metric("ì„±ê³µë¥ ", f"{(users_helped/len(active_users)*100 if active_users else 0):.0f}%")

                except Exception as e:
                    st.error(f"[ERROR] ìë™ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
                    if 'loop' in locals():
                        loop.close()

        # Active users section
        st.divider()
        st.subheader("[ACTIVE] ìµœê·¼ 24ì‹œê°„ í™œë™ ì‚¬ìš©ì")

        if st.button("[REFRESH] í™œë™ ì‚¬ìš©ì ìƒˆë¡œê³ ì¹¨"):
            with st.spinner("[LOADING] í™œë™ ì‚¬ìš©ì í™•ì¸ ì¤‘..."):
                try:
                    import asyncio

                    # Get active users
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    active_users = loop.run_until_complete(
                        monitor_instance.get_active_users(hours_back=24)
                    )
                    loop.close()

                    if active_users:
                        st.success(f"[FOUND] {len(active_users)}ëª…ì˜ í™œë™ ì‚¬ìš©ì ë°œê²¬")

                        # Display active users
                        for user in active_users:
                            with st.expander(f"ì‚¬ìš©ì: {user['user_id']} (ì˜¤ë‹µ {user['wrong_count']}ê°œ)"):
                                col1, col2 = st.columns(2)
                                with col1:
                                    st.write(f"**ë§ˆì§€ë§‰ í™œë™**: {user['last_activity']}")
                                    st.write(f"**ì˜¤ë‹µ ìˆ˜**: {user['wrong_count']}")
                                with col2:
                                    st.write(f"**ê³¼ëª©**: {', '.join(user['subjects'])}")
                                    # Check if needs help
                                    needs_help_loop = asyncio.new_event_loop()
                                    asyncio.set_event_loop(needs_help_loop)
                                    needs_help = needs_help_loop.run_until_complete(
                                        monitor_instance.check_user_needs_help(user)
                                    )
                                    needs_help_loop.close()

                                    if needs_help:
                                        st.error("[ALERT] ë„ì›€ í•„ìš”")
                                        if st.button(f"[GENERATE] ì¦‰ì‹œ ë¬¸ì œ ìƒì„±", key=f"gen_{user['user_id']}"):
                                            # Add to queue
                                            monitor_instance.processing_queue.append({
                                                'user_id': user['user_id'],
                                                'user_data': user,
                                                'timestamp': datetime.now(),
                                                'status': 'pending'
                                            })
                                            st.success("[QUEUED] ì²˜ë¦¬ ëŒ€ê¸°ì—´ì— ì¶”ê°€ë¨")
                                    else:
                                        st.success("[OK] ì–‘í˜¸")
                    else:
                        st.info("[EMPTY] ìµœê·¼ 24ì‹œê°„ ë™ì•ˆ í™œë™í•œ ì‚¬ìš©ìê°€ ì—†ìŠµë‹ˆë‹¤")

                except Exception as e:
                    st.error(f"[ERROR] ì‚¬ìš©ì ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

        # Processing queue section
        if status['queue_length'] > 0:
            st.divider()
            st.subheader("[QUEUE] ì²˜ë¦¬ ëŒ€ê¸°ì—´")

            # Display queue items
            for item in status['queue_details']:
                status_color = {
                    'pending': 'ğŸŸ¡',
                    'processing': 'ğŸ”µ',
                    'completed': 'ğŸŸ¢',
                    'failed': 'ğŸ”´'
                }.get(item['status'], 'âšª')

                with st.container():
                    col1, col2, col3 = st.columns([1, 2, 1])
                    with col1:
                        st.write(f"{status_color} {item['user_id']}")
                    with col2:
                        st.write(f"ìƒíƒœ: {item['status']}")
                    with col3:
                        if item['status'] == 'completed':
                            st.write(f"ìƒì„±: {item.get('questions_generated', 0)}ê°œ")
                        elif item['status'] == 'failed':
                            st.write(f"ì˜¤ë¥˜: {item.get('error', 'Unknown')}")

        # Manual refresh button
        if st.button("[REFRESH] ìˆ˜ë™ ìƒˆë¡œê³ ì¹¨", key="manual_refresh"):
            st.rerun()

    with manual_tab:
        st.info("[INFO] GPT-5-miniê°€ í•™ìŠµ ì´ë ¥ì„ ë¶„ì„í•˜ì—¬ ìµœì ì˜ í•™ìŠµ ê³„íšì„ ìë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤")

        # User input section
        col1, col2 = st.columns(2)

        with col1:
            user_id = st.text_input("ì‚¬ìš©ì ID", value="test_user", help="Flutter ì•±ì˜ ì‚¬ìš©ì ID", key="manual_user_id")
            days_back = st.number_input("ë¶„ì„ ê¸°ê°„ (ì¼)", min_value=7, max_value=90, value=30, key="manual_days")

        with col2:
            target_count = st.number_input("ìƒì„±í•  ë¬¸ì œ ìˆ˜", min_value=5, max_value=50, value=12, key="manual_count")
            focus_weak = st.checkbox("ì•½ì  ì¤‘ì‹¬ í•™ìŠµ", value=True, help="í‹€ë¦° ë¬¸ì œê°€ ë§ì€ ì˜ì—­ ì§‘ì¤‘", key="manual_weak")

        # Display current analysis
        if st.button("[ANALYZE] í•™ìŠµ ì´ë ¥ ë¶„ì„", key="manual_analyze"):
            with st.spinner("[PROCESSING] Firebaseì—ì„œ í•™ìŠµ ì´ë ¥ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
                try:
                    from learning_plan_engine import LearningPlanEngine
                    import asyncio

                    # Initialize engine
                    engine = LearningPlanEngine()

                    # Run async analysis
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)

                    analysis = loop.run_until_complete(
                        engine.analyze_user_history(user_id, days_back)
                    )

                    # Store in session state
                    st.session_state['learning_analysis'] = analysis
                    st.session_state['user_id'] = user_id

                    # Display analysis results
                    if analysis:
                        st.success("[SUCCESS] í•™ìŠµ ì´ë ¥ ë¶„ì„ ì™„ë£Œ")

                        # Show metrics
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("ì´ ë¬¸ì œ í’€ì´", analysis.get('total_attempts', 0))
                        with col2:
                            accuracy = analysis.get('overall_accuracy', 0)
                            st.metric("ì „ì²´ ì •ë‹µë¥ ", f"{accuracy:.1f}%")
                        with col3:
                            st.metric("ë¶„ì„ ê¸°ê°„", f"{days_back}ì¼")

                        # Show weak concepts
                        if analysis.get('weak_concepts'):
                            st.subheader("[WEAK] ì·¨ì•½ ê°œë… Top 5")
                            for concept in analysis['weak_concepts'][:5]:
                                accuracy = concept.get('accuracy', 0)
                                attempts = concept.get('attempts', 0)
                                st.write(f"- **{concept['concept']}**: ì •ë‹µë¥  {accuracy:.1f}% (ì‹œë„ {attempts}íšŒ)")

                        # Show strong concepts
                        if analysis.get('strong_concepts'):
                            with st.expander("[STRONG] ê°•ì  ê°œë… ë³´ê¸°"):
                                for concept in analysis['strong_concepts'][:5]:
                                    accuracy = concept.get('accuracy', 0)
                                    attempts = concept.get('attempts', 0)
                                    st.write(f"- {concept['concept']}: ì •ë‹µë¥  {accuracy:.1f}% (ì‹œë„ {attempts}íšŒ)")

                    else:
                        st.warning("[WARNING] ë¶„ì„í•  í•™ìŠµ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤")

                except Exception as e:
                    st.error(f"[ERROR] ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
                finally:
                    if 'loop' in locals():
                        loop.close()

    # Generate learning plan
    if st.session_state.get('learning_analysis'):
        st.divider()
        st.subheader("[PLAN] AI í•™ìŠµ ê³„íš ìƒì„±")

        if st.button("[GENERATE] GPT-5-minië¡œ ìµœì  í•™ìŠµ ê³„íš ìƒì„±"):
            with st.spinner("[AI] GPT-5-miniê°€ ìµœì  í•™ìŠµ ê³„íšì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
                try:
                    from learning_plan_engine import LearningPlanEngine
                    import asyncio

                    engine = LearningPlanEngine()
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)

                    plan = loop.run_until_complete(
                        engine.generate_learning_plan(
                            st.session_state['learning_analysis'],
                            target_count
                        )
                    )

                    # Store plan
                    st.session_state['learning_plan'] = plan

                    # Display plan
                    if plan:
                        st.success("[SUCCESS] í•™ìŠµ ê³„íš ìƒì„± ì™„ë£Œ")

                        # Show plan overview
                        st.subheader("[OVERVIEW] ê³„íš ê°œìš”")
                        st.write(f"**ì „ëµ**: {plan.get('strategy', 'N/A')}")
                        st.write(f"**ëª©í‘œ**: {plan.get('goal', 'N/A')}")
                        st.write(f"**ì´ ë¬¸ì œ ìˆ˜**: {plan.get('total_questions', 0)}")

                        # Show question distribution
                        if plan.get('question_distribution'):
                            st.subheader("[DISTRIBUTION] ë¬¸ì œ ìœ í˜• ë¶„ë°°")
                            for item in plan['question_distribution']:
                                st.write(f"- **{item['type']}**: {item['count']}ë¬¸ì œ ({item['reason']})")

                        # Show topic focus
                        if plan.get('topic_focus'):
                            st.subheader("[TOPICS] ì£¼ì œ ì´ˆì ")
                            for topic in plan['topic_focus']:
                                st.write(f"- **{topic['topic']}**: {topic['count']}ë¬¸ì œ - {topic['reason']}")

                        # Show difficulty distribution
                        if plan.get('difficulty_distribution'):
                            st.subheader("[DIFFICULTY] ë‚œì´ë„ ë¶„í¬")
                            for diff in plan['difficulty_distribution']:
                                st.write(f"- **{diff['level'].upper()}**: {diff['count']}ë¬¸ì œ ({diff['percentage']}%)")

                    else:
                        st.error("[ERROR] ê³„íš ìƒì„± ì‹¤íŒ¨")

                except Exception as e:
                    st.error(f"[ERROR] ê³„íš ìƒì„± ì˜¤ë¥˜: {str(e)}")
                finally:
                    if 'loop' in locals():
                        loop.close()

    # Execute plan
    if st.session_state.get('learning_plan'):
        st.divider()
        st.subheader("[EXECUTE] ê³„íš ì‹¤í–‰")

        st.warning("[WARNING] ê³„íšì„ ì‹¤í–‰í•˜ë©´ ì‹¤ì œë¡œ ë¬¸ì œê°€ ìƒì„±ë˜ê³  Firebaseì— ì €ì¥ë©ë‹ˆë‹¤")

        if st.button("[EXECUTE] í•™ìŠµ ê³„íš ì‹¤í–‰ (ë¬¸ì œ ìƒì„±)"):
            with st.spinner("[PROCESSING] AIê°€ ë¬¸ì œë¥¼ ìƒì„±í•˜ëŠ” ì¤‘..."):
                try:
                    from learning_plan_engine import LearningPlanEngine
                    import asyncio

                    engine = LearningPlanEngine()
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)

                    result = loop.run_until_complete(
                        engine.execute_plan(
                            st.session_state['learning_plan'],
                            save_to_firebase=True
                        )
                    )

                    # Display execution results
                    if result and result.get('success'):
                        st.success(f"[SUCCESS] {result['total_generated']}ê°œ ë¬¸ì œ ìƒì„± ì™„ë£Œ!")

                        # Show statistics
                        st.subheader("[STATS] ìƒì„± í†µê³„")
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("ìƒì„± ì„±ê³µ", result['total_generated'])
                        with col2:
                            st.metric("ì‹¤í–‰ ì‹œê°„", f"{result.get('execution_time', 0):.1f}ì´ˆ")

                        # Show generated questions preview
                        if result.get('questions'):
                            st.subheader("[PREVIEW] ìƒì„±ëœ ë¬¸ì œ ë¯¸ë¦¬ë³´ê¸°")
                            for i, q in enumerate(result['questions'][:3], 1):
                                with st.expander(f"ë¬¸ì œ {i}: {q.get('type', 'MCQ')}"):
                                    st.write(f"**ë¬¸ì œ**: {q['question_text']}")
                                    st.write("**ì„ íƒì§€**:")
                                    for j, choice in enumerate(q['choices'], 1):
                                        st.write(f"  {j}. {choice}")
                                    st.write(f"**ì •ë‹µ**: {q['correct_answer']}")
                    else:
                        st.error("[ERROR] ì‹¤í–‰ ì‹¤íŒ¨")

                except Exception as e:
                    st.error(f"[ERROR] ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
                finally:
                    if 'loop' in locals():
                        loop.close()


def generation_history_section():
    """Display generation history"""
    st.subheader("[HISTORY] AI ë¬¸ì œ ìƒì„± ì´ë ¥")

    # Time period selection
    col1, col2 = st.columns(2)
    with col1:
        period = st.selectbox("ê¸°ê°„ ì„ íƒ", ["ì˜¤ëŠ˜", "ìµœê·¼ 7ì¼", "ìµœê·¼ 30ì¼", "ì „ì²´"], key="history_period")
    with col2:
        if st.button("[REFRESH] ì´ë ¥ ìƒˆë¡œê³ ì¹¨", key="refresh_history"):
            st.rerun()

    # Get generation history from Firebase
    with st.spinner("[LOADING] Firebaseì—ì„œ ìƒì„± ì´ë ¥ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
        try:
            import firebase_admin
            from firebase_admin import credentials, firestore
            from datetime import datetime, timedelta

            # Initialize Firebase if not already done
            if not firebase_admin._apps:
                cred = credentials.Certificate('firebase-service-account.json')
                firebase_admin.initialize_app(cred)

            db = firestore.client()

            # Calculate date range
            now = datetime.now()
            if period == "ì˜¤ëŠ˜":
                start_date = now.replace(hour=0, minute=0, second=0, microsecond=0)
            elif period == "ìµœê·¼ 7ì¼":
                start_date = now - timedelta(days=7)
            elif period == "ìµœê·¼ 30ì¼":
                start_date = now - timedelta(days=30)
            else:  # ì „ì²´
                start_date = datetime(2024, 1, 1)  # Arbitrary old date

            # Query generation logs from Firebase
            generation_logs = []

            # Get from nursing_problems collection (recently generated problems)
            problems_ref = db.collection('nursing_problems')
            query = problems_ref.where('generated_by', 'in', ['gpt-5-mini', 'gpt-5', 'gemini-2.5-flash'])

            if period != "ì „ì²´":
                query = query.where('timestamp', '>=', start_date)

            query = query.order_by('timestamp', direction=firestore.Query.DESCENDING).limit(100)

            docs = query.stream()

            for doc in docs:
                data = doc.to_dict()
                if data.get('generated_by'):
                    generation_logs.append({
                        'id': doc.id,
                        'timestamp': data.get('timestamp', ''),
                        'type': data.get('type', 'MCQ'),
                        'model': data.get('generated_by', 'Unknown'),
                        'difficulty': data.get('difficulty', 'medium'),
                        'subject': data.get('subject', 'nursing'),
                        'created_by': data.get('created_by', 'ai_batch_generator')
                    })

            # Also check for batch generation logs if we have a separate collection
            try:
                batch_logs_ref = db.collection('generation_logs')
                batch_query = batch_logs_ref

                if period != "ì „ì²´":
                    batch_query = batch_query.where('timestamp', '>=', start_date)

                batch_query = batch_query.order_by('timestamp', direction=firestore.Query.DESCENDING).limit(50)
                batch_docs = batch_query.stream()

                for doc in batch_docs:
                    data = doc.to_dict()
                    generation_logs.append({
                        'id': doc.id,
                        'timestamp': data.get('timestamp', ''),
                        'type': 'Batch Generation',
                        'model': data.get('model_used', 'GPT-5-mini'),
                        'count': data.get('questions_generated', 0),
                        'user': data.get('user_id', 'System'),
                        'status': data.get('status', 'completed')
                    })
            except:
                # If generation_logs collection doesn't exist, continue
                pass

            if generation_logs:
                # Convert to DataFrame
                history_data = []
                for log in generation_logs:
                    # Format timestamp
                    timestamp_str = ""
                    if log.get('timestamp'):
                        try:
                            if isinstance(log['timestamp'], datetime):
                                timestamp_str = log['timestamp'].strftime('%Y-%m-%d %H:%M')
                            elif isinstance(log['timestamp'], str):
                                timestamp_str = log['timestamp'][:16]  # Take first 16 chars (YYYY-MM-DD HH:MM)
                        except:
                            timestamp_str = "N/A"

                    history_data.append({
                        'ì‹œê°„': timestamp_str,
                        'ìœ í˜•': log.get('type', 'MCQ'),
                        'ëª¨ë¸': log.get('model', 'Unknown'),
                        'ë‚œì´ë„': log.get('difficulty', log.get('status', 'N/A')),
                        'ê³¼ëª©': log.get('subject', log.get('user', 'N/A')),
                        'ìƒì„±ì': log.get('created_by', log.get('user', 'System'))
                    })

                df = pd.DataFrame(history_data)

                # Display summary metrics
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("ì´ ìƒì„± ë¬¸ì œ", len(history_data))
                with col2:
                    # Count by model
                    if 'gpt-5-mini' in df['ëª¨ë¸'].values:
                        gpt5_mini_count = len(df[df['ëª¨ë¸'] == 'gpt-5-mini'])
                    else:
                        gpt5_mini_count = 0
                    st.metric("GPT-5-mini", gpt5_mini_count)
                with col3:
                    if 'gpt-5' in df['ëª¨ë¸'].values:
                        gpt5_count = len(df[df['ëª¨ë¸'] == 'gpt-5'])
                    else:
                        gpt5_count = 0
                    st.metric("GPT-5", gpt5_count)
                with col4:
                    if 'gemini-2.5-flash' in df['ëª¨ë¸'].values:
                        gemini_count = len(df[df['ëª¨ë¸'] == 'gemini-2.5-flash'])
                    else:
                        gemini_count = 0
                    st.metric("Gemini", gemini_count)

                # Display the dataframe
                st.dataframe(df, width='stretch')

                # Model usage chart
                if len(df) > 0:
                    st.subheader("[CHART] ëª¨ë¸ë³„ ì‚¬ìš© í†µê³„")
                    model_counts = df['ëª¨ë¸'].value_counts()
                    st.bar_chart(model_counts)

            else:
                st.info("[EMPTY] ì„ íƒí•œ ê¸°ê°„ì— ìƒì„± ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤")

        except Exception as e:
            st.error(f"[ERROR] ì´ë ¥ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

            # Show sample data for demonstration
            st.info("[INFO] ìƒ˜í”Œ ë°ì´í„°ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤")
            sample_data = {
                "ì‹œê°„": ["2025-01-23 10:00", "2025-01-23 09:30", "2025-01-23 09:00"],
                "ìœ í˜•": ["MCQ", "Case", "Image"],
                "ëª¨ë¸": ["gpt-5-mini", "gpt-5", "gemini-2.5-flash"],
                "ë‚œì´ë„": ["medium", "hard", "easy"],
                "ê³¼ëª©": ["nursing", "medical", "pharmacology"],
                "ìƒì„±ì": ["ai_batch_generator", "user_monitor", "manual"]
            }
            df = pd.DataFrame(sample_data)
            st.dataframe(df, width='stretch')


def system_management_tab():
    """System management and settings tab"""
    st.header("[SYSTEM] ì‹œìŠ¤í…œ ê´€ë¦¬")

    # Create subtabs for system management
    mgmt_tab1, mgmt_tab2 = st.tabs(["[SETTINGS] ì‹œìŠ¤í…œ ì„¤ì •", "[API] API ì‚¬ìš©ëŸ‰"])

    with mgmt_tab1:
        st.subheader("[SETTINGS] ì‹œìŠ¤í…œ ì„¤ì •")

        col1, col2 = st.columns(2)

        with col1:
            st.info("[PATH] Jobs ë””ë ‰í„°ë¦¬")
            st.code(str(JOBS_DIR))

            st.info("[PATH] ChromaDB ê²½ë¡œ")
            st.code("database/chroma_db/")

        with col2:
            st.info("[MODEL] AI ëª¨ë¸ ì„¤ì •")
            st.code("Embedding: text-embedding-004")
            st.code("Primary: GPT-5 Mini")
            st.code("Advanced: GPT-5")

        # Environment check
        st.subheader("[CHECK] í™˜ê²½ í™•ì¸")

        try:
            validate_config()
            st.success("[OK] ëª¨ë“  ì„¤ì •ì´ ì˜¬ë°”ë¦…ë‹ˆë‹¤")
        except Exception as e:
            st.error(f"[ERROR] ì„¤ì • ì˜¤ë¥˜: {e}")

    with mgmt_tab2:
        st.subheader("[API] API ì‚¬ìš©ëŸ‰ ì¶”ì ")

        # API Usage Overview
        st.info("[INFO] OpenAI ë° Gemini API ì‚¬ìš©ëŸ‰ ë° ë¹„ìš© ì¶”ì ")

        # Time period selection
        period = st.selectbox("ê¸°ê°„ ì„ íƒ", ["ì˜¤ëŠ˜", "ì´ë²ˆ ì£¼", "ì´ë²ˆ ë‹¬"])

        try:
            # Get usage data based on period
            if period == "ì˜¤ëŠ˜":
                usage_data = api_tracker.get_daily_usage()
                st.subheader(f"[TODAY] ì˜¤ëŠ˜ ì‚¬ìš©ëŸ‰ ({datetime.now().strftime('%Y-%m-%d')})")
            elif period == "ì´ë²ˆ ì£¼":
                usage_data = api_tracker.get_weekly_usage()
                st.subheader("[WEEK] ìµœê·¼ 7ì¼ ì‚¬ìš©ëŸ‰")
            else:  # ì´ë²ˆ ë‹¬
                now = datetime.now()
                usage_data = api_tracker.get_monthly_usage(now.year, now.month)
                st.subheader(f"[MONTH] {now.year}ë…„ {now.month}ì›” ì‚¬ìš©ëŸ‰")

            # Display metrics
            col1, col2, col3 = st.columns(3)

            total_cost = usage_data.get('total_cost', 0) if usage_data else 0
            total_tokens = usage_data.get('total_tokens', 0) if usage_data else 0

            with col1:
                st.metric("ì´ í† í° ì‚¬ìš©ëŸ‰", f"{total_tokens:,}")
            with col2:
                st.metric("ì´ ë¹„ìš©", f"${total_cost:.4f}")
            with col3:
                st.metric("ì›í™” í™˜ì‚° (1,400ì›/$)", f"â‚©{total_cost * 1400:.0f}")

            # Model-wise breakdown
            if usage_data and usage_data.get('by_model'):
                st.subheader("[MODEL] ëª¨ë¸ë³„ ì‚¬ìš©ëŸ‰")

                model_data = []
                for model, stats in usage_data['by_model'].items():
                    model_data.append({
                        'ëª¨ë¸': model,
                        'ì…ë ¥ í† í°': f"{stats.get('input_tokens', 0):,}",
                        'ì¶œë ¥ í† í°': f"{stats.get('output_tokens', 0):,}",
                        'ìš”ì²­ íšŸìˆ˜': stats.get('requests', 0),
                        'ë¹„ìš© (USD)': f"${stats.get('cost', 0):.4f}"
                    })

                if model_data:
                    model_df = pd.DataFrame(model_data)
                    st.dataframe(model_df, width='stretch')
            else:
                st.info("[INFO] í•´ë‹¹ ê¸°ê°„ì˜ ì‚¬ìš© ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤")

        except Exception as e:
            st.error(f"[ERROR] API ì‚¬ìš©ëŸ‰ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            st.info("[INFO] api_usage_trackerê°€ ì œëŒ€ë¡œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")

        # Model pricing reference
        with st.expander("[PRICE] ëª¨ë¸ë³„ ê°€ê²©í‘œ"):
            pricing_data = [
                {'ëª¨ë¸': 'GPT-5', 'ì…ë ¥ (1M tokens)': '$1.25', 'ì¶œë ¥ (1M tokens)': '$10.00'},
                {'ëª¨ë¸': 'GPT-5 Mini', 'ì…ë ¥ (1M tokens)': '$0.65', 'ì¶œë ¥ (1M tokens)': '$5.00'},
                {'ëª¨ë¸': 'GPT-5 Nano', 'ì…ë ¥ (1M tokens)': '$0.40', 'ì¶œë ¥ (1M tokens)': '$2.50'},
                {'ëª¨ë¸': 'Gemini 2.5 Pro', 'ì…ë ¥ (1M tokens)': '$1.25', 'ì¶œë ¥ (1M tokens)': '$10.00'},
                {'ëª¨ë¸': 'Gemini 2.5 Flash', 'ì…ë ¥ (1M tokens)': '$0.10', 'ì¶œë ¥ (1M tokens)': '$0.40'},
            ]
            pricing_df = pd.DataFrame(pricing_data)
            st.dataframe(pricing_df, width='stretch')


def chromadb_check_tab():
    """ChromaDB data check tab with deletion capability"""
    st.subheader("[CHECK] ChromaDB ë°ì´í„° í™•ì¸ ë° ê´€ë¦¬")

    # Collection selection
    collection_name = st.selectbox(
        "ì»¬ë ‰ì…˜ ì„ íƒ",
        ["nursing_questions", "nursing_concepts", "medical_concepts", "fitness_knowledge", "lingumo_knowledge"]
    )

    # Store data in session state
    if 'chromadb_data' not in st.session_state:
        st.session_state.chromadb_data = None
        st.session_state.chromadb_ids = []

    # Get collection data
    col1, col2, col3 = st.columns([1, 1, 2])
    with col1:
        if st.button("[LOAD] ë°ì´í„° ì¡°íšŒ"):
            try:
                from rag_engine_multi_domain import multi_domain_rag_engine

                # Get or create collection
                collection = multi_domain_rag_engine.chroma_client.get_or_create_collection(collection_name)

                # Get all data
                results = collection.get()

                if results and results['ids']:
                    st.success(f"[SUCCESS] {len(results['ids'])}ê°œ ë°ì´í„° ë°œê²¬")

                    # Store full IDs for deletion
                    st.session_state.chromadb_ids = results['ids']

                    # Create DataFrame for display
                    data_list = []
                    for i, doc_id in enumerate(results['ids']):
                        metadata = results['metadatas'][i] if i < len(results['metadatas']) else {}
                        document = results['documents'][i] if i < len(results['documents']) else ""

                        # Extract full question data from document and metadata
                        question_display = metadata.get('questionText', metadata.get('title', ''))
                        if not question_display and document:
                            # Try to extract from document if not in metadata
                            question_display = document.split('\n')[0].replace('ë¬¸ì œ: ', '').replace('ì„¤ëª…: ', '')[:100]

                        # Check if data has image
                        has_image = metadata.get('hasImage', False)
                        image_url = metadata.get('imageUrl', '')

                        data_item = {
                            'Index': i,
                            'ID': doc_id[:8] + '...',  # Display shortened ID
                            'ë¬¸ì œ/ê°œë…': question_display[:80] + '...' if len(question_display) > 80 else question_display,
                            'íƒ€ì…': metadata.get('type', 'N/A'),
                            'ê³¼ëª©': metadata.get('subject', metadata.get('category', 'N/A')),
                            'ë‚œì´ë„': metadata.get('difficulty', 'N/A'),
                            'íƒœê·¸': metadata.get('tags', metadata.get('keywords', 'N/A')),
                            'ì´ë¯¸ì§€': '[IMAGE]' if has_image else 'N/A',
                            'ì´ë¯¸ì§€URL': image_url[:50] + '...' if len(image_url) > 50 else image_url if image_url else 'N/A'
                        }

                        # Add specific fields based on type
                        if metadata.get('type') == 'problem':
                            data_item.update({
                                'ì •ë‹µ': metadata.get('correctAnswer', 'N/A')[:50],
                                'ì„ íƒì§€1': metadata.get('choice1', 'N/A')[:30],
                                'ì„ íƒì§€2': metadata.get('choice2', 'N/A')[:30],
                            })
                        elif metadata.get('type') == 'concept':
                            data_item.update({
                                'ì´ë¯¸ì§€ë¶„ì„': '[ANALYZED]' if metadata.get('imageMainObjects') else 'N/A',
                                'ì£¼ìš”ê°ì²´': metadata.get('imageMainObjects', 'N/A')[:50],
                                'ì˜ë£Œíƒœê·¸': metadata.get('imageMedicalTags', 'N/A')[:50]
                            })

                        data_list.append(data_item)

                    st.session_state.chromadb_data = pd.DataFrame(data_list)
                else:
                    st.info(f"[INFO] {collection_name} ì»¬ë ‰ì…˜ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                    st.session_state.chromadb_data = None
                    st.session_state.chromadb_ids = []

            except Exception as e:
                st.error(f"[ERROR] ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")

    with col2:
        # Delete all button
        if st.button("[DELETE ALL] ì „ì²´ ì‚­ì œ", type="secondary"):
            if st.session_state.chromadb_ids:
                try:
                    from rag_engine_multi_domain import multi_domain_rag_engine
                    collection = multi_domain_rag_engine.chroma_client.get_or_create_collection(collection_name)

                    # Delete all documents
                    collection.delete(ids=st.session_state.chromadb_ids)
                    st.success(f"[SUCCESS] {len(st.session_state.chromadb_ids)}ê°œ ë°ì´í„° ì‚­ì œ ì™„ë£Œ!")

                    # Clear session state
                    st.session_state.chromadb_data = None
                    st.session_state.chromadb_ids = []
                    st.rerun()

                except Exception as e:
                    st.error(f"[ERROR] ì „ì²´ ì‚­ì œ ì‹¤íŒ¨: {e}")
            else:
                st.warning("[WARNING] ì‚­ì œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì¡°íšŒí•˜ì„¸ìš”.")

    # Display data if available
    if st.session_state.chromadb_data is not None:
        st.divider()

        # Show data table
        st.dataframe(st.session_state.chromadb_data, width='stretch')

        # Image preview section
        st.divider()
        st.subheader("[IMAGE] ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°")

        # Select item for image preview
        if '[IMAGE]' in st.session_state.chromadb_data['ì´ë¯¸ì§€'].values:
            image_items = st.session_state.chromadb_data[st.session_state.chromadb_data['ì´ë¯¸ì§€'] == '[IMAGE]']

            selected_index = st.selectbox(
                "ì´ë¯¸ì§€ê°€ ìˆëŠ” í•­ëª© ì„ íƒ",
                options=image_items['Index'].tolist(),
                format_func=lambda x: f"Index {x}: {image_items.iloc[image_items['Index'].tolist().index(x)]['ë¬¸ì œ/ê°œë…'][:50]}..."
            )

            if selected_index is not None:
                selected_row = st.session_state.chromadb_data.iloc[selected_index]
                image_url = selected_row['ì´ë¯¸ì§€URL'].replace('...', '') if selected_row['ì´ë¯¸ì§€URL'] != 'N/A' else None

                col_img1, col_img2 = st.columns([1, 2])

                with col_img1:
                    if image_url and image_url != 'N/A':
                        try:
                            st.image(image_url, caption="ì €ì¥ëœ ì´ë¯¸ì§€", width=200)
                        except Exception as e:
                            st.error(f"[ERROR] ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
                            st.write(f"**ì´ë¯¸ì§€ URL**: {image_url}")
                    else:
                        st.info("[INFO] ì´ë¯¸ì§€ URLì´ ì—†ìŠµë‹ˆë‹¤")

                with col_img2:
                    st.write(f"**ë¬¸ì œ/ê°œë…**: {selected_row['ë¬¸ì œ/ê°œë…']}")
                    st.write(f"**íƒ€ì…**: {selected_row['íƒ€ì…']}")
                    st.write(f"**ê³¼ëª©**: {selected_row['ê³¼ëª©']}")

                    if selected_row.get('ì´ë¯¸ì§€ë¶„ì„') == '[ANALYZED]':
                        st.write("**[ANALYSIS] ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ**")
                        st.write(f"**ì£¼ìš” ê°ì²´**: {selected_row.get('ì£¼ìš”ê°ì²´', 'N/A')}")
                        st.write(f"**ì˜ë£Œ íƒœê·¸**: {selected_row.get('ì˜ë£Œíƒœê·¸', 'N/A')}")
                    elif selected_row.get('ì •ë‹µ'):
                        st.write(f"**ì •ë‹µ**: {selected_row.get('ì •ë‹µ', 'N/A')}")
        else:
            st.info("[INFO] ì´ë¯¸ì§€ê°€ í¬í•¨ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")

        # Export option
        csv = st.session_state.chromadb_data.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="[EXPORT] CSVë¡œ ë‹¤ìš´ë¡œë“œ",
            data=csv,
            file_name=f"{collection_name}_data.csv",
            mime="text/csv"
        )

        # Individual deletion
        st.divider()
        st.subheader("[DELETE] ê°œë³„ ë°ì´í„° ì‚­ì œ")

        # Select items to delete
        indices_to_delete = st.multiselect(
            "ì‚­ì œí•  í•­ëª© ì„ íƒ (Index ë²ˆí˜¸)",
            options=st.session_state.chromadb_data['Index'].tolist(),
            format_func=lambda x: f"Index {x}: {st.session_state.chromadb_data.iloc[x]['ë¬¸ì œ'][:50] if 'ë¬¸ì œ' in st.session_state.chromadb_data.columns else st.session_state.chromadb_data.iloc[x].get('ì œëª©/ì§ˆë¬¸', 'N/A')[:50]}..."
        )

        if st.button("[DELETE SELECTED] ì„ íƒ í•­ëª© ì‚­ì œ"):
            if indices_to_delete:
                try:
                    from rag_engine_multi_domain import multi_domain_rag_engine
                    collection = multi_domain_rag_engine.chroma_client.get_or_create_collection(collection_name)

                    # Get IDs to delete
                    ids_to_delete = [st.session_state.chromadb_ids[i] for i in indices_to_delete]

                    # Delete selected documents
                    collection.delete(ids=ids_to_delete)
                    st.success(f"[SUCCESS] {len(ids_to_delete)}ê°œ í•­ëª© ì‚­ì œ ì™„ë£Œ!")

                    # Clear session state to refresh
                    st.session_state.chromadb_data = None
                    st.session_state.chromadb_ids = []
                    st.rerun()

                except Exception as e:
                    st.error(f"[ERROR] ì„ íƒ í•­ëª© ì‚­ì œ ì‹¤íŒ¨: {e}")
            else:
                st.warning("[WARNING] ì‚­ì œí•  í•­ëª©ì„ ì„ íƒí•˜ì„¸ìš”.")

    # Collection statistics
    st.divider()
    st.subheader("[STATS] ì»¬ë ‰ì…˜ í†µê³„")

    try:
        from services.firebase_service import firebase_service
        from rag_engine_multi_domain import multi_domain_rag_engine

        stats_data = []

        # ChromaDB collections to check
        collections_info = [
            ("nursing_questions", "ê°„í˜¸ ë¬¸ì œ"),
            ("medical_problems", "ì˜í•™ ë¬¸ì œ"),
            ("medical_concepts", "ì˜í•™ ê°œë…"),
            ("fitness_knowledge", "ìš´ë™/ì˜ì–‘"),
            ("lingumo_knowledge", "ì–¸ì–´ í•™ìŠµ")
        ]

        # Get ChromaDB stats
        for coll_name, display_name in collections_info:
            try:
                collection = multi_domain_rag_engine.chroma_client.get_or_create_collection(coll_name)

                # fitness_knowledgeëŠ” ìš´ë™/ì˜ì–‘/ê±´ê°• ë¶„ë¦¬
                if coll_name == "fitness_knowledge":
                    results = collection.get()
                    if results and results['metadatas']:
                        # ìš´ë™ ê°œë…
                        exercise_count = sum(1 for m in results['metadatas'] if m.get('category') == 'ìš´ë™')
                        stats_data.append({
                            'ë°ì´í„°ë² ì´ìŠ¤': 'ChromaDB',
                            'ì»¬ë ‰ì…˜': 'ìš´ë™',
                            'ë°ì´í„° ìˆ˜': exercise_count,
                            'ìƒíƒœ': '[ACTIVE]' if exercise_count > 0 else '[EMPTY]'
                        })

                        # ì˜ì–‘ ê°œë…
                        nutrition_count = sum(1 for m in results['metadatas'] if m.get('category') == 'ì˜ì–‘')
                        stats_data.append({
                            'ë°ì´í„°ë² ì´ìŠ¤': 'ChromaDB',
                            'ì»¬ë ‰ì…˜': 'ì˜ì–‘',
                            'ë°ì´í„° ìˆ˜': nutrition_count,
                            'ìƒíƒœ': '[ACTIVE]' if nutrition_count > 0 else '[EMPTY]'
                        })

                        # ê±´ê°• ê°œë…
                        health_count = sum(1 for m in results['metadatas'] if m.get('category') == 'ê±´ê°•')
                        stats_data.append({
                            'ë°ì´í„°ë² ì´ìŠ¤': 'ChromaDB',
                            'ì»¬ë ‰ì…˜': 'ê±´ê°•',
                            'ë°ì´í„° ìˆ˜': health_count,
                            'ìƒíƒœ': '[ACTIVE]' if health_count > 0 else '[EMPTY]'
                        })
                    else:
                        stats_data.append({
                            'ë°ì´í„°ë² ì´ìŠ¤': 'ChromaDB',
                            'ì»¬ë ‰ì…˜': 'ìš´ë™',
                            'ë°ì´í„° ìˆ˜': 0,
                            'ìƒíƒœ': '[EMPTY]'
                        })
                        stats_data.append({
                            'ë°ì´í„°ë² ì´ìŠ¤': 'ChromaDB',
                            'ì»¬ë ‰ì…˜': 'ì˜ì–‘',
                            'ë°ì´í„° ìˆ˜': 0,
                            'ìƒíƒœ': '[EMPTY]'
                        })
                        stats_data.append({
                            'ë°ì´í„°ë² ì´ìŠ¤': 'ChromaDB',
                            'ì»¬ë ‰ì…˜': 'ê±´ê°•',
                            'ë°ì´í„° ìˆ˜': 0,
                            'ìƒíƒœ': '[EMPTY]'
                        })
                else:
                    count = collection.count()
                    stats_data.append({
                        'ë°ì´í„°ë² ì´ìŠ¤': 'ChromaDB',
                        'ì»¬ë ‰ì…˜': display_name,
                        'ë°ì´í„° ìˆ˜': count,
                        'ìƒíƒœ': '[ACTIVE]' if count > 0 else '[EMPTY]'
                    })
            except Exception as e:
                if coll_name == "fitness_knowledge":
                    stats_data.append({
                        'ë°ì´í„°ë² ì´ìŠ¤': 'ChromaDB',
                        'ì»¬ë ‰ì…˜': 'ìš´ë™',
                        'ë°ì´í„° ìˆ˜': 0,
                        'ìƒíƒœ': '[ERROR]'
                    })
                    stats_data.append({
                        'ë°ì´í„°ë² ì´ìŠ¤': 'ChromaDB',
                        'ì»¬ë ‰ì…˜': 'ì˜ì–‘',
                        'ë°ì´í„° ìˆ˜': 0,
                        'ìƒíƒœ': '[ERROR]'
                    })
                    stats_data.append({
                        'ë°ì´í„°ë² ì´ìŠ¤': 'ChromaDB',
                        'ì»¬ë ‰ì…˜': 'ê±´ê°•',
                        'ë°ì´í„° ìˆ˜': 0,
                        'ìƒíƒœ': '[ERROR]'
                    })
                else:
                    stats_data.append({
                        'ë°ì´í„°ë² ì´ìŠ¤': 'ChromaDB',
                        'ì»¬ë ‰ì…˜': display_name,
                        'ë°ì´í„° ìˆ˜': 0,
                        'ìƒíƒœ': '[ERROR]'
                    })


        # Display statistics
        if stats_data:
            stats_df = pd.DataFrame(stats_data)

            # Summary metrics
            col1, col2, col3 = st.columns(3)

            with col1:
                total_problems = sum(row['ë°ì´í„° ìˆ˜'] for row in stats_data if 'ë¬¸ì œ' in row['ì»¬ë ‰ì…˜'])
                st.metric("[PROBLEMS] ì´ ë¬¸ì œ", f"{total_problems:,}")

            with col2:
                total_concepts = sum(row['ë°ì´í„° ìˆ˜'] for row in stats_data if 'ê°œë…' in row['ì»¬ë ‰ì…˜'] or row['ì»¬ë ‰ì…˜'] in ['ìš´ë™', 'ì˜ì–‘', 'ê±´ê°•'])
                st.metric("[CONCEPTS] ì´ ê°œë…", f"{total_concepts:,}")

            with col3:
                total_chromadb = sum(row['ë°ì´í„° ìˆ˜'] for row in stats_data)
                st.metric("[TOTAL] ì „ì²´ ë°ì´í„°", f"{total_chromadb:,}")

            # Detailed table
            st.dataframe(
                stats_df.style.highlight_max(subset=['ë°ì´í„° ìˆ˜'], color='lightgreen'),
                width='stretch'
            )

            # Last update time
            st.caption(f"[UPDATE] ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    except Exception as e:
        st.error(f"[ERROR] í†µê³„ ë¡œë“œ ì‹¤íŒ¨: {e}")


def fitness_data_input_tab():
    """Fitness and nutrition data input tab"""
    from fitness_manual_form import fitness_concept_input_form

    st.header("ğŸ‹ï¸ ìš´ë™/ì˜ì–‘ ê°œë… ì…ë ¥")
    st.markdown("ìš´ë™ ë°©ë²•, í¼ ê°€ì´ë“œ, ì˜ì–‘ ì •ë³´ ë“±ì„ ì…ë ¥í•˜ì—¬ Areumfit RAG ì‹œìŠ¤í…œì— ì €ì¥í•©ë‹ˆë‹¤.")

    fitness_concept_input_form()


def lingumo_data_input_tab():
    """Language learning data input tab"""
    from lingumo_manual_form import lingumo_content_input_form

    st.header("ğŸŒ ì–¸ì–´ í•™ìŠµ ì½˜í…ì¸  ì…ë ¥")
    st.markdown("ë‹¨ì–´, ë¬¸ì¥, ë¬¸ë²• ë“±ì„ ì…ë ¥í•˜ì—¬ Lingumo RAG ì‹œìŠ¤í…œì— ì €ì¥í•©ë‹ˆë‹¤.")

    lingumo_content_input_form()


if __name__ == "__main__":
    main()




