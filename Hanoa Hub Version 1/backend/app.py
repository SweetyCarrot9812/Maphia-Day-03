"""
Hanoa RAG System - Streamlit Main Application (Simplified Version)
"""
import json
import uuid
from datetime import datetime
from pathlib import Path

import streamlit as st
import pandas as pd

from config import (
    validate_config, JOBS_DIR, OBSIDIAN_VAULT_PATH,
    DOMAIN_COLLECTIONS, DEFAULT_DOMAIN, ENABLE_CROSS_DOMAIN_SEARCH,
    ENABLE_IMAGE_VECTORS, GEMINI_API_KEY, OPENAI_API_KEY
)
from rag_engine import rag_engine
from rag_engine_multi_domain import multi_domain_rag_engine
from jobs_worker import jobs_worker
from analyzers.problem_analyzer import problem_analyzer
from models.problem_schema import ProblemData, create_sample_problems
from api_usage_tracker import api_tracker
from services.firebase_service import firebase_service
from services.gemini_service import gemini_service
from analyzers.image_hierarchical_analyzer import ImageHierarchicalAnalyzer
from deduplication_engine import deduplication_engine
from PIL import Image
import io
import base64

# Page configuration
st.set_page_config(
    page_title="Hanoa RAG System",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded"
)

def main():
    """Main Streamlit application"""

    # Initialize session state
    if 'initialized' not in st.session_state:
        try:
            validate_config()
            st.session_state.initialized = True
        except Exception as e:
            st.error(f"Configuration error: {e}")
            st.stop()

    # Header
    st.title("ğŸ“š Hanoa RAG System")
    st.markdown("ê°„í˜¸í•™/ì˜í•™ ë¬¸ì œ ë° ê°œë… ê´€ë¦¬ ì‹œìŠ¤í…œ")

    # Sidebar - System Status
    with st.sidebar:
        st.header("[STATUS] ì‹œìŠ¤í…œ ìƒíƒœ")

        # RAG Stats
        try:
            stats = rag_engine.get_stats()
            st.metric("ì´ ë¬¸ì œ", stats['questions'])
            st.metric("ì „ì²´ ë°ì´í„°", stats['total'])
        except Exception as e:
            st.error(f"[ERROR] RAG ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")

        # Firebase Status
        st.divider()
        st.subheader("[FIREBASE] ì—°ê²° ìƒíƒœ")
        if firebase_service.initialized:
            st.success("[OK] Firebase ì—°ê²°ë¨")
        else:
            st.warning("[WARNING] Firebase ë¯¸ì—°ê²°")

        st.divider()

        if st.button("[REFRESH] ìƒˆë¡œê³ ì¹¨"):
            st.rerun()

    # Main content tabs - ë‹¨ìˆœí™” (2ê°œ íƒ­ë§Œ)
    tab1, tab2 = st.tabs([
        "[DATA] ë°ì´í„° ì…ë ¥",
        "[SYSTEM] ì‹œìŠ¤í…œ ê´€ë¦¬"
    ])

    with tab1:
        data_input_tab()

    with tab2:
        system_management_tab()


def data_input_tab():
    """Data input tab for questions and concepts"""
    st.header("[DATA] ë°ì´í„° ì…ë ¥")

    # Create sub-tabs for input and data check
    data_tab1, data_tab2 = st.tabs(["[INPUT] ë°ì´í„° ì…ë ¥", "[CHECK] ë°ì´í„° í™•ì¸"])

    with data_tab1:
        input_type = st.selectbox("ì…ë ¥ íƒ€ì…", ["ë¬¸ì œ", "ê°œë…"])

        if input_type == "ë¬¸ì œ":
            question_input_form()
        else:
            concept_input_form()

    with data_tab2:
        chromadb_check_tab()


def question_input_form():
    """Form for inputting nursing/medical questions with image support"""
    st.subheader("[INFO] ë¬¸ì œ ì…ë ¥")

    # ë¶„ì•¼ ì„ íƒ (ê°„í˜¸/ì˜í•™)
    field = st.selectbox("ë¶„ì•¼ ì„ íƒ *", ["ê°„í˜¸", "ì˜í•™"])

    with st.form("question_form"):
        # Image upload section
        st.subheader("[IMAGE] ì´ë¯¸ì§€ ì—…ë¡œë“œ (ì„ íƒì‚¬í•­)")
        uploaded_image = st.file_uploader(
            "ë¬¸ì œ ê´€ë ¨ ì´ë¯¸ì§€",
            type=['png', 'jpg', 'jpeg'],
            help="ë¬¸ì œì™€ ê´€ë ¨ëœ ì˜ë£Œ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”"
        )

        image_analysis_result = None
        if uploaded_image is not None:
            # Display uploaded image
            col_img1, col_img2 = st.columns([1, 2])
            with col_img1:
                st.image(uploaded_image, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", width=200)

            with col_img2:
                analyze_on_save = st.checkbox("[ANALYSIS] ì´ë¯¸ì§€ ìë™ ë¶„ì„", value=True, key="question_analyze_image")
                if analyze_on_save:
                    st.info("[INFO] ì´ë¯¸ì§€ê°€ ì €ì¥ ì‹œ ìë™ ë¶„ì„ë©ë‹ˆë‹¤")

        st.divider()

        col1, col2 = st.columns([2, 1])

        with col1:
            question_text = st.text_area("ë¬¸ì œ", height=100, help="ê°„í˜¸ ë¬¸ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”")
            explanation = st.text_area("í•´ì„¤", height=80, help="ì •ë‹µ í•´ì„¤ì„ ì…ë ¥í•˜ì„¸ìš”")

        with col2:
            # ë¶„ì•¼ì— ë”°ë¼ ê³¼ëª© ëª©ë¡ ë³€ê²½
            if field == "ê°„í˜¸":
                subject = st.selectbox("ê³¼ëª©", [
                    "ê¸°ë³¸ê°„í˜¸í•™", "ì„±ì¸ê°„í˜¸í•™", "ì•„ë™ê°„í˜¸í•™", "ëª¨ì„±ê°„í˜¸í•™",
                    "ì •ì‹ ê°„í˜¸í•™", "ì§€ì—­ì‚¬íšŒê°„í˜¸í•™", "ê°„í˜¸ê´€ë¦¬í•™"
                ])
            else:  # ì˜í•™
                subject = st.selectbox("ê³¼ëª©", [
                    "í•´ë¶€í•™", "ìƒë¦¬í•™", "ë³‘ë¦¬í•™", "ì•½ë¦¬í•™",
                    "ë‚´ê³¼í•™", "ì™¸ê³¼í•™", "ì†Œì•„ê³¼í•™", "ì‚°ë¶€ì¸ê³¼í•™", "ì •ì‹ ì˜í•™"
                ])
            tags = st.text_input("íƒœê·¸", help="ì‰¼í‘œë¡œ êµ¬ë¶„ (ì„ íƒì‚¬í•­)")

        # Choices
        st.subheader("ì„ íƒì§€ (í•„ìˆ˜ 5ê°œ)")
        choices = []
        for i in range(1, 6):
            choice = st.text_input(f"ì„ íƒì§€ {i} *", key=f"choice_{i}", help="í•„ìˆ˜ ì…ë ¥")
            choices.append(choice)

        # Filter out empty choices for validation
        non_empty_choices = [c for c in choices if c.strip()]

        # Always show all 5 number options for answer selection
        st.subheader("ì •ë‹µ ì„ íƒ")
        answer_options = ["1ë²ˆ", "2ë²ˆ", "3ë²ˆ", "4ë²ˆ", "5ë²ˆ"]
        correct_answer_number = st.selectbox("ì •ë‹µ", answer_options)

        # Get the actual answer based on selection
        if correct_answer_number:
            answer_index = int(correct_answer_number.replace("ë²ˆ", "")) - 1
            if answer_index < len(choices) and choices[answer_index].strip():
                correct_answer = choices[answer_index]
            else:
                correct_answer = ""
        else:
            correct_answer = ""

        submitted = st.form_submit_button("[SAVE] ë¬¸ì œ ì €ì¥")

        if submitted:
            # Validate all 5 choices are filled
            if question_text and len(non_empty_choices) == 5 and correct_answer and correct_answer != "ì„ íƒì§€ë¥¼ ë¨¼ì € ì…ë ¥í•˜ì„¸ìš”":
                # ì„ íƒì§€ ì¤‘ë³µ ì²´í¬
                if len(set(non_empty_choices)) != len(non_empty_choices):
                    st.error("[ERROR] ì¤‘ë³µëœ ì„ íƒì§€ê°€ ìˆìŠµë‹ˆë‹¤! ëª¨ë“  ì„ íƒì§€ëŠ” ì„œë¡œ ë‹¬ë¼ì•¼ í•©ë‹ˆë‹¤.")
                else:
                    try:
                        # ë¬¸ì œ ì¤‘ë³µ ì²´í¬ë¥¼ ìœ„í•´ ChromaDBì—ì„œ ê²€ìƒ‰
                        from rag_engine_multi_domain import multi_domain_rag_engine

                        # ë¬¸ì œ í…ìŠ¤íŠ¸ë¡œ ìœ ì‚¬í•œ ë¬¸ì œ ê²€ìƒ‰
                        if field == "ê°„í˜¸":
                            collection_name = 'nursing_questions'
                        else:  # ì˜í•™
                            collection_name = 'medical_problems'

                        try:
                            collection = multi_domain_rag_engine.chroma_client.get_collection(collection_name)

                            # ì •í™•íˆ ê°™ì€ ë¬¸ì œ í…ìŠ¤íŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸
                            results = collection.query(
                                query_texts=[question_text],
                                n_results=1,
                                where={"type": "problem"}
                            )

                            # ê³ ê¸‰ ì¤‘ë³µ ì œê±° íŒŒì´í”„ë¼ì¸ ì‚¬ìš©
                            if results['documents'] and results['documents'][0]:
                                # ë¬¸ì„œ í˜•íƒœë¡œ ì¤€ë¹„
                                existing_docs = []
                                for i, doc_text in enumerate(results['documents'][0]):
                                    if doc_text:  # Noneì´ ì•„ë‹Œ ê²½ìš°ë§Œ
                                        existing_docs.append({
                                            'id': results['ids'][0][i] if results['ids'] and results['ids'][0] else str(i),
                                            'text': doc_text,
                                            'meta': results['metadatas'][0][i] if results['metadatas'] and results['metadatas'][0] else {}
                                        })

                                # í˜„ì¬ ë¬¸ì œë„ ë¬¸ì„œë¡œ ì¶”ê°€
                                existing_docs.append({
                                    'id': 'new_question',
                                    'text': question_text,
                                    'meta': {'type': 'new'}
                                })

                                # ì˜ë£Œ ë„ë©”ì¸ìœ¼ë¡œ ì¤‘ë³µ ì œê±° ì‹¤í–‰
                                unique_ids, duplicate_pairs = deduplication_engine.deduplicate(
                                    existing_docs,
                                    domain='medical',
                                    return_pairs=True
                                )

                                # new_questionì´ ì¤‘ë³µìœ¼ë¡œ íŒì •ë˜ì—ˆëŠ”ì§€ í™•ì¸
                                is_duplicate = False
                                if duplicate_pairs:
                                    for pair in duplicate_pairs:
                                        if pair.doc2_id == 'new_question' or pair.doc1_id == 'new_question':
                                            is_duplicate = True
                                            # ì¤‘ë³µëœ ê¸°ì¡´ ë¬¸ì œ ì°¾ê¸°
                                            existing_id = pair.doc1_id if pair.doc2_id == 'new_question' else pair.doc2_id
                                            for doc in existing_docs:
                                                if doc['id'] == existing_id:
                                                    st.error(f"[ERROR] ì¤‘ë³µëœ ë¬¸ì œê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤!")
                                                    st.warning(f"ê¸°ì¡´ ë¬¸ì œ: {doc['text'][:100]}...")
                                                    st.info(f"ìœ ì‚¬ë„ ì ìˆ˜: {pair.combined_score:.3f} (ì½”ì‚¬ì¸: {pair.cos_sim:.3f}, ìì¹´ë“œ: {pair.jaccard_score:.3f})")
                                                    break
                                            break

                                if is_duplicate:
                                    return  # ì¤‘ë³µì´ë©´ ì €ì¥í•˜ì§€ ì•ŠìŒ
                        except Exception as e:
                            # ì»¬ë ‰ì…˜ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±ë  ê²ƒì´ë¯€ë¡œ ì¤‘ë³µ ì²´í¬ ìŠ¤í‚µ
                            pass

                        question_data = {
                            'id': str(uuid.uuid4()),
                            'questionText': question_text,
                            'choices': non_empty_choices,
                            'correctAnswer': correct_answer,
                            'explanation': explanation,
                            'subject': subject,
                            'difficulty': 'ë¯¸ë¶„ë¥˜',
                            'tags': [tag.strip() for tag in tags.split(',') if tag.strip()],
                            'createdBy': 'streamlit_user',
                            'createdAt': datetime.now().isoformat(),
                            'status': 'pending_analysis',
                            'hasImage': uploaded_image is not None,
                            'imageAnalysis': None
                        }

                        # Process image if uploaded
                        if uploaded_image is not None:
                            try:
                                # Save image
                                image_dir = Path("storage/images")
                                image_dir.mkdir(parents=True, exist_ok=True)

                                image_filename = f"question_{question_data['id']}.{uploaded_image.name.split('.')[-1]}"
                                image_path = image_dir / image_filename

                                with open(image_path, "wb") as f:
                                    f.write(uploaded_image.getbuffer())

                                question_data['imagePath'] = str(image_path)

                                # Analyze image if checkbox was checked
                                if analyze_on_save:
                                    with st.spinner("[ANALYSIS] ì´ë¯¸ì§€ ë¶„ì„ ì¤‘..."):
                                        # Use hierarchical analyzer
                                        image = Image.open(uploaded_image)
                                        analyzer = ImageHierarchicalAnalyzer()

                                        analysis_result = analyzer.analyze_with_escalation(
                                            image=image,
                                            domain="medical",
                                            analyze_depth="standard"
                                        )

                                        question_data['imageAnalysis'] = {
                                            'main_objects': analysis_result.main_objects,
                                            'medical_tags': analysis_result.medical_tags,
                                            'description': analysis_result.description,
                                            'confidence': analysis_result.confidence_score,
                                            'analyzed_by': analysis_result.analyzed_by
                                        }

                                        st.success("[SUCCESS] ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ!")
                            except Exception as e:
                                st.warning(f"[WARNING] ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

                        # AI ë¶„ì„ ìë™ ì‹¤í–‰
                        with st.spinner("[ANALYSIS] AIê°€ ë¬¸ì œë¥¼ ë¶„ì„ ì¤‘..."):
                            try:
                                # ProblemAnalyzerì˜ process_problem ë©”ì„œë“œ í˜¸ì¶œ
                                analysis_result = problem_analyzer.process_problem(
                                    question_text=question_text,
                                    choices=non_empty_choices,
                                    correct_answer=correct_answer,
                                    explanation=explanation,
                                    subject=subject
                                )

                                # ë¶„ì„ ê²°ê³¼ë¥¼ ë¬¸ì œ ë°ì´í„°ì— ì¶”ê°€
                                question_data['analysis'] = {
                                    'concepts': analysis_result.get('concepts', []),
                                    'keywords': analysis_result.get('keywords', []),
                                    'difficulty': analysis_result.get('difficulty', 'ë³´í†µ'),
                                    'confidence_score': 0.85,
                                    'verified_by': 'hierarchical_analyzer',
                                    'processed_at': datetime.now().isoformat()
                                }
                                question_data['status'] = 'analysis_completed'

                                st.success("[SUCCESS] AI ë¶„ì„ ì™„ë£Œ!")

                                # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                                with st.expander("[RESULT] ë¶„ì„ ê²°ê³¼", expanded=True):
                                    col1, col2 = st.columns(2)
                                    with col1:
                                        st.write("**ê°œë…:**", ', '.join(analysis_result.get('concepts', [])))
                                        st.write("**í‚¤ì›Œë“œ:**", ', '.join(analysis_result.get('keywords', [])))
                                    with col2:
                                        st.write("**ë‚œì´ë„:**", analysis_result.get('difficulty', 'ë³´í†µ'))
                                        st.write("**ì‹ ë¢°ë„:**", f"{0.85:.1%}")
                            except Exception as e:
                                st.error(f"[ERROR] AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
                                question_data['status'] = 'analysis_failed'

                        # ChromaDBì— ìë™ ì €ì¥
                        with st.spinner("[SAVE] ChromaDBì— ì €ì¥ ì¤‘..."):
                            try:
                                from rag_engine_multi_domain import multi_domain_rag_engine

                                # nursing_questions ì»¬ë ‰ì…˜ì— ì¶”ê°€
                                collection = multi_domain_rag_engine.chroma_client.get_or_create_collection('nursing_questions')

                                # Create full document with all question data
                                full_document = f"""
ë¬¸ì œ: {question_data['questionText']}
ì„ íƒì§€:
1. {question_data.get('choices', ['', '', '', '', ''])[0]}
2. {question_data.get('choices', ['', '', '', '', ''])[1]}
3. {question_data.get('choices', ['', '', '', '', ''])[2]}
4. {question_data.get('choices', ['', '', '', '', ''])[3]}
5. {question_data.get('choices', ['', '', '', '', ''])[4]}
ì •ë‹µ: {question_data.get('correctAnswer', '')}
í•´ì„¤: {question_data.get('explanation', '')}
"""

                                # Store complete metadata including choices
                                collection.add(
                                ids=[question_data['id']],
                                documents=[full_document],
                                metadatas=[{
                                    'questionText': question_data['questionText'],
                                    'choice1': question_data.get('choices', ['', '', '', '', ''])[0],
                                    'choice2': question_data.get('choices', ['', '', '', '', ''])[1],
                                    'choice3': question_data.get('choices', ['', '', '', '', ''])[2],
                                    'choice4': question_data.get('choices', ['', '', '', '', ''])[3],
                                    'choice5': question_data.get('choices', ['', '', '', '', ''])[4],
                                    'correctAnswer': question_data.get('correctAnswer', ''),
                                    'explanation': question_data.get('explanation', ''),
                                    'subject': question_data.get('subject', 'ê°„í˜¸í•™'),
                                    'difficulty': question_data.get('analysis', {}).get('difficulty', 'ë³´í†µ'),
                                    'tags': ', '.join(question_data.get('analysis', {}).get('keywords', [])),
                                    'createdBy': 'streamlit_user',
                                    'createdAt': question_data.get('createdAt', '')
                                }]
                                )

                                st.success(f"[SUCCESS] ChromaDB ì €ì¥ ì™„ë£Œ!")
                            except Exception as e:
                                st.error(f"[ERROR] ChromaDB ì €ì¥ ì‹¤íŒ¨: {e}")

                        # Firebaseì— ìë™ ì—…ë¡œë“œ (ë¶„ì•¼ì— ë”°ë¼ ë‹¤ë¥¸ ì»¬ë ‰ì…˜ ì‚¬ìš©)
                        with st.spinner("[UPLOAD] Firebaseì— ì—…ë¡œë“œ ì¤‘..."):
                            try:
                                problem_data = {
                                'id': question_data.get('id'),
                                'questionText': question_data['questionText'],
                                'choices': question_data.get('choices', []),
                                'correctAnswer': question_data.get('correctAnswer', ''),
                                'subject': question_data.get('subject', 'ê°„í˜¸í•™'),
                                'difficulty': question_data.get('analysis', {}).get('difficulty', 'ë³´í†µ'),
                                'tags': question_data.get('analysis', {}).get('keywords', []),
                                'concepts': question_data.get('analysis', {}).get('concepts', []),
                                'explanation': question_data.get('explanation', ''),
                                'hasImage': question_data.get('hasImage', False),
                                'imageAnalysis': question_data.get('imageAnalysis'),
                                'createdAt': question_data.get('createdAt'),
                                'createdBy': question_data.get('createdBy', 'streamlit_user'),
                                'status': 'completed'
                            }

                                # ë¶„ì•¼ì— ë”°ë¼ ë‹¤ë¥¸ ì—…ë¡œë“œ ë©”ì„œë“œ ì‚¬ìš©
                                if field == "ê°„í˜¸":
                                    upload_result = firebase_service.upload_problem(problem_data)
                                else:  # ì˜í•™
                                    upload_result = firebase_service.upload_medical_problem(problem_data)

                                if upload_result and upload_result.get('success', False):
                                    st.success(f"[SUCCESS] Firebase ì—…ë¡œë“œ ì„±ê³µ! (ë¶„ì•¼: {field})")
                                else:
                                    st.warning("[WARNING] Firebase ì—…ë¡œë“œ ë¶€ë¶„ ì‹¤íŒ¨")
                            except Exception as e:
                                st.error(f"[ERROR] Firebase ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")

                        # Jobs/completed í´ë”ì— ì €ì¥
                        completed_path = Path("Jobs/completed")
                        completed_path.mkdir(parents=True, exist_ok=True)

                        completed_file = completed_path / f"problem_{question_data['id']}.json"
                        with open(completed_file, 'w', encoding='utf-8') as f:
                            json.dump(question_data, f, ensure_ascii=False, indent=2)

                        st.success(f"[SUCCESS] ë¬¸ì œ ì €ì¥ ì™„ë£Œ!")
                        st.info(f"[INFO] íŒŒì¼ ìœ„ì¹˜: {completed_file}")

                    except Exception as e:
                        st.error(f"[ERROR] ì €ì¥ ì‹¤íŒ¨: {e}")
            else:
                missing = []
                if not question_text:
                    missing.append("ë¬¸ì œ")
                if len(non_empty_choices) != 5:
                    missing.append(f"ì„ íƒì§€ (í˜„ì¬ {len(non_empty_choices)}/5)")
                if not correct_answer or correct_answer == "ì„ íƒì§€ë¥¼ ë¨¼ì € ì…ë ¥í•˜ì„¸ìš”":
                    missing.append("ì •ë‹µ")
                st.warning(f"[WARNING] ë‹¤ìŒ í•„ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”: {', '.join(missing)}")


def concept_input_form():
    """Form for inputting medical concepts"""
    st.subheader("[INFO] ì˜í•™ ê°œë… ì…ë ¥")

    with st.form("concept_form"):
        description = st.text_area(
            "ê°œë… ì„¤ëª… *",
            height=200,
            help="ê°œë…ì— ëŒ€í•œ ìƒì„¸í•œ ì„¤ëª…ì„ ì…ë ¥í•˜ì„¸ìš”"
        )

        tags = st.text_input("íƒœê·¸", help="ì‰¼í‘œë¡œ êµ¬ë¶„ (ì„ íƒì‚¬í•­)")

        submitted = st.form_submit_button("[SAVE] ê°œë… ì €ì¥")

        if submitted:
            if description:
                try:
                    concept_data = {
                        'id': str(uuid.uuid4()),
                        'title': description[:50] + '...' if len(description) > 50 else description,  # ì„¤ëª… ì•ë¶€ë¶„ì„ ì œëª©ìœ¼ë¡œ ì‚¬ìš©
                        'description': description,
                        'tags': [tag.strip() for tag in tags.split(',') if tag.strip()],
                        'createdAt': datetime.now().isoformat(),
                        'createdBy': 'streamlit_user'
                    }

                    # AI ë¶„ì„
                    with st.spinner("[ANALYSIS] AIê°€ ê°œë…ì„ ë¶„ì„ ì¤‘..."):
                        try:
                            analyzed = gemini_service.analyze_concept(description)
                            concept_data.update({
                                'keywords': analyzed.get('keywords', []),
                                'category': analyzed.get('category', ''),
                                'detailed_explanation': analyzed.get('detailed_explanation', description)
                            })
                            st.success("[SUCCESS] AI ë¶„ì„ ì™„ë£Œ!")
                        except Exception as e:
                            st.warning(f"[WARNING] AI ë¶„ì„ ì‹¤íŒ¨: {e}")

                    # ChromaDBì— ì €ì¥
                    with st.spinner("[SAVE] ChromaDBì— ì €ì¥ ì¤‘..."):
                        try:
                            from rag_engine_multi_domain import multi_domain_rag_engine

                            # ëª¨ë“  ê°œë…ì€ medical_concepts ì»¬ë ‰ì…˜ì— ì €ì¥
                            collection_name = 'medical_concepts'
                            collection = multi_domain_rag_engine.chroma_client.get_or_create_collection(collection_name)

                            # Create full document with complete concept data
                            full_document = f"""
ì„¤ëª…: {concept_data.get('description', '')}
ìƒì„¸ ì„¤ëª…: {concept_data.get('detailed_explanation', '')}
ì¹´í…Œê³ ë¦¬: {concept_data.get('category', '')}
í‚¤ì›Œë“œ: {', '.join(concept_data.get('keywords', []))}
íƒœê·¸: {', '.join(concept_data.get('tags', []))}
"""

                            # Store complete metadata
                            collection.add(
                                ids=[concept_data['id']],
                                documents=[full_document],
                                metadatas=[{
                                    'title': concept_data['title'],
                                    'description': concept_data['description'][:500] if len(concept_data['description']) > 500 else concept_data['description'],
                                    'category': concept_data.get('category', ''),
                                    'keywords': ', '.join(concept_data.get('keywords', [])),
                                    'tags': ', '.join(concept_data.get('tags', [])),
                                    'createdBy': concept_data['createdBy'],
                                    'createdAt': concept_data['createdAt']
                                }]
                            )

                            st.success(f"[SUCCESS] ChromaDB ì €ì¥ ì™„ë£Œ! (ì»¬ë ‰ì…˜: {collection_name})")
                        except Exception as e:
                            st.error(f"[ERROR] ChromaDB ì €ì¥ ì‹¤íŒ¨: {e}")

                    # Firebaseì— ì—…ë¡œë“œ
                    with st.spinner("[UPLOAD] Firebaseì— ì—…ë¡œë“œ ì¤‘..."):
                        try:
                            upload_result = firebase_service.upload_concept(concept_data)
                            if upload_result.get('success'):
                                st.success(f"[SUCCESS] Firebase ì—…ë¡œë“œ ì„±ê³µ!")
                        except Exception as e:
                            st.error(f"[ERROR] Firebase ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")

                    st.success("[SUCCESS] ê°œë… ì €ì¥ ì™„ë£Œ!")

                except Exception as e:
                    st.error(f"[ERROR] ì €ì¥ ì‹¤íŒ¨: {e}")
            else:
                st.warning("[WARNING] ê°œë… ì„¤ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”")


def system_management_tab():
    """System management and settings tab"""
    st.header("[SYSTEM] ì‹œìŠ¤í…œ ê´€ë¦¬")

    # Create subtabs for system management
    mgmt_tab1, mgmt_tab2 = st.tabs(["[SETTINGS] ì‹œìŠ¤í…œ ì„¤ì •", "[API] API ì‚¬ìš©ëŸ‰"])

    with mgmt_tab1:
        st.subheader("[SETTINGS] ì‹œìŠ¤í…œ ì„¤ì •")

        col1, col2 = st.columns(2)

        with col1:
            st.info("[PATH] Jobs ë””ë ‰í„°ë¦¬")
            st.code(str(JOBS_DIR))

            st.info("[PATH] ChromaDB ê²½ë¡œ")
            st.code("database/chroma_db/")

        with col2:
            st.info("[MODEL] AI ëª¨ë¸ ì„¤ì •")
            st.code("Embedding: text-embedding-004")
            st.code("Primary: GPT-5 Mini")
            st.code("Advanced: GPT-5")

        # Environment check
        st.subheader("[CHECK] í™˜ê²½ í™•ì¸")

        try:
            validate_config()
            st.success("[OK] ëª¨ë“  ì„¤ì •ì´ ì˜¬ë°”ë¦…ë‹ˆë‹¤")
        except Exception as e:
            st.error(f"[ERROR] ì„¤ì • ì˜¤ë¥˜: {e}")

    with mgmt_tab2:
        st.subheader("[API] API ì‚¬ìš©ëŸ‰ ì¶”ì ")

        # API Usage Overview
        st.info("[INFO] OpenAI ë° Gemini API ì‚¬ìš©ëŸ‰ ë° ë¹„ìš© ì¶”ì ")

        # Time period selection
        period = st.selectbox("ê¸°ê°„ ì„ íƒ", ["ì˜¤ëŠ˜", "ì´ë²ˆ ì£¼", "ì´ë²ˆ ë‹¬"])

        try:
            # Get usage data based on period
            if period == "ì˜¤ëŠ˜":
                usage_data = api_tracker.get_daily_usage()
                st.subheader(f"[TODAY] ì˜¤ëŠ˜ ì‚¬ìš©ëŸ‰ ({datetime.now().strftime('%Y-%m-%d')})")
            elif period == "ì´ë²ˆ ì£¼":
                usage_data = api_tracker.get_weekly_usage()
                st.subheader("[WEEK] ìµœê·¼ 7ì¼ ì‚¬ìš©ëŸ‰")
            else:  # ì´ë²ˆ ë‹¬
                now = datetime.now()
                usage_data = api_tracker.get_monthly_usage(now.year, now.month)
                st.subheader(f"[MONTH] {now.year}ë…„ {now.month}ì›” ì‚¬ìš©ëŸ‰")

            # Display metrics
            col1, col2, col3 = st.columns(3)

            total_cost = usage_data.get('total_cost', 0) if usage_data else 0
            total_tokens = usage_data.get('total_tokens', 0) if usage_data else 0

            with col1:
                st.metric("ì´ í† í° ì‚¬ìš©ëŸ‰", f"{total_tokens:,}")
            with col2:
                st.metric("ì´ ë¹„ìš©", f"${total_cost:.4f}")
            with col3:
                st.metric("ì›í™” í™˜ì‚° (1,400ì›/$)", f"â‚©{total_cost * 1400:.0f}")

            # Model-wise breakdown
            if usage_data and usage_data.get('by_model'):
                st.subheader("[MODEL] ëª¨ë¸ë³„ ì‚¬ìš©ëŸ‰")

                model_data = []
                for model, stats in usage_data['by_model'].items():
                    model_data.append({
                        'ëª¨ë¸': model,
                        'ì…ë ¥ í† í°': f"{stats.get('input_tokens', 0):,}",
                        'ì¶œë ¥ í† í°': f"{stats.get('output_tokens', 0):,}",
                        'ìš”ì²­ íšŸìˆ˜': stats.get('requests', 0),
                        'ë¹„ìš© (USD)': f"${stats.get('cost', 0):.4f}"
                    })

                if model_data:
                    model_df = pd.DataFrame(model_data)
                    st.dataframe(model_df, use_container_width=True)
            else:
                st.info("[INFO] í•´ë‹¹ ê¸°ê°„ì˜ ì‚¬ìš© ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤")

        except Exception as e:
            st.error(f"[ERROR] API ì‚¬ìš©ëŸ‰ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            st.info("[INFO] api_usage_trackerê°€ ì œëŒ€ë¡œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")

        # Model pricing reference
        with st.expander("[PRICE] ëª¨ë¸ë³„ ê°€ê²©í‘œ"):
            pricing_data = [
                {'ëª¨ë¸': 'GPT-5', 'ì…ë ¥ (1M tokens)': '$1.25', 'ì¶œë ¥ (1M tokens)': '$10.00'},
                {'ëª¨ë¸': 'GPT-5 Mini', 'ì…ë ¥ (1M tokens)': '$0.65', 'ì¶œë ¥ (1M tokens)': '$5.00'},
                {'ëª¨ë¸': 'GPT-5 Nano', 'ì…ë ¥ (1M tokens)': '$0.40', 'ì¶œë ¥ (1M tokens)': '$2.50'},
                {'ëª¨ë¸': 'Gemini 2.5 Pro', 'ì…ë ¥ (1M tokens)': '$1.25', 'ì¶œë ¥ (1M tokens)': '$10.00'},
                {'ëª¨ë¸': 'Gemini 2.5 Flash', 'ì…ë ¥ (1M tokens)': '$0.10', 'ì¶œë ¥ (1M tokens)': '$0.40'},
            ]
            pricing_df = pd.DataFrame(pricing_data)
            st.dataframe(pricing_df, use_container_width=True)


def chromadb_check_tab():
    """ChromaDB data check tab with deletion capability"""
    st.subheader("[CHECK] ChromaDB ë°ì´í„° í™•ì¸ ë° ê´€ë¦¬")

    # Collection selection
    collection_name = st.selectbox(
        "ì»¬ë ‰ì…˜ ì„ íƒ",
        ["nursing_questions", "nursing_concepts", "medical_concepts"]
    )

    # Store data in session state
    if 'chromadb_data' not in st.session_state:
        st.session_state.chromadb_data = None
        st.session_state.chromadb_ids = []

    # Get collection data
    col1, col2, col3 = st.columns([1, 1, 2])
    with col1:
        if st.button("[LOAD] ë°ì´í„° ì¡°íšŒ"):
            try:
                from rag_engine_multi_domain import multi_domain_rag_engine

                # Get or create collection
                collection = multi_domain_rag_engine.chroma_client.get_or_create_collection(collection_name)

                # Get all data
                results = collection.get()

                if results and results['ids']:
                    st.success(f"[SUCCESS] {len(results['ids'])}ê°œ ë°ì´í„° ë°œê²¬")

                    # Store full IDs for deletion
                    st.session_state.chromadb_ids = results['ids']

                    # Create DataFrame for display
                    data_list = []
                    for i, doc_id in enumerate(results['ids']):
                        metadata = results['metadatas'][i] if i < len(results['metadatas']) else {}
                        document = results['documents'][i] if i < len(results['documents']) else ""

                        # Extract full question data from document and metadata
                        question_display = metadata.get('questionText', metadata.get('title', ''))
                        if not question_display and document:
                            # Try to extract from document if not in metadata
                            question_display = document.split('\n')[0].replace('ë¬¸ì œ: ', '')[:100]

                        data_list.append({
                            'Index': i,
                            'ID': doc_id[:8] + '...',  # Display shortened ID
                            'ë¬¸ì œ': question_display[:80] + '...' if len(question_display) > 80 else question_display,
                            'ê³¼ëª©': metadata.get('subject', 'N/A'),
                            'ë‚œì´ë„': metadata.get('difficulty', 'N/A'),
                            'íƒœê·¸': metadata.get('tags', 'N/A'),
                            'ì •ë‹µ': metadata.get('correctAnswer', 'N/A')[:50],
                            'ì„ íƒì§€1': metadata.get('choice1', 'N/A')[:30],
                            'ì„ íƒì§€2': metadata.get('choice2', 'N/A')[:30],
                            'ì„ íƒì§€3': metadata.get('choice3', 'N/A')[:30],
                            'ì„ íƒì§€4': metadata.get('choice4', 'N/A')[:30],
                            'ì„ íƒì§€5': metadata.get('choice5', 'N/A')[:30]
                        })

                    st.session_state.chromadb_data = pd.DataFrame(data_list)
                else:
                    st.info(f"[INFO] {collection_name} ì»¬ë ‰ì…˜ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                    st.session_state.chromadb_data = None
                    st.session_state.chromadb_ids = []

            except Exception as e:
                st.error(f"[ERROR] ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")

    with col2:
        # Delete all button
        if st.button("[DELETE ALL] ì „ì²´ ì‚­ì œ", type="secondary"):
            if st.session_state.chromadb_ids:
                try:
                    from rag_engine_multi_domain import multi_domain_rag_engine
                    collection = multi_domain_rag_engine.chroma_client.get_or_create_collection(collection_name)

                    # Delete all documents
                    collection.delete(ids=st.session_state.chromadb_ids)
                    st.success(f"[SUCCESS] {len(st.session_state.chromadb_ids)}ê°œ ë°ì´í„° ì‚­ì œ ì™„ë£Œ!")

                    # Clear session state
                    st.session_state.chromadb_data = None
                    st.session_state.chromadb_ids = []
                    st.rerun()

                except Exception as e:
                    st.error(f"[ERROR] ì „ì²´ ì‚­ì œ ì‹¤íŒ¨: {e}")
            else:
                st.warning("[WARNING] ì‚­ì œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì¡°íšŒí•˜ì„¸ìš”.")

    # Display data if available
    if st.session_state.chromadb_data is not None:
        st.divider()

        # Show data table
        st.dataframe(st.session_state.chromadb_data, use_container_width=True)

        # Export option
        csv = st.session_state.chromadb_data.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="[EXPORT] CSVë¡œ ë‹¤ìš´ë¡œë“œ",
            data=csv,
            file_name=f"{collection_name}_data.csv",
            mime="text/csv"
        )

        # Individual deletion
        st.divider()
        st.subheader("[DELETE] ê°œë³„ ë°ì´í„° ì‚­ì œ")

        # Select items to delete
        indices_to_delete = st.multiselect(
            "ì‚­ì œí•  í•­ëª© ì„ íƒ (Index ë²ˆí˜¸)",
            options=st.session_state.chromadb_data['Index'].tolist(),
            format_func=lambda x: f"Index {x}: {st.session_state.chromadb_data.iloc[x]['ë¬¸ì œ'][:50] if 'ë¬¸ì œ' in st.session_state.chromadb_data.columns else st.session_state.chromadb_data.iloc[x].get('ì œëª©/ì§ˆë¬¸', 'N/A')[:50]}..."
        )

        if st.button("[DELETE SELECTED] ì„ íƒ í•­ëª© ì‚­ì œ"):
            if indices_to_delete:
                try:
                    from rag_engine_multi_domain import multi_domain_rag_engine
                    collection = multi_domain_rag_engine.chroma_client.get_or_create_collection(collection_name)

                    # Get IDs to delete
                    ids_to_delete = [st.session_state.chromadb_ids[i] for i in indices_to_delete]

                    # Delete selected documents
                    collection.delete(ids=ids_to_delete)
                    st.success(f"[SUCCESS] {len(ids_to_delete)}ê°œ í•­ëª© ì‚­ì œ ì™„ë£Œ!")

                    # Clear session state to refresh
                    st.session_state.chromadb_data = None
                    st.session_state.chromadb_ids = []
                    st.rerun()

                except Exception as e:
                    st.error(f"[ERROR] ì„ íƒ í•­ëª© ì‚­ì œ ì‹¤íŒ¨: {e}")
            else:
                st.warning("[WARNING] ì‚­ì œí•  í•­ëª©ì„ ì„ íƒí•˜ì„¸ìš”.")

    # Collection statistics
    st.divider()
    st.subheader("[STATS] ì»¬ë ‰ì…˜ í†µê³„")

    try:
        stats_data = []

        for coll_name in ["nursing_questions", "nursing_concepts", "medical_concepts"]:
            try:
                collection = multi_domain_rag_engine.chroma_client.get_or_create_collection(coll_name)
                count = collection.count()
                stats_data.append({
                    'ì»¬ë ‰ì…˜': coll_name,
                    'ë°ì´í„° ìˆ˜': count,
                    'ìƒíƒœ': '[ACTIVE]' if count > 0 else '[EMPTY]'
                })
            except:
                stats_data.append({
                    'ì»¬ë ‰ì…˜': coll_name,
                    'ë°ì´í„° ìˆ˜': 0,
                    'ìƒíƒœ': '[ERROR]'
                })

        stats_df = pd.DataFrame(stats_data)
        st.dataframe(stats_df, use_container_width=True)

    except Exception as e:
        st.error(f"[ERROR] í†µê³„ ë¡œë“œ ì‹¤íŒ¨: {e}")


if __name__ == "__main__":
    main()