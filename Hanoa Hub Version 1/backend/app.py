"""
Hanoa RAG System - Streamlit Main Application (Simplified Version)
"""
import json
import os
import uuid
from datetime import datetime
from pathlib import Path

import streamlit as st
import pandas as pd

from config import (
    validate_config, JOBS_DIR, OBSIDIAN_VAULT_PATH,
    DOMAIN_COLLECTIONS, DEFAULT_DOMAIN, ENABLE_CROSS_DOMAIN_SEARCH,
    ENABLE_IMAGE_VECTORS, GEMINI_API_KEY, OPENAI_API_KEY,
    MAX_IMAGE_SIZE_MB
)
from rag_engine import rag_engine
from rag_engine_multi_domain import multi_domain_rag_engine
from jobs_worker import jobs_worker
from analyzers.problem_analyzer import problem_analyzer
from models.problem_schema import ProblemData, create_sample_problems
from api_usage_tracker import api_tracker
from services.firebase_service import firebase_service
from services.gemini_service import gemini_service
from analyzers.image_hierarchical_analyzer import ImageHierarchicalAnalyzer
from deduplication_engine import deduplication_engine
from PIL import Image
import io
import os
import hashlib
import base64
import asyncio
from ai_batch_generator import BatchQuestionGenerator
from question_types import QuestionType

# Page configuration
st.set_page_config(
    page_title="Hanoa RAG System",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded"
)

def main():
    """Main Streamlit application"""

    # Initialize session state
    if 'initialized' not in st.session_state:
        try:
            validate_config()
            st.session_state.initialized = True
        except Exception as e:
            st.error(f"Configuration error: {e}")
            st.stop()

    # Header
    st.title("ğŸ“š Hanoa RAG System")
    st.markdown("ê°„í˜¸í•™/ì˜í•™ ë¬¸ì œ ë° ê°œë… ê´€ë¦¬ ì‹œìŠ¤í…œ")

    # Sidebar - System Status
    with st.sidebar:
        st.header("[STATUS] ì‹œìŠ¤í…œ ìƒíƒœ")

        # RAG Stats
        try:
            stats = rag_engine.get_stats()
            st.metric("ì´ ë¬¸ì œ", stats['questions'])
            st.metric("ì „ì²´ ë°ì´í„°", stats['total'])
        except Exception as e:
            st.error(f"[ERROR] RAG ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")

        # Firebase Status
        st.divider()
        st.subheader("[FIREBASE] ì—°ê²° ìƒíƒœ")
        if firebase_service.initialized:
            st.success("[OK] Firebase ì—°ê²°ë¨")
        else:
            st.warning("[WARNING] Firebase ë¯¸ì—°ê²°")

        st.divider()

        if st.button("[REFRESH] ìƒˆë¡œê³ ì¹¨"):
            st.rerun()

    # Main content tabs - 3ê°œ íƒ­
    tab1, tab2, tab3 = st.tabs([
        "[DATA] ë°ì´í„° ì…ë ¥",
        "[AI] AI ë¬¸ì œ ìƒì„±",
        "[SYSTEM] ì‹œìŠ¤í…œ ê´€ë¦¬"
    ])

    with tab1:
        data_input_tab()

    with tab2:
        ai_generation_tab()

    with tab3:
        system_management_tab()


def data_input_tab():
    """Data input tab for questions and concepts"""
    st.header("[DATA] ë°ì´í„° ì…ë ¥")

    # Create sub-tabs for input and data check
    data_tab1, data_tab2 = st.tabs(["[INPUT] ë°ì´í„° ì…ë ¥", "[CHECK] ë°ì´í„° í™•ì¸"])

    with data_tab1:
        input_type = st.selectbox("ì…ë ¥ íƒ€ì…", ["ë¬¸ì œ", "ê°œë…"])

        if input_type == "ë¬¸ì œ":
            question_input_form()
        else:
            concept_input_form()

    with data_tab2:
        chromadb_check_tab()


def question_input_form():
    """Form for inputting nursing/medical questions with image support"""
    st.subheader("[INFO] ë¬¸ì œ ì…ë ¥")

    # ë¶„ì•¼ ì„ íƒ (ê°„í˜¸/ì˜í•™)
    field = st.selectbox("ë¶„ì•¼ ì„ íƒ *", ["ê°„í˜¸", "ì˜í•™"])

    with st.form("question_form"):
        # Image upload section
        st.subheader("[IMAGE] ì´ë¯¸ì§€ ì—…ë¡œë“œ (ì„ íƒì‚¬í•­)")
        uploaded_image = st.file_uploader(
            "ë¬¸ì œ ê´€ë ¨ ì´ë¯¸ì§€",
            type=['png', 'jpg', 'jpeg', 'webp'],
            help="ë¬¸ì œì™€ ê´€ë ¨ëœ ì˜ë£Œ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (PNG, JPG, JPEG, WebP ì§€ì›)"
        )

        image_analysis_result = None
        if uploaded_image is not None:
            # Display uploaded image
            col_img1, col_img2 = st.columns([1, 2])
            with col_img1:
                st.image(uploaded_image, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", width=200)

            with col_img2:
                analyze_on_save = st.checkbox("[ANALYSIS] ì´ë¯¸ì§€ ìë™ ë¶„ì„", value=True, key="question_analyze_image")
                if analyze_on_save:
                    st.info("[INFO] ì´ë¯¸ì§€ê°€ ì €ì¥ ì‹œ ìë™ ë¶„ì„ë©ë‹ˆë‹¤")

        st.divider()

        col1, col2 = st.columns([2, 1])

        with col1:
            question_text = st.text_area("ë¬¸ì œ", height=100, help="ê°„í˜¸ ë¬¸ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”")
            explanation = st.text_area("í•´ì„¤", height=80, help="ì •ë‹µ í•´ì„¤ì„ ì…ë ¥í•˜ì„¸ìš”")

        with col2:
            # ë¶„ì•¼ì— ë”°ë¼ ê³¼ëª© ëª©ë¡ ë³€ê²½
            if field == "ê°„í˜¸":
                subject = st.selectbox("ê³¼ëª©", [
                    "ê¸°ë³¸ê°„í˜¸í•™", "ì„±ì¸ê°„í˜¸í•™", "ì•„ë™ê°„í˜¸í•™", "ëª¨ì„±ê°„í˜¸í•™",
                    "ì •ì‹ ê°„í˜¸í•™", "ì§€ì—­ì‚¬íšŒê°„í˜¸í•™", "ê°„í˜¸ê´€ë¦¬í•™"
                ])
            else:  # ì˜í•™
                subject = st.selectbox("ê³¼ëª©", [
                    "í•´ë¶€í•™", "ìƒë¦¬í•™", "ë³‘ë¦¬í•™", "ì•½ë¦¬í•™",
                    "ë‚´ê³¼í•™", "ì™¸ê³¼í•™", "ì†Œì•„ê³¼í•™", "ì‚°ë¶€ì¸ê³¼í•™", "ì •ì‹ ì˜í•™"
                ])
            tags = st.text_input("íƒœê·¸", help="ì‰¼í‘œë¡œ êµ¬ë¶„ (ì„ íƒì‚¬í•­)")

        # Choices
        st.subheader("ì„ íƒì§€ (í•„ìˆ˜ 5ê°œ)")
        choices = []
        for i in range(1, 6):
            choice = st.text_input(f"ì„ íƒì§€ {i} *", key=f"choice_{i}", help="í•„ìˆ˜ ì…ë ¥")
            choices.append(choice)

        # Filter out empty choices for validation
        non_empty_choices = [c for c in choices if c.strip()]

        # Always show all 5 number options for answer selection
        st.subheader("ì •ë‹µ ì„ íƒ")
        answer_options = ["1ë²ˆ", "2ë²ˆ", "3ë²ˆ", "4ë²ˆ", "5ë²ˆ"]
        correct_answer_number = st.selectbox("ì •ë‹µ", answer_options)

        # Get the actual answer based on selection
        if correct_answer_number:
            answer_index = int(correct_answer_number.replace("ë²ˆ", "")) - 1
            if answer_index < len(choices) and choices[answer_index].strip():
                correct_answer = choices[answer_index]
            else:
                correct_answer = ""
        else:
            correct_answer = ""

        submitted = st.form_submit_button("[SAVE] ë¬¸ì œ ì €ì¥")

        if submitted:
            # Validate all 5 choices are filled
            if question_text and len(non_empty_choices) == 5 and correct_answer and correct_answer != "ì„ íƒì§€ë¥¼ ë¨¼ì € ì…ë ¥í•˜ì„¸ìš”":
                # ì„ íƒì§€ ì¤‘ë³µ ì²´í¬
                if len(set(non_empty_choices)) != len(non_empty_choices):
                    st.error("[ERROR] ì¤‘ë³µëœ ì„ íƒì§€ê°€ ìˆìŠµë‹ˆë‹¤! ëª¨ë“  ì„ íƒì§€ëŠ” ì„œë¡œ ë‹¬ë¼ì•¼ í•©ë‹ˆë‹¤.")
                else:
                    try:
                        # ë¬¸ì œ ì¤‘ë³µ ì²´í¬ë¥¼ ìœ„í•´ ChromaDBì—ì„œ ê²€ìƒ‰
                        from rag_engine_multi_domain import multi_domain_rag_engine

                        # ë¬¸ì œ í…ìŠ¤íŠ¸ë¡œ ìœ ì‚¬í•œ ë¬¸ì œ ê²€ìƒ‰
                        if field == "ê°„í˜¸":
                            collection_name = 'nursing_questions'
                        else:  # ì˜í•™
                            collection_name = 'medical_problems'

                        try:
                            collection = multi_domain_rag_engine.chroma_client.get_collection(collection_name)

                            # ì •í™•íˆ ê°™ì€ ë¬¸ì œ í…ìŠ¤íŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸
                            results = collection.query(
                                query_texts=[question_text],
                                n_results=1,
                                where={"type": "problem"}
                            )

                            # ê³ ê¸‰ ì¤‘ë³µ ì œê±° íŒŒì´í”„ë¼ì¸ ì‚¬ìš©
                            if results['documents'] and results['documents'][0]:
                                # ë¬¸ì„œ í˜•íƒœë¡œ ì¤€ë¹„
                                existing_docs = []
                                for i, doc_text in enumerate(results['documents'][0]):
                                    if doc_text:  # Noneì´ ì•„ë‹Œ ê²½ìš°ë§Œ
                                        existing_docs.append({
                                            'id': results['ids'][0][i] if results['ids'] and results['ids'][0] else str(i),
                                            'text': doc_text,
                                            'meta': results['metadatas'][0][i] if results['metadatas'] and results['metadatas'][0] else {}
                                        })

                                # í˜„ì¬ ë¬¸ì œë„ ë¬¸ì„œë¡œ ì¶”ê°€
                                existing_docs.append({
                                    'id': 'new_question',
                                    'text': question_text,
                                    'meta': {'type': 'new'}
                                })

                                # ì˜ë£Œ ë„ë©”ì¸ìœ¼ë¡œ ì¤‘ë³µ ì œê±° ì‹¤í–‰
                                unique_ids, duplicate_pairs = deduplication_engine.deduplicate(
                                    existing_docs,
                                    domain='medical',
                                    return_pairs=True
                                )

                                # new_questionì´ ì¤‘ë³µìœ¼ë¡œ íŒì •ë˜ì—ˆëŠ”ì§€ í™•ì¸
                                is_duplicate = False
                                if duplicate_pairs:
                                    for pair in duplicate_pairs:
                                        if pair.doc2_id == 'new_question' or pair.doc1_id == 'new_question':
                                            is_duplicate = True
                                            # ì¤‘ë³µëœ ê¸°ì¡´ ë¬¸ì œ ì°¾ê¸°
                                            existing_id = pair.doc1_id if pair.doc2_id == 'new_question' else pair.doc2_id
                                            for doc in existing_docs:
                                                if doc['id'] == existing_id:
                                                    st.error(f"[ERROR] ì¤‘ë³µëœ ë¬¸ì œê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤!")
                                                    st.warning(f"ê¸°ì¡´ ë¬¸ì œ: {doc['text'][:100]}...")
                                                    st.info(f"ìœ ì‚¬ë„ ì ìˆ˜: {pair.combined_score:.3f} (ì½”ì‚¬ì¸: {pair.cos_sim:.3f}, ìì¹´ë“œ: {pair.jaccard_score:.3f})")
                                                    break
                                            break

                                if is_duplicate:
                                    return  # ì¤‘ë³µì´ë©´ ì €ì¥í•˜ì§€ ì•ŠìŒ
                        except Exception as e:
                            # ì»¬ë ‰ì…˜ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±ë  ê²ƒì´ë¯€ë¡œ ì¤‘ë³µ ì²´í¬ ìŠ¤í‚µ
                            pass

                        question_data = {
                            'id': str(uuid.uuid4()),
                            'questionText': question_text,
                            'choices': non_empty_choices,
                            'correctAnswer': correct_answer,
                            'answer': answer_index if correct_answer else None,
                            'explanation': explanation,
                            'subject': subject,
                            'difficulty': 'ë¯¸ë¶„ë¥˜',
                            'tags': [tag.strip() for tag in tags.split(',') if tag.strip()],
                            'createdBy': 'streamlit_user',
                            'createdAt': datetime.now().isoformat(),
                            'status': 'pending_analysis',
                            'hasImage': uploaded_image is not None,
                            'imageAnalysis': None
                        }

                        # Process image if uploaded
                        if uploaded_image is not None:
                            try:
                                # Save image
                                image_dir = Path("storage/images")
                                image_dir.mkdir(parents=True, exist_ok=True)

                                image_filename = f"question_{question_data['id']}.{uploaded_image.name.split('.')[-1]}"
                                image_path = image_dir / image_filename

                                # í’ˆì§ˆ/ì¤‘ë³µ ê²€ì‚¬ (ìš©ëŸ‰, í•´ì‹œ)
                                try:
                                    img_bytes = uploaded_image.getvalue()
                                except Exception:
                                    img_bytes = uploaded_image.getbuffer()

                                try:
                                    size_bytes = len(img_bytes)
                                except Exception:
                                    size_bytes = uploaded_image.size if hasattr(uploaded_image, 'size') else 0

                                if MAX_IMAGE_SIZE_MB and size_bytes and size_bytes > MAX_IMAGE_SIZE_MB * 1024 * 1024:
                                    st.error(f"[ERROR] ì´ë¯¸ì§€ ìš©ëŸ‰ì´ {MAX_IMAGE_SIZE_MB}MBë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤.")
                                    st.stop()

                                image_hash = hashlib.sha256(bytes(img_bytes)).hexdigest()
                                question_data['imageHash'] = image_hash

                                # ë¡œì»¬ í•´ì‹œ ì¸ë±ìŠ¤ ì¤‘ë³µ ì²´í¬
                                hash_index_path = Path("database/image_hash_index.json")
                                hash_index_path.parent.mkdir(parents=True, exist_ok=True)
                                try:
                                    with open(hash_index_path, 'r', encoding='utf-8') as hf:
                                        hash_index = json.load(hf)
                                except Exception:
                                    hash_index = {}

                                if image_hash in hash_index:
                                    st.error("[ERROR] ë™ì¼í•œ ì´ë¯¸ì§€ê°€ ì´ë¯¸ ì—…ë¡œë“œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì €ì¥ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                                    st.info(f"[INFO] ê¸°ì¡´ ì´ë¯¸ì§€ URL: {hash_index.get(image_hash)}")
                                    st.stop()

                                with open(image_path, "wb") as f:
                                    f.write(uploaded_image.getbuffer())

                                question_data['imagePath'] = str(image_path)

                                # Firebase Storage ì—…ë¡œë“œ ë° URL ì„¤ì •
                                try:
                                    with open(image_path, 'rb') as img_file:
                                        image_url = firebase_service.upload_image_to_storage(
                                            image_data=img_file,
                                            path_prefix="problems/",
                                            filename=image_filename,
                                            use_webp=True
                                        )
                                    if image_url:
                                        question_data['hasImage'] = True
                                        question_data['imageUrl'] = image_url
                                        question_data['imageUrls'] = [image_url]
                                        # í•´ì‹œ ì¸ë±ìŠ¤ ì €ì¥
                                        try:
                                            hash_index[image_hash] = image_url
                                            with open(hash_index_path, 'w', encoding='utf-8') as hf:
                                                json.dump(hash_index, hf, ensure_ascii=False, indent=2)
                                        except Exception:
                                            pass
                                except Exception as e:
                                    pass

                                # Analyze image if checkbox was checked
                                if analyze_on_save:
                                    with st.spinner("[ANALYSIS] ì´ë¯¸ì§€ ë¶„ì„ ì¤‘..."):
                                        # Use hierarchical analyzer
                                        image = Image.open(uploaded_image)
                                        analyzer = ImageHierarchicalAnalyzer()

                                        # ì´ë¯¸ì§€ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                                        temp_image_path = f"temp_question_{question_data['id']}.jpg"
                                        image.save(temp_image_path)

                                        analysis_result = analyzer.analyze_image(
                                            image_path=temp_image_path,
                                            domain="medical",
                                            context="ì˜í•™ ë¬¸ì œ ì´ë¯¸ì§€",
                                            save_to_chroma=False  # ChromaDBëŠ” ë³„ë„ ì €ì¥
                                        )

                                        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                                        if os.path.exists(temp_image_path):
                                            os.remove(temp_image_path)

                                        question_data['imageAnalysis'] = {
                                            'main_objects': analysis_result.main_objects,
                                            'medical_tags': analysis_result.medical_tags,
                                            'description': analysis_result.description,
                                            'confidence': analysis_result.confidence_score,
                                            'analyzed_by': analysis_result.analyzed_by
                                        }

                                        st.success("[SUCCESS] ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ!")
                            except Exception as e:
                                st.warning(f"[WARNING] ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

                        # AI ë¶„ì„ ìë™ ì‹¤í–‰
                        with st.spinner("[ANALYSIS] AIê°€ ë¬¸ì œë¥¼ ë¶„ì„ ì¤‘..."):
                            try:
                                # ProblemAnalyzerì˜ process_problem ë©”ì„œë“œ í˜¸ì¶œ
                                analysis_result = problem_analyzer.process_problem(
                                    question_text=question_text,
                                    choices=non_empty_choices,
                                    correct_answer=correct_answer,
                                    explanation=explanation,
                                    subject=subject
                                )

                                # ë¶„ì„ ê²°ê³¼ë¥¼ ë¬¸ì œ ë°ì´í„°ì— ì¶”ê°€
                                question_data['analysis'] = {
                                    'concepts': analysis_result.get('concepts', []),
                                    'keywords': analysis_result.get('keywords', []),
                                    'difficulty': analysis_result.get('difficulty', 'ë³´í†µ'),
                                    'confidence_score': 0.85,
                                    'verified_by': 'hierarchical_analyzer',
                                    'processed_at': datetime.now().isoformat()
                                }
                                question_data['status'] = 'analysis_completed'

                                st.success("[SUCCESS] AI ë¶„ì„ ì™„ë£Œ!")

                                # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                                with st.expander("[RESULT] ë¶„ì„ ê²°ê³¼", expanded=True):
                                    col1, col2 = st.columns(2)
                                    with col1:
                                        st.write("**ê°œë…:**", ', '.join(analysis_result.get('concepts', [])))
                                        st.write("**í‚¤ì›Œë“œ:**", ', '.join(analysis_result.get('keywords', [])))
                                    with col2:
                                        st.write("**ë‚œì´ë„:**", analysis_result.get('difficulty', 'ë³´í†µ'))
                                        st.write("**ì‹ ë¢°ë„:**", f"{0.85:.1%}")
                            except Exception as e:
                                st.error(f"[ERROR] AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
                                question_data['status'] = 'analysis_failed'

                        # ChromaDBì— ìë™ ì €ì¥
                        with st.spinner("[SAVE] ChromaDBì— ì €ì¥ ì¤‘..."):
                            try:
                                from rag_engine_multi_domain import multi_domain_rag_engine

                                # nursing_questions ì»¬ë ‰ì…˜ì— ì¶”ê°€
                                collection = multi_domain_rag_engine.chroma_client.get_or_create_collection('nursing_questions')

                                # Create full document with all question data
                                full_document = f"""
ë¬¸ì œ: {question_data['questionText']}
ì„ íƒì§€:
1. {question_data.get('choices', ['', '', '', '', ''])[0]}
2. {question_data.get('choices', ['', '', '', '', ''])[1]}
3. {question_data.get('choices', ['', '', '', '', ''])[2]}
4. {question_data.get('choices', ['', '', '', '', ''])[3]}
5. {question_data.get('choices', ['', '', '', '', ''])[4]}
ì •ë‹µ: {question_data.get('correctAnswer', '')}
í•´ì„¤: {question_data.get('explanation', '')}
"""

                                # Store complete metadata including choices
                                collection.add(
                                ids=[question_data['id']],
                                documents=[full_document],
                                metadatas=[{
                                    'questionText': question_data.get('questionText', ''),
                                    'choice1': question_data.get('choices', ['', '', '', '', ''])[0] or '',
                                    'choice2': question_data.get('choices', ['', '', '', '', ''])[1] or '',
                                    'choice3': question_data.get('choices', ['', '', '', '', ''])[2] or '',
                                    'choice4': question_data.get('choices', ['', '', '', '', ''])[3] or '',
                                    'choice5': question_data.get('choices', ['', '', '', '', ''])[4] or '',
                                    'correctAnswer': question_data.get('correctAnswer', '') or '',
                                    'explanation': question_data.get('explanation', '') or '',
                                    'subject': question_data.get('subject', 'ê°„í˜¸í•™') or 'ê°„í˜¸í•™',
                                    'difficulty': question_data.get('analysis', {}).get('difficulty', 'ë³´í†µ') or 'ë³´í†µ',
                                    'tags': ', '.join(question_data.get('analysis', {}).get('keywords', [])) or '',
                                    'createdBy': 'streamlit_user',
                                    'createdAt': question_data.get('createdAt', '') or '',
                                    'hasImage': bool(question_data.get('hasImage', False)),
                                    'type': 'problem'
                                }]
                                )

                                st.success(f"[SUCCESS] ChromaDB ì €ì¥ ì™„ë£Œ!")
                            except Exception as e:
                                st.error(f"[ERROR] ChromaDB ì €ì¥ ì‹¤íŒ¨: {e}")

                        # Firebaseì— ìë™ ì—…ë¡œë“œ (ë¶„ì•¼ì— ë”°ë¼ ë‹¤ë¥¸ ì»¬ë ‰ì…˜ ì‚¬ìš©)
                        with st.spinner("[UPLOAD] Firebaseì— ì—…ë¡œë“œ ì¤‘..."):
                            try:
                                problem_data = {
                                'id': question_data.get('id'),
                                'questionText': question_data['questionText'],
                                'choices': question_data.get('choices', []),
                                'correctAnswer': question_data.get('correctAnswer', ''),
                                'answer': question_data.get('answer'),
                                'subject': question_data.get('subject', 'ê°„í˜¸í•™'),
                                'difficulty': question_data.get('analysis', {}).get('difficulty', 'ë³´í†µ'),
                                'tags': question_data.get('analysis', {}).get('keywords', []),
                                'concepts': question_data.get('analysis', {}).get('concepts', []),
                                'explanation': question_data.get('explanation', ''),
                                'hasImage': question_data.get('hasImage', False),
                                'imageUrl': question_data.get('imageUrl'),
                                'imageUrls': question_data.get('imageUrls', []),
                                'imageAnalysis': question_data.get('imageAnalysis'),
                                'createdAt': question_data.get('createdAt'),
                                'createdBy': question_data.get('createdBy', 'streamlit_user'),
                                'status': 'completed'
                            }

                                # ë¶„ì•¼ì— ë”°ë¼ ë‹¤ë¥¸ ì—…ë¡œë“œ ë©”ì„œë“œ ì‚¬ìš©
                                if field == "ê°„í˜¸":
                                    upload_result = firebase_service.upload_problem(problem_data)
                                else:  # ì˜í•™
                                    upload_result = firebase_service.upload_medical_problem(problem_data)

                                if upload_result and upload_result.get('success', False):
                                    st.success(f"[SUCCESS] Firebase ì—…ë¡œë“œ ì„±ê³µ! (ë¶„ì•¼: {field})")
                                else:
                                    st.warning("[WARNING] Firebase ì—…ë¡œë“œ ë¶€ë¶„ ì‹¤íŒ¨")
                            except Exception as e:
                                st.error(f"[ERROR] Firebase ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")

                        # Jobs/completed í´ë”ì— ì €ì¥
                        completed_path = Path("Jobs/completed")
                        completed_path.mkdir(parents=True, exist_ok=True)

                        completed_file = completed_path / f"problem_{question_data['id']}.json"
                        with open(completed_file, 'w', encoding='utf-8') as f:
                            json.dump(question_data, f, ensure_ascii=False, indent=2)

                        # RAG(ChromaDB)ì— ì§ˆë¬¸ ë“±ë¡
                        try:
                            rag_engine.add_question(question_data)
                        except Exception:
                            pass

                        st.success(f"[SUCCESS] ë¬¸ì œ ì €ì¥ ì™„ë£Œ!")
                        st.info(f"[INFO] íŒŒì¼ ìœ„ì¹˜: {completed_file}")

                    except Exception as e:
                        st.error(f"[ERROR] ì €ì¥ ì‹¤íŒ¨: {e}")
            else:
                missing = []
                if not question_text:
                    missing.append("ë¬¸ì œ")
                if len(non_empty_choices) != 5:
                    missing.append(f"ì„ íƒì§€ (í˜„ì¬ {len(non_empty_choices)}/5)")
                if not correct_answer or correct_answer == "ì„ íƒì§€ë¥¼ ë¨¼ì € ì…ë ¥í•˜ì„¸ìš”":
                    missing.append("ì •ë‹µ")
                st.warning(f"[WARNING] ë‹¤ìŒ í•„ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”: {', '.join(missing)}")


def concept_input_form():
    """Form for inputting medical concepts with image support"""
    st.subheader("[INFO] ì˜í•™ ê°œë… ì…ë ¥")

    with st.form("concept_form"):
        # Image upload section
        st.subheader("[IMAGE] ì´ë¯¸ì§€ ì—…ë¡œë“œ (ì„ íƒì‚¬í•­)")
        uploaded_image = st.file_uploader(
            "ê°œë… ê´€ë ¨ ì´ë¯¸ì§€",
            type=['png', 'jpg', 'jpeg', 'webp'],
            help="ê°œë…ê³¼ ê´€ë ¨ëœ ì˜ë£Œ ì´ë¯¸ì§€, ë„ì‹, ì°¨íŠ¸ ë“±ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (PNG, JPG, JPEG, WebP ì§€ì›)"
        )

        image_analysis_result = None
        image_url = None
        if uploaded_image is not None:
            # Display uploaded image
            col_img1, col_img2 = st.columns([1, 2])
            with col_img1:
                st.image(uploaded_image, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", width=200)

            with col_img2:
                analyze_on_save = st.checkbox("[ANALYSIS] ì´ë¯¸ì§€ ìë™ ë¶„ì„", value=True, key="concept_analyze_image")
                if analyze_on_save:
                    st.info("[INFO] ì´ë¯¸ì§€ê°€ ì €ì¥ ì‹œ ìë™ ë¶„ì„ë©ë‹ˆë‹¤")

        st.divider()

        description = st.text_area(
            "ê°œë… ì„¤ëª… *",
            height=200,
            help="ê°œë…ì— ëŒ€í•œ ìƒì„¸í•œ ì„¤ëª…ì„ ì…ë ¥í•˜ì„¸ìš”"
        )

        tags = st.text_input("íƒœê·¸", help="ì‰¼í‘œë¡œ êµ¬ë¶„ (ì„ íƒì‚¬í•­)")

        submitted = st.form_submit_button("[SAVE] ê°œë… ì €ì¥")

        if submitted:
            # ê°œë… ì„¤ëª…ì´ ìˆê±°ë‚˜ ì´ë¯¸ì§€ê°€ ì—…ë¡œë“œëœ ê²½ìš° ì €ì¥ ê°€ëŠ¥
            if description or uploaded_image is not None:
                try:
                    concept_data = {
                        'id': str(uuid.uuid4()),
                        'title': '',  # ë‚˜ì¤‘ì— ì„¤ì •
                        'description': description or '',  # ì„¤ëª…ì´ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´
                        'tags': [tag.strip() for tag in tags.split(',') if tag.strip()],
                        'createdAt': datetime.now().isoformat(),
                        'createdBy': 'streamlit_user',
                        'hasImage': uploaded_image is not None,
                        'imageAnalysis': None,
                        'imageUrl': None
                    }

                    # Process image if uploaded
                    if uploaded_image is not None:
                        try:
                            # Upload image to Firebase Storage
                            with st.spinner("[UPLOAD] ì´ë¯¸ì§€ë¥¼ Firebase Storageì— ì—…ë¡œë“œ ì¤‘..."):
                                image_url = firebase_service.upload_image_to_storage(
                                    image_data=uploaded_image,
                                    path_prefix="concepts/images/",
                                    filename=f"concept_{concept_data['id']}.jpg",
                                    use_webp=False  # JPEGë¡œ ë³€ê²½
                                )

                                if image_url:
                                    concept_data['imageUrl'] = image_url
                                    st.success(f"[SUCCESS] ì´ë¯¸ì§€ ì—…ë¡œë“œ ì™„ë£Œ! URL: {image_url[:50]}...")
                                else:
                                    st.error("[ERROR] ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹¤íŒ¨ - Firebase Storage ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”")
                                    concept_data['hasImage'] = False
                                    raise Exception("Firebase Storage ì—…ë¡œë“œ ì‹¤íŒ¨")

                            # Analyze image if checkbox was checked and upload succeeded
                            if analyze_on_save and image_url:
                                with st.spinner("[ANALYSIS] ì´ë¯¸ì§€ ë¶„ì„ ì¤‘..."):
                                    try:
                                        # Use hierarchical analyzer
                                        image = Image.open(uploaded_image)
                                        analyzer = ImageHierarchicalAnalyzer()

                                        # ì´ë¯¸ì§€ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                                        temp_image_path = f"temp_concept_{concept_data['id']}.jpg"
                                        image.save(temp_image_path)

                                        st.info(f"[DEBUG] ì„ì‹œ íŒŒì¼ ìƒì„±: {temp_image_path}")

                                        analysis_result = analyzer.analyze_image(
                                            image_path=temp_image_path,
                                            domain="medical",
                                            context="ì˜í•™ ê°œë… ì´ë¯¸ì§€",
                                            save_to_chroma=False  # ChromaDBëŠ” ë³„ë„ ì €ì¥
                                        )

                                        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                                        if os.path.exists(temp_image_path):
                                            os.remove(temp_image_path)

                                        if analysis_result:
                                            concept_data['imageAnalysis'] = {
                                                'main_objects': getattr(analysis_result, 'main_objects', []),
                                                'medical_tags': getattr(analysis_result, 'medical_tags', []),
                                                'description': getattr(analysis_result, 'description', ''),
                                                'confidence': getattr(analysis_result, 'confidence_score', 0.0),
                                                'analyzed_by': getattr(analysis_result, 'analyzed_by', 'unknown'),
                                                'analysis_type': 'concept_image'
                                            }

                                            # ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ê°œë… ì„¤ëª…ì— ìë™ìœ¼ë¡œ ì¶”ê°€
                                            if hasattr(analysis_result, 'description') and analysis_result.description:
                                                concept_data['imageDescription'] = analysis_result.description

                                                # ì„¤ëª…ì´ ì—†ìœ¼ë©´ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ì„¤ëª…ìœ¼ë¡œ ì‚¬ìš©
                                                if not concept_data['description']:
                                                    concept_data['description'] = analysis_result.description
                                                    st.info("[AUTO] ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ê°œë… ì„¤ëª…ìœ¼ë¡œ ìë™ ì„¤ì •í–ˆìŠµë‹ˆë‹¤")

                                                # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                                                with st.expander("[RESULT] ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼", expanded=True):
                                                    # AI ëª¨ë¸ ì •ë³´ ë¨¼ì € í‘œì‹œ
                                                    analysis_model = getattr(analysis_result, 'analyzed_by', 'unknown')
                                                    if analysis_model == 'gemini_flash':
                                                        st.info("ğŸ¤– **ë¶„ì„ ëª¨ë¸**: Gemini 2.5 Flash (1ë‹¨ê³„ - ë¹ ë¥¸ ë¶„ì„)")
                                                    elif analysis_model == 'gpt5_mini':
                                                        st.info("ğŸ¤– **ë¶„ì„ ëª¨ë¸**: GPT-5 Mini (2ë‹¨ê³„ - ì¤‘ê°„ ê²€ìˆ˜)")
                                                    elif analysis_model == 'gpt5_enhanced':
                                                        st.info("ğŸ¤– **ë¶„ì„ ëª¨ë¸**: GPT-5 (3ë‹¨ê³„ - ìµœê³ ê¸‰ ì •ë°€ ë¶„ì„)")
                                                    else:
                                                        st.info(f"ğŸ¤– **ë¶„ì„ ëª¨ë¸**: {analysis_model}")

                                                    st.write("**ë¶„ì„ëœ ì£¼ìš” ê°ì²´:**", ', '.join(analysis_result.main_objects[:5]))
                                                    st.write("**ì˜ë£Œ íƒœê·¸:**", ', '.join(analysis_result.medical_tags[:5]))
                                                    st.write("**ì´ë¯¸ì§€ ì„¤ëª…:**", analysis_result.description)
                                                    st.write("**ì‹ ë¢°ë„:**", f"{analysis_result.confidence_score:.1%}")

                                                    # ì—ìŠ¤ì»¬ë ˆì´ì…˜ ì´ìœ  í‘œì‹œ (ìˆëŠ” ê²½ìš°)
                                                    if hasattr(analysis_result, 'escalation_reason') and analysis_result.escalation_reason:
                                                        st.caption(f"ğŸ’¡ **ì—ìŠ¤ì»¬ë ˆì´ì…˜ ì´ìœ **: {analysis_result.escalation_reason}")

                                            st.success("[SUCCESS] ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ!")
                                        else:
                                            st.error("[ERROR] ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
                                            concept_data['imageAnalysis'] = None

                                    except Exception as analysis_error:
                                        st.error(f"[ERROR] ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {analysis_error}")
                                        concept_data['imageAnalysis'] = None
                                        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                                        if os.path.exists(f"temp_concept_{concept_data['id']}.jpg"):
                                            os.remove(f"temp_concept_{concept_data['id']}.jpg")

                        except Exception as e:
                            st.error(f"[ERROR] ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                            st.error("[DEBUG] Firebase ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”")
                            concept_data['hasImage'] = False
                            concept_data['imageUrl'] = None
                            concept_data['imageAnalysis'] = None

                    # AI ë¶„ì„ (ì„¤ëª…ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ)
                    if concept_data['description']:
                        with st.spinner("[ANALYSIS] AIê°€ ê°œë…ì„ ë¶„ì„ ì¤‘..."):
                            try:
                                analyzed = gemini_service.analyze_concept(concept_data['description'])
                                concept_data.update({
                                    'keywords': analyzed.get('keywords', []),
                                    'category': analyzed.get('category', ''),
                                    'detailed_explanation': analyzed.get('detailed_explanation', concept_data['description'])
                                })
                                st.success("[SUCCESS] AI ë¶„ì„ ì™„ë£Œ!")
                            except Exception as e:
                                st.warning(f"[WARNING] AI ë¶„ì„ ì‹¤íŒ¨: {e}")

                    # ì œëª© ì„¤ì • (ì„¤ëª… ë˜ëŠ” ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ê¸°ë°˜)
                    if concept_data.get('description'):
                        concept_data['title'] = concept_data['description'][:50] + '...' if len(concept_data['description']) > 50 else concept_data['description']
                    elif concept_data.get('imageAnalysis') and concept_data['imageAnalysis'].get('main_objects'):
                        # ì´ë¯¸ì§€ ì£¼ìš” ê°ì²´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì œëª© ìƒì„±
                        main_objects = concept_data['imageAnalysis']['main_objects'][:3]
                        concept_data['title'] = f"ì˜ë£Œ ì´ë¯¸ì§€: {', '.join(main_objects)}"
                    else:
                        concept_data['title'] = f"ê°œë… {datetime.now().strftime('%Y-%m-%d %H:%M')}"

                    # ChromaDBì— ì €ì¥
                    with st.spinner("[SAVE] ChromaDBì— ì €ì¥ ì¤‘..."):
                        try:
                            st.info("[DEBUG] ChromaDB ì €ì¥ ì‹œì‘...")
                            from rag_engine_multi_domain import multi_domain_rag_engine

                            # ëª¨ë“  ê°œë…ì€ medical_concepts ì»¬ë ‰ì…˜ì— ì €ì¥
                            collection_name = 'medical_concepts'
                            st.info(f"[DEBUG] ì»¬ë ‰ì…˜ ì ‘ê·¼: {collection_name}")

                            collection = multi_domain_rag_engine.chroma_client.get_or_create_collection(collection_name)
                            st.info(f"[DEBUG] ì»¬ë ‰ì…˜ ìƒì„±/ì ‘ê·¼ ì™„ë£Œ: {collection}")

                            # ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
                            st.info(f"[DEBUG] ê°œë… ë°ì´í„° ê²€ì¦: ID={concept_data.get('id')}, ì œëª©={concept_data.get('title')}")
                            st.info(f"[DEBUG] ì´ë¯¸ì§€ ì •ë³´: hasImage={concept_data.get('hasImage')}, imageUrl={bool(concept_data.get('imageUrl'))}")

                            # Create full document with complete concept data including image info
                            image_info = ""
                            if concept_data.get('hasImage'):
                                image_analysis = concept_data.get('imageAnalysis') or {}
                                if isinstance(image_analysis, dict):
                                    image_info = f"""
ì´ë¯¸ì§€ í¬í•¨: ì˜ˆ
ì´ë¯¸ì§€ ì„¤ëª…: {concept_data.get('imageDescription', '') or ''}
ì´ë¯¸ì§€ ì£¼ìš” ê°ì²´: {', '.join(image_analysis.get('main_objects', []) or [])}
ì´ë¯¸ì§€ ì˜ë£Œ íƒœê·¸: {', '.join(image_analysis.get('medical_tags', []) or [])}
"""
                                else:
                                    image_info = "\nì´ë¯¸ì§€ í¬í•¨: ì˜ˆ\n"

                            full_document = f"""
ì„¤ëª…: {concept_data.get('description', '')}
ìƒì„¸ ì„¤ëª…: {concept_data.get('detailed_explanation', '')}
ì¹´í…Œê³ ë¦¬: {concept_data.get('category', '')}
í‚¤ì›Œë“œ: {', '.join(concept_data.get('keywords', []))}
íƒœê·¸: {', '.join(concept_data.get('tags', []))}
{image_info}
"""

                            # Store complete metadata including image info (ChromaDBì—ì„œ None ê°’ ë°©ì§€)
                            metadata = {
                                'title': concept_data.get('title', ''),
                                'description': concept_data.get('description', '')[:500] if concept_data.get('description') else '',
                                'category': concept_data.get('category', ''),
                                'keywords': ', '.join(concept_data.get('keywords', [])) or '',
                                'tags': ', '.join(concept_data.get('tags', [])) or '',
                                'createdBy': concept_data.get('createdBy', 'streamlit_user'),
                                'createdAt': concept_data.get('createdAt', ''),
                                'hasImage': bool(concept_data.get('hasImage', False)),
                                'imageUrl': concept_data.get('imageUrl', '') or '',
                                'type': 'concept'
                            }

                            # Add image analysis metadata if available (None ê°’ ë°©ì§€)
                            if concept_data.get('imageAnalysis') and isinstance(concept_data['imageAnalysis'], dict):
                                image_analysis = concept_data['imageAnalysis']
                                metadata.update({
                                    'imageDescription': concept_data.get('imageDescription', '') or '',
                                    'imageMainObjects': ', '.join(image_analysis.get('main_objects', []) or []) or '',
                                    'imageMedicalTags': ', '.join(image_analysis.get('medical_tags', []) or []) or '',
                                    'imageConfidence': float(image_analysis.get('confidence', 0.0) or 0.0)
                                })

                            collection.add(
                                ids=[concept_data['id']],
                                documents=[full_document],
                                metadatas=[metadata]
                            )

                            st.success(f"[SUCCESS] ChromaDB ì €ì¥ ì™„ë£Œ! (ì»¬ë ‰ì…˜: {collection_name})")
                        except Exception as e:
                            st.error(f"[ERROR] ChromaDB ì €ì¥ ì‹¤íŒ¨: {e}")

                    # Firebaseì— ì—…ë¡œë“œ
                    with st.spinner("[UPLOAD] Firebaseì— ì—…ë¡œë“œ ì¤‘..."):
                        try:
                            upload_result = firebase_service.upload_concept(concept_data)
                            if upload_result.get('success'):
                                st.success(f"[SUCCESS] Firebase ì—…ë¡œë“œ ì„±ê³µ!")
                        except Exception as e:
                            st.error(f"[ERROR] Firebase ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")

                    st.success("[SUCCESS] ê°œë… ì €ì¥ ì™„ë£Œ!")

                except Exception as e:
                    st.error(f"[ERROR] ì €ì¥ ì‹¤íŒ¨: {e}")
            else:
                st.warning("[WARNING] ê°œë… ì„¤ëª…ì„ ì…ë ¥í•˜ê±°ë‚˜ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”")


def ai_generation_tab():
    """AI batch question generation tab"""
    st.header("[AI] AI ë¬¸ì œ ë°°ì¹˜ ìƒì„±")

    # Create subtabs - Only AUTO and HISTORY
    gen_tab1, gen_tab2 = st.tabs([
        "[AUTO] AI ìë™ í•™ìŠµ ê³„íš",
        "[HISTORY] ìƒì„± ì´ë ¥"
    ])

    with gen_tab1:
        auto_learning_plan_section()

    with gen_tab2:
        generation_history_section()


def auto_learning_plan_section():
    """AI-powered automatic learning plan generation"""
    st.subheader("[AUTO] AI ìë™ í•™ìŠµ ê³„íš - ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§")

    # Tab for monitoring mode
    monitor_tab, manual_tab = st.tabs(["[MONITOR] ìë™ ëª¨ë‹ˆí„°ë§", "[MANUAL] ìˆ˜ë™ ìƒì„±"])

    with monitor_tab:
        st.info("[INFO] í•™ìŠµ ì¤‘ì¸ ì‚¬ìš©ìë¥¼ í™•ì¸í•˜ê³  í•„ìš”í•œ ì‚¬ìš©ìì—ê²Œ ë§ì¶¤ ë¬¸ì œë¥¼ ìƒì„±í•©ë‹ˆë‹¤")

        # Import monitoring service
        from user_monitor_service import monitor_instance

        # Display monitoring status
        col1, col2, col3 = st.columns(3)

        # Get current status
        status = monitor_instance.get_queue_status()

        with col1:
            st.metric("ì²˜ë¦¬ëœ ì‚¬ìš©ì", status['monitored_users'])
        with col2:
            st.metric("ëŒ€ê¸° ì¤‘ì¸ ì‘ì—…", status['pending'])
        with col3:
            st.metric("ì™„ë£Œëœ ì‘ì—…", status['completed'])

        # One-click automation button
        st.divider()
        if st.button("[AUTO] ì „ì²´ ìë™ ì²˜ë¦¬ ì‹¤í–‰", type="primary", use_container_width=True):
            with st.spinner("[PROCESSING] í™œë™ ì‚¬ìš©ì ë¶„ì„ ë° ë¬¸ì œ ìë™ ìƒì„± ì¤‘..."):
                try:
                    import asyncio
                    from learning_plan_engine import LearningPlanEngine

                    # Initialize engine
                    engine = LearningPlanEngine()
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)

                    # Step 1: Get active users
                    st.info("[STEP 1] í™œë™ ì‚¬ìš©ì í™•ì¸ ì¤‘...")
                    active_users = loop.run_until_complete(
                        monitor_instance.get_active_users(hours_back=24)
                    )

                    if not active_users:
                        st.warning("[EMPTY] ìµœê·¼ 24ì‹œê°„ ë™ì•ˆ í™œë™í•œ ì‚¬ìš©ìê°€ ì—†ìŠµë‹ˆë‹¤")
                        loop.close()
                    else:
                        st.success(f"[FOUND] {len(active_users)}ëª…ì˜ í™œë™ ì‚¬ìš©ì ë°œê²¬")

                        # Step 2: Process users who need help
                        users_processed = 0
                        users_helped = 0

                        progress_bar = st.progress(0)
                        status_text = st.empty()

                        for i, user in enumerate(active_users):
                            progress = (i + 1) / len(active_users)
                            progress_bar.progress(progress)
                            status_text.text(f"ì²˜ë¦¬ ì¤‘: {user['user_id']} ({i+1}/{len(active_users)})")

                            # Check if user needs help
                            needs_help = loop.run_until_complete(
                                monitor_instance.check_user_needs_help(user)
                            )

                            if needs_help:
                                st.write(f"[HELP] {user['user_id']} - ì˜¤ë‹µ {user['wrong_count']}ê°œ, ë„ì›€ í•„ìš”")

                                # Step 3: Generate learning plan for this user
                                try:
                                    # Analyze user history
                                    analysis = loop.run_until_complete(
                                        engine.analyze_user_history(user['user_id'], days_back=30)
                                    )

                                    if analysis:
                                        # Generate plan
                                        plan = loop.run_until_complete(
                                            engine.generate_learning_plan(analysis, target_count=10)
                                        )

                                        if plan:
                                            # Execute plan
                                            result = loop.run_until_complete(
                                                engine.execute_plan(plan, save_to_firebase=True)
                                            )

                                            if result['success']:
                                                st.success(f"âœ“ {user['user_id']}: {result['total_generated']}ê°œ ë¬¸ì œ ìƒì„± ì™„ë£Œ")
                                                users_helped += 1
                                            else:
                                                st.warning(f"âœ— {user['user_id']}: ë¬¸ì œ ìƒì„± ì‹¤íŒ¨")
                                        else:
                                            st.warning(f"âœ— {user['user_id']}: ê³„íš ìƒì„± ì‹¤íŒ¨")
                                    else:
                                        st.info(f"- {user['user_id']}: í•™ìŠµ ì´ë ¥ ì—†ìŒ")

                                except Exception as e:
                                    st.error(f"âœ— {user['user_id']}: ì˜¤ë¥˜ - {str(e)}")

                            users_processed += 1

                        loop.close()

                        # Final summary
                        st.divider()
                        st.subheader("[SUMMARY] ì²˜ë¦¬ ê²°ê³¼")
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("ì „ì²´ ì‚¬ìš©ì", len(active_users))
                        with col2:
                            st.metric("ë„ì›€ ì œê³µ", users_helped)
                        with col3:
                            st.metric("ì„±ê³µë¥ ", f"{(users_helped/len(active_users)*100 if active_users else 0):.0f}%")

                except Exception as e:
                    st.error(f"[ERROR] ìë™ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
                    if 'loop' in locals():
                        loop.close()

        # Active users section
        st.divider()
        st.subheader("[ACTIVE] ìµœê·¼ 24ì‹œê°„ í™œë™ ì‚¬ìš©ì")

        if st.button("[REFRESH] í™œë™ ì‚¬ìš©ì ìƒˆë¡œê³ ì¹¨"):
            with st.spinner("[LOADING] í™œë™ ì‚¬ìš©ì í™•ì¸ ì¤‘..."):
                try:
                    import asyncio

                    # Get active users
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    active_users = loop.run_until_complete(
                        monitor_instance.get_active_users(hours_back=24)
                    )
                    loop.close()

                    if active_users:
                        st.success(f"[FOUND] {len(active_users)}ëª…ì˜ í™œë™ ì‚¬ìš©ì ë°œê²¬")

                        # Display active users
                        for user in active_users:
                            with st.expander(f"ì‚¬ìš©ì: {user['user_id']} (ì˜¤ë‹µ {user['wrong_count']}ê°œ)"):
                                col1, col2 = st.columns(2)
                                with col1:
                                    st.write(f"**ë§ˆì§€ë§‰ í™œë™**: {user['last_activity']}")
                                    st.write(f"**ì˜¤ë‹µ ìˆ˜**: {user['wrong_count']}")
                                with col2:
                                    st.write(f"**ê³¼ëª©**: {', '.join(user['subjects'])}")
                                    # Check if needs help
                                    needs_help_loop = asyncio.new_event_loop()
                                    asyncio.set_event_loop(needs_help_loop)
                                    needs_help = needs_help_loop.run_until_complete(
                                        monitor_instance.check_user_needs_help(user)
                                    )
                                    needs_help_loop.close()

                                    if needs_help:
                                        st.error("[ALERT] ë„ì›€ í•„ìš”")
                                        if st.button(f"[GENERATE] ì¦‰ì‹œ ë¬¸ì œ ìƒì„±", key=f"gen_{user['user_id']}"):
                                            # Add to queue
                                            monitor_instance.processing_queue.append({
                                                'user_id': user['user_id'],
                                                'user_data': user,
                                                'timestamp': datetime.now(),
                                                'status': 'pending'
                                            })
                                            st.success("[QUEUED] ì²˜ë¦¬ ëŒ€ê¸°ì—´ì— ì¶”ê°€ë¨")
                                    else:
                                        st.success("[OK] ì–‘í˜¸")
                    else:
                        st.info("[EMPTY] ìµœê·¼ 24ì‹œê°„ ë™ì•ˆ í™œë™í•œ ì‚¬ìš©ìê°€ ì—†ìŠµë‹ˆë‹¤")

                except Exception as e:
                    st.error(f"[ERROR] ì‚¬ìš©ì ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

        # Processing queue section
        if status['queue_length'] > 0:
            st.divider()
            st.subheader("[QUEUE] ì²˜ë¦¬ ëŒ€ê¸°ì—´")

            # Display queue items
            for item in status['queue_details']:
                status_color = {
                    'pending': 'ğŸŸ¡',
                    'processing': 'ğŸ”µ',
                    'completed': 'ğŸŸ¢',
                    'failed': 'ğŸ”´'
                }.get(item['status'], 'âšª')

                with st.container():
                    col1, col2, col3 = st.columns([1, 2, 1])
                    with col1:
                        st.write(f"{status_color} {item['user_id']}")
                    with col2:
                        st.write(f"ìƒíƒœ: {item['status']}")
                    with col3:
                        if item['status'] == 'completed':
                            st.write(f"ìƒì„±: {item.get('questions_generated', 0)}ê°œ")
                        elif item['status'] == 'failed':
                            st.write(f"ì˜¤ë¥˜: {item.get('error', 'Unknown')}")

        # Manual refresh button
        if st.button("[REFRESH] ìˆ˜ë™ ìƒˆë¡œê³ ì¹¨", key="manual_refresh"):
            st.rerun()

    with manual_tab:
        st.info("[INFO] GPT-5-miniê°€ í•™ìŠµ ì´ë ¥ì„ ë¶„ì„í•˜ì—¬ ìµœì ì˜ í•™ìŠµ ê³„íšì„ ìë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤")

        # User input section
        col1, col2 = st.columns(2)

        with col1:
            user_id = st.text_input("ì‚¬ìš©ì ID", value="test_user", help="Flutter ì•±ì˜ ì‚¬ìš©ì ID", key="manual_user_id")
            days_back = st.number_input("ë¶„ì„ ê¸°ê°„ (ì¼)", min_value=7, max_value=90, value=30, key="manual_days")

        with col2:
            target_count = st.number_input("ìƒì„±í•  ë¬¸ì œ ìˆ˜", min_value=5, max_value=50, value=12, key="manual_count")
            focus_weak = st.checkbox("ì•½ì  ì¤‘ì‹¬ í•™ìŠµ", value=True, help="í‹€ë¦° ë¬¸ì œê°€ ë§ì€ ì˜ì—­ ì§‘ì¤‘", key="manual_weak")

        # Display current analysis
        if st.button("[ANALYZE] í•™ìŠµ ì´ë ¥ ë¶„ì„", key="manual_analyze"):
            with st.spinner("[PROCESSING] Firebaseì—ì„œ í•™ìŠµ ì´ë ¥ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
                try:
                    from learning_plan_engine import LearningPlanEngine
                    import asyncio

                    # Initialize engine
                    engine = LearningPlanEngine()

                    # Run async analysis
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)

                    analysis = loop.run_until_complete(
                        engine.analyze_user_history(user_id, days_back)
                    )

                    # Store in session state
                    st.session_state['learning_analysis'] = analysis
                    st.session_state['user_id'] = user_id

                    # Display analysis results
                    if analysis:
                        st.success("[SUCCESS] í•™ìŠµ ì´ë ¥ ë¶„ì„ ì™„ë£Œ")

                        # Show metrics
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("ì´ ë¬¸ì œ í’€ì´", analysis.get('total_attempts', 0))
                        with col2:
                            accuracy = analysis.get('overall_accuracy', 0)
                            st.metric("ì „ì²´ ì •ë‹µë¥ ", f"{accuracy:.1f}%")
                        with col3:
                            st.metric("ë¶„ì„ ê¸°ê°„", f"{days_back}ì¼")

                        # Show weak concepts
                        if analysis.get('weak_concepts'):
                            st.subheader("[WEAK] ì·¨ì•½ ê°œë… Top 5")
                            for concept in analysis['weak_concepts'][:5]:
                                accuracy = concept.get('accuracy', 0)
                                attempts = concept.get('attempts', 0)
                                st.write(f"- **{concept['concept']}**: ì •ë‹µë¥  {accuracy:.1f}% (ì‹œë„ {attempts}íšŒ)")

                        # Show strong concepts
                        if analysis.get('strong_concepts'):
                            with st.expander("[STRONG] ê°•ì  ê°œë… ë³´ê¸°"):
                                for concept in analysis['strong_concepts'][:5]:
                                    accuracy = concept.get('accuracy', 0)
                                    attempts = concept.get('attempts', 0)
                                    st.write(f"- {concept['concept']}: ì •ë‹µë¥  {accuracy:.1f}% (ì‹œë„ {attempts}íšŒ)")

                    else:
                        st.warning("[WARNING] ë¶„ì„í•  í•™ìŠµ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤")

                except Exception as e:
                    st.error(f"[ERROR] ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
                finally:
                    if 'loop' in locals():
                        loop.close()

    # Generate learning plan
    if st.session_state.get('learning_analysis'):
        st.divider()
        st.subheader("[PLAN] AI í•™ìŠµ ê³„íš ìƒì„±")

        if st.button("[GENERATE] GPT-5-minië¡œ ìµœì  í•™ìŠµ ê³„íš ìƒì„±"):
            with st.spinner("[AI] GPT-5-miniê°€ ìµœì  í•™ìŠµ ê³„íšì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
                try:
                    from learning_plan_engine import LearningPlanEngine
                    import asyncio

                    engine = LearningPlanEngine()
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)

                    plan = loop.run_until_complete(
                        engine.generate_learning_plan(
                            st.session_state['learning_analysis'],
                            target_count
                        )
                    )

                    # Store plan
                    st.session_state['learning_plan'] = plan

                    # Display plan
                    if plan:
                        st.success("[SUCCESS] í•™ìŠµ ê³„íš ìƒì„± ì™„ë£Œ")

                        # Show plan overview
                        st.subheader("[OVERVIEW] ê³„íš ê°œìš”")
                        st.write(f"**ì „ëµ**: {plan.get('strategy', 'N/A')}")
                        st.write(f"**ëª©í‘œ**: {plan.get('goal', 'N/A')}")
                        st.write(f"**ì´ ë¬¸ì œ ìˆ˜**: {plan.get('total_questions', 0)}")

                        # Show question distribution
                        if plan.get('question_distribution'):
                            st.subheader("[DISTRIBUTION] ë¬¸ì œ ìœ í˜• ë¶„ë°°")
                            for item in plan['question_distribution']:
                                st.write(f"- **{item['type']}**: {item['count']}ë¬¸ì œ ({item['reason']})")

                        # Show topic focus
                        if plan.get('topic_focus'):
                            st.subheader("[TOPICS] ì£¼ì œ ì´ˆì ")
                            for topic in plan['topic_focus']:
                                st.write(f"- **{topic['topic']}**: {topic['count']}ë¬¸ì œ - {topic['reason']}")

                        # Show difficulty distribution
                        if plan.get('difficulty_distribution'):
                            st.subheader("[DIFFICULTY] ë‚œì´ë„ ë¶„í¬")
                            for diff in plan['difficulty_distribution']:
                                st.write(f"- **{diff['level'].upper()}**: {diff['count']}ë¬¸ì œ ({diff['percentage']}%)")

                    else:
                        st.error("[ERROR] ê³„íš ìƒì„± ì‹¤íŒ¨")

                except Exception as e:
                    st.error(f"[ERROR] ê³„íš ìƒì„± ì˜¤ë¥˜: {str(e)}")
                finally:
                    if 'loop' in locals():
                        loop.close()

    # Execute plan
    if st.session_state.get('learning_plan'):
        st.divider()
        st.subheader("[EXECUTE] ê³„íš ì‹¤í–‰")

        st.warning("[WARNING] ê³„íšì„ ì‹¤í–‰í•˜ë©´ ì‹¤ì œë¡œ ë¬¸ì œê°€ ìƒì„±ë˜ê³  Firebaseì— ì €ì¥ë©ë‹ˆë‹¤")

        if st.button("[EXECUTE] í•™ìŠµ ê³„íš ì‹¤í–‰ (ë¬¸ì œ ìƒì„±)"):
            with st.spinner("[PROCESSING] AIê°€ ë¬¸ì œë¥¼ ìƒì„±í•˜ëŠ” ì¤‘..."):
                try:
                    from learning_plan_engine import LearningPlanEngine
                    import asyncio

                    engine = LearningPlanEngine()
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)

                    result = loop.run_until_complete(
                        engine.execute_plan(
                            st.session_state['learning_plan'],
                            save_to_firebase=True
                        )
                    )

                    # Display execution results
                    if result and result.get('success'):
                        st.success(f"[SUCCESS] {result['total_generated']}ê°œ ë¬¸ì œ ìƒì„± ì™„ë£Œ!")

                        # Show statistics
                        st.subheader("[STATS] ìƒì„± í†µê³„")
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("ìƒì„± ì„±ê³µ", result['total_generated'])
                        with col2:
                            st.metric("ì‹¤í–‰ ì‹œê°„", f"{result.get('execution_time', 0):.1f}ì´ˆ")

                        # Show generated questions preview
                        if result.get('questions'):
                            st.subheader("[PREVIEW] ìƒì„±ëœ ë¬¸ì œ ë¯¸ë¦¬ë³´ê¸°")
                            for i, q in enumerate(result['questions'][:3], 1):
                                with st.expander(f"ë¬¸ì œ {i}: {q.get('type', 'MCQ')}"):
                                    st.write(f"**ë¬¸ì œ**: {q['question_text']}")
                                    st.write("**ì„ íƒì§€**:")
                                    for j, choice in enumerate(q['choices'], 1):
                                        st.write(f"  {j}. {choice}")
                                    st.write(f"**ì •ë‹µ**: {q['correct_answer']}")
                    else:
                        st.error("[ERROR] ì‹¤í–‰ ì‹¤íŒ¨")

                except Exception as e:
                    st.error(f"[ERROR] ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
                finally:
                    if 'loop' in locals():
                        loop.close()


def generation_history_section():
    """Display generation history"""
    st.subheader("[HISTORY] AI ë¬¸ì œ ìƒì„± ì´ë ¥")

    # Time period selection
    col1, col2 = st.columns(2)
    with col1:
        period = st.selectbox("ê¸°ê°„ ì„ íƒ", ["ì˜¤ëŠ˜", "ìµœê·¼ 7ì¼", "ìµœê·¼ 30ì¼", "ì „ì²´"], key="history_period")
    with col2:
        if st.button("[REFRESH] ì´ë ¥ ìƒˆë¡œê³ ì¹¨", key="refresh_history"):
            st.rerun()

    # Get generation history from Firebase
    with st.spinner("[LOADING] Firebaseì—ì„œ ìƒì„± ì´ë ¥ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
        try:
            import firebase_admin
            from firebase_admin import credentials, firestore
            from datetime import datetime, timedelta

            # Initialize Firebase if not already done
            if not firebase_admin._apps:
                cred = credentials.Certificate('firebase-service-account.json')
                firebase_admin.initialize_app(cred)

            db = firestore.client()

            # Calculate date range
            now = datetime.now()
            if period == "ì˜¤ëŠ˜":
                start_date = now.replace(hour=0, minute=0, second=0, microsecond=0)
            elif period == "ìµœê·¼ 7ì¼":
                start_date = now - timedelta(days=7)
            elif period == "ìµœê·¼ 30ì¼":
                start_date = now - timedelta(days=30)
            else:  # ì „ì²´
                start_date = datetime(2024, 1, 1)  # Arbitrary old date

            # Query generation logs from Firebase
            generation_logs = []

            # Get from nursing_problems collection (recently generated problems)
            problems_ref = db.collection('nursing_problems')
            query = problems_ref.where('generated_by', 'in', ['gpt-5-mini', 'gpt-5', 'gemini-2.5-flash'])

            if period != "ì „ì²´":
                query = query.where('timestamp', '>=', start_date)

            query = query.order_by('timestamp', direction=firestore.Query.DESCENDING).limit(100)

            docs = query.stream()

            for doc in docs:
                data = doc.to_dict()
                if data.get('generated_by'):
                    generation_logs.append({
                        'id': doc.id,
                        'timestamp': data.get('timestamp', ''),
                        'type': data.get('type', 'MCQ'),
                        'model': data.get('generated_by', 'Unknown'),
                        'difficulty': data.get('difficulty', 'medium'),
                        'subject': data.get('subject', 'nursing'),
                        'created_by': data.get('created_by', 'ai_batch_generator')
                    })

            # Also check for batch generation logs if we have a separate collection
            try:
                batch_logs_ref = db.collection('generation_logs')
                batch_query = batch_logs_ref

                if period != "ì „ì²´":
                    batch_query = batch_query.where('timestamp', '>=', start_date)

                batch_query = batch_query.order_by('timestamp', direction=firestore.Query.DESCENDING).limit(50)
                batch_docs = batch_query.stream()

                for doc in batch_docs:
                    data = doc.to_dict()
                    generation_logs.append({
                        'id': doc.id,
                        'timestamp': data.get('timestamp', ''),
                        'type': 'Batch Generation',
                        'model': data.get('model_used', 'GPT-5-mini'),
                        'count': data.get('questions_generated', 0),
                        'user': data.get('user_id', 'System'),
                        'status': data.get('status', 'completed')
                    })
            except:
                # If generation_logs collection doesn't exist, continue
                pass

            if generation_logs:
                # Convert to DataFrame
                history_data = []
                for log in generation_logs:
                    # Format timestamp
                    timestamp_str = ""
                    if log.get('timestamp'):
                        try:
                            if isinstance(log['timestamp'], datetime):
                                timestamp_str = log['timestamp'].strftime('%Y-%m-%d %H:%M')
                            elif isinstance(log['timestamp'], str):
                                timestamp_str = log['timestamp'][:16]  # Take first 16 chars (YYYY-MM-DD HH:MM)
                        except:
                            timestamp_str = "N/A"

                    history_data.append({
                        'ì‹œê°„': timestamp_str,
                        'ìœ í˜•': log.get('type', 'MCQ'),
                        'ëª¨ë¸': log.get('model', 'Unknown'),
                        'ë‚œì´ë„': log.get('difficulty', log.get('status', 'N/A')),
                        'ê³¼ëª©': log.get('subject', log.get('user', 'N/A')),
                        'ìƒì„±ì': log.get('created_by', log.get('user', 'System'))
                    })

                df = pd.DataFrame(history_data)

                # Display summary metrics
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("ì´ ìƒì„± ë¬¸ì œ", len(history_data))
                with col2:
                    # Count by model
                    if 'gpt-5-mini' in df['ëª¨ë¸'].values:
                        gpt5_mini_count = len(df[df['ëª¨ë¸'] == 'gpt-5-mini'])
                    else:
                        gpt5_mini_count = 0
                    st.metric("GPT-5-mini", gpt5_mini_count)
                with col3:
                    if 'gpt-5' in df['ëª¨ë¸'].values:
                        gpt5_count = len(df[df['ëª¨ë¸'] == 'gpt-5'])
                    else:
                        gpt5_count = 0
                    st.metric("GPT-5", gpt5_count)
                with col4:
                    if 'gemini-2.5-flash' in df['ëª¨ë¸'].values:
                        gemini_count = len(df[df['ëª¨ë¸'] == 'gemini-2.5-flash'])
                    else:
                        gemini_count = 0
                    st.metric("Gemini", gemini_count)

                # Display the dataframe
                st.dataframe(df, use_container_width=True)

                # Model usage chart
                if len(df) > 0:
                    st.subheader("[CHART] ëª¨ë¸ë³„ ì‚¬ìš© í†µê³„")
                    model_counts = df['ëª¨ë¸'].value_counts()
                    st.bar_chart(model_counts)

            else:
                st.info("[EMPTY] ì„ íƒí•œ ê¸°ê°„ì— ìƒì„± ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤")

        except Exception as e:
            st.error(f"[ERROR] ì´ë ¥ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

            # Show sample data for demonstration
            st.info("[INFO] ìƒ˜í”Œ ë°ì´í„°ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤")
            sample_data = {
                "ì‹œê°„": ["2025-01-23 10:00", "2025-01-23 09:30", "2025-01-23 09:00"],
                "ìœ í˜•": ["MCQ", "Case", "Image"],
                "ëª¨ë¸": ["gpt-5-mini", "gpt-5", "gemini-2.5-flash"],
                "ë‚œì´ë„": ["medium", "hard", "easy"],
                "ê³¼ëª©": ["nursing", "medical", "pharmacology"],
                "ìƒì„±ì": ["ai_batch_generator", "user_monitor", "manual"]
            }
            df = pd.DataFrame(sample_data)
            st.dataframe(df, use_container_width=True)


def system_management_tab():
    """System management and settings tab"""
    st.header("[SYSTEM] ì‹œìŠ¤í…œ ê´€ë¦¬")

    # Create subtabs for system management
    mgmt_tab1, mgmt_tab2 = st.tabs(["[SETTINGS] ì‹œìŠ¤í…œ ì„¤ì •", "[API] API ì‚¬ìš©ëŸ‰"])

    with mgmt_tab1:
        st.subheader("[SETTINGS] ì‹œìŠ¤í…œ ì„¤ì •")

        col1, col2 = st.columns(2)

        with col1:
            st.info("[PATH] Jobs ë””ë ‰í„°ë¦¬")
            st.code(str(JOBS_DIR))

            st.info("[PATH] ChromaDB ê²½ë¡œ")
            st.code("database/chroma_db/")

        with col2:
            st.info("[MODEL] AI ëª¨ë¸ ì„¤ì •")
            st.code("Embedding: text-embedding-004")
            st.code("Primary: GPT-5 Mini")
            st.code("Advanced: GPT-5")

        # Environment check
        st.subheader("[CHECK] í™˜ê²½ í™•ì¸")

        try:
            validate_config()
            st.success("[OK] ëª¨ë“  ì„¤ì •ì´ ì˜¬ë°”ë¦…ë‹ˆë‹¤")
        except Exception as e:
            st.error(f"[ERROR] ì„¤ì • ì˜¤ë¥˜: {e}")

    with mgmt_tab2:
        st.subheader("[API] API ì‚¬ìš©ëŸ‰ ì¶”ì ")

        # API Usage Overview
        st.info("[INFO] OpenAI ë° Gemini API ì‚¬ìš©ëŸ‰ ë° ë¹„ìš© ì¶”ì ")

        # Time period selection
        period = st.selectbox("ê¸°ê°„ ì„ íƒ", ["ì˜¤ëŠ˜", "ì´ë²ˆ ì£¼", "ì´ë²ˆ ë‹¬"])

        try:
            # Get usage data based on period
            if period == "ì˜¤ëŠ˜":
                usage_data = api_tracker.get_daily_usage()
                st.subheader(f"[TODAY] ì˜¤ëŠ˜ ì‚¬ìš©ëŸ‰ ({datetime.now().strftime('%Y-%m-%d')})")
            elif period == "ì´ë²ˆ ì£¼":
                usage_data = api_tracker.get_weekly_usage()
                st.subheader("[WEEK] ìµœê·¼ 7ì¼ ì‚¬ìš©ëŸ‰")
            else:  # ì´ë²ˆ ë‹¬
                now = datetime.now()
                usage_data = api_tracker.get_monthly_usage(now.year, now.month)
                st.subheader(f"[MONTH] {now.year}ë…„ {now.month}ì›” ì‚¬ìš©ëŸ‰")

            # Display metrics
            col1, col2, col3 = st.columns(3)

            total_cost = usage_data.get('total_cost', 0) if usage_data else 0
            total_tokens = usage_data.get('total_tokens', 0) if usage_data else 0

            with col1:
                st.metric("ì´ í† í° ì‚¬ìš©ëŸ‰", f"{total_tokens:,}")
            with col2:
                st.metric("ì´ ë¹„ìš©", f"${total_cost:.4f}")
            with col3:
                st.metric("ì›í™” í™˜ì‚° (1,400ì›/$)", f"â‚©{total_cost * 1400:.0f}")

            # Model-wise breakdown
            if usage_data and usage_data.get('by_model'):
                st.subheader("[MODEL] ëª¨ë¸ë³„ ì‚¬ìš©ëŸ‰")

                model_data = []
                for model, stats in usage_data['by_model'].items():
                    model_data.append({
                        'ëª¨ë¸': model,
                        'ì…ë ¥ í† í°': f"{stats.get('input_tokens', 0):,}",
                        'ì¶œë ¥ í† í°': f"{stats.get('output_tokens', 0):,}",
                        'ìš”ì²­ íšŸìˆ˜': stats.get('requests', 0),
                        'ë¹„ìš© (USD)': f"${stats.get('cost', 0):.4f}"
                    })

                if model_data:
                    model_df = pd.DataFrame(model_data)
                    st.dataframe(model_df, use_container_width=True)
            else:
                st.info("[INFO] í•´ë‹¹ ê¸°ê°„ì˜ ì‚¬ìš© ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤")

        except Exception as e:
            st.error(f"[ERROR] API ì‚¬ìš©ëŸ‰ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            st.info("[INFO] api_usage_trackerê°€ ì œëŒ€ë¡œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")

        # Model pricing reference
        with st.expander("[PRICE] ëª¨ë¸ë³„ ê°€ê²©í‘œ"):
            pricing_data = [
                {'ëª¨ë¸': 'GPT-5', 'ì…ë ¥ (1M tokens)': '$1.25', 'ì¶œë ¥ (1M tokens)': '$10.00'},
                {'ëª¨ë¸': 'GPT-5 Mini', 'ì…ë ¥ (1M tokens)': '$0.65', 'ì¶œë ¥ (1M tokens)': '$5.00'},
                {'ëª¨ë¸': 'GPT-5 Nano', 'ì…ë ¥ (1M tokens)': '$0.40', 'ì¶œë ¥ (1M tokens)': '$2.50'},
                {'ëª¨ë¸': 'Gemini 2.5 Pro', 'ì…ë ¥ (1M tokens)': '$1.25', 'ì¶œë ¥ (1M tokens)': '$10.00'},
                {'ëª¨ë¸': 'Gemini 2.5 Flash', 'ì…ë ¥ (1M tokens)': '$0.10', 'ì¶œë ¥ (1M tokens)': '$0.40'},
            ]
            pricing_df = pd.DataFrame(pricing_data)
            st.dataframe(pricing_df, use_container_width=True)


def chromadb_check_tab():
    """ChromaDB data check tab with deletion capability"""
    st.subheader("[CHECK] ChromaDB ë°ì´í„° í™•ì¸ ë° ê´€ë¦¬")

    # Collection selection
    collection_name = st.selectbox(
        "ì»¬ë ‰ì…˜ ì„ íƒ",
        ["nursing_questions", "nursing_concepts", "medical_concepts"]
    )

    # Store data in session state
    if 'chromadb_data' not in st.session_state:
        st.session_state.chromadb_data = None
        st.session_state.chromadb_ids = []

    # Get collection data
    col1, col2, col3 = st.columns([1, 1, 2])
    with col1:
        if st.button("[LOAD] ë°ì´í„° ì¡°íšŒ"):
            try:
                from rag_engine_multi_domain import multi_domain_rag_engine

                # Get or create collection
                collection = multi_domain_rag_engine.chroma_client.get_or_create_collection(collection_name)

                # Get all data
                results = collection.get()

                if results and results['ids']:
                    st.success(f"[SUCCESS] {len(results['ids'])}ê°œ ë°ì´í„° ë°œê²¬")

                    # Store full IDs for deletion
                    st.session_state.chromadb_ids = results['ids']

                    # Create DataFrame for display
                    data_list = []
                    for i, doc_id in enumerate(results['ids']):
                        metadata = results['metadatas'][i] if i < len(results['metadatas']) else {}
                        document = results['documents'][i] if i < len(results['documents']) else ""

                        # Extract full question data from document and metadata
                        question_display = metadata.get('questionText', metadata.get('title', ''))
                        if not question_display and document:
                            # Try to extract from document if not in metadata
                            question_display = document.split('\n')[0].replace('ë¬¸ì œ: ', '').replace('ì„¤ëª…: ', '')[:100]

                        # Check if data has image
                        has_image = metadata.get('hasImage', False)
                        image_url = metadata.get('imageUrl', '')

                        data_item = {
                            'Index': i,
                            'ID': doc_id[:8] + '...',  # Display shortened ID
                            'ë¬¸ì œ/ê°œë…': question_display[:80] + '...' if len(question_display) > 80 else question_display,
                            'íƒ€ì…': metadata.get('type', 'N/A'),
                            'ê³¼ëª©': metadata.get('subject', metadata.get('category', 'N/A')),
                            'ë‚œì´ë„': metadata.get('difficulty', 'N/A'),
                            'íƒœê·¸': metadata.get('tags', metadata.get('keywords', 'N/A')),
                            'ì´ë¯¸ì§€': '[IMAGE]' if has_image else 'N/A',
                            'ì´ë¯¸ì§€URL': image_url[:50] + '...' if len(image_url) > 50 else image_url if image_url else 'N/A'
                        }

                        # Add specific fields based on type
                        if metadata.get('type') == 'problem':
                            data_item.update({
                                'ì •ë‹µ': metadata.get('correctAnswer', 'N/A')[:50],
                                'ì„ íƒì§€1': metadata.get('choice1', 'N/A')[:30],
                                'ì„ íƒì§€2': metadata.get('choice2', 'N/A')[:30],
                            })
                        elif metadata.get('type') == 'concept':
                            data_item.update({
                                'ì´ë¯¸ì§€ë¶„ì„': '[ANALYZED]' if metadata.get('imageMainObjects') else 'N/A',
                                'ì£¼ìš”ê°ì²´': metadata.get('imageMainObjects', 'N/A')[:50],
                                'ì˜ë£Œíƒœê·¸': metadata.get('imageMedicalTags', 'N/A')[:50]
                            })

                        data_list.append(data_item)

                    st.session_state.chromadb_data = pd.DataFrame(data_list)
                else:
                    st.info(f"[INFO] {collection_name} ì»¬ë ‰ì…˜ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                    st.session_state.chromadb_data = None
                    st.session_state.chromadb_ids = []

            except Exception as e:
                st.error(f"[ERROR] ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")

    with col2:
        # Delete all button
        if st.button("[DELETE ALL] ì „ì²´ ì‚­ì œ", type="secondary"):
            if st.session_state.chromadb_ids:
                try:
                    from rag_engine_multi_domain import multi_domain_rag_engine
                    collection = multi_domain_rag_engine.chroma_client.get_or_create_collection(collection_name)

                    # Delete all documents
                    collection.delete(ids=st.session_state.chromadb_ids)
                    st.success(f"[SUCCESS] {len(st.session_state.chromadb_ids)}ê°œ ë°ì´í„° ì‚­ì œ ì™„ë£Œ!")

                    # Clear session state
                    st.session_state.chromadb_data = None
                    st.session_state.chromadb_ids = []
                    st.rerun()

                except Exception as e:
                    st.error(f"[ERROR] ì „ì²´ ì‚­ì œ ì‹¤íŒ¨: {e}")
            else:
                st.warning("[WARNING] ì‚­ì œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì¡°íšŒí•˜ì„¸ìš”.")

    # Display data if available
    if st.session_state.chromadb_data is not None:
        st.divider()

        # Show data table
        st.dataframe(st.session_state.chromadb_data, use_container_width=True)

        # Image preview section
        st.divider()
        st.subheader("[IMAGE] ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°")

        # Select item for image preview
        if '[IMAGE]' in st.session_state.chromadb_data['ì´ë¯¸ì§€'].values:
            image_items = st.session_state.chromadb_data[st.session_state.chromadb_data['ì´ë¯¸ì§€'] == '[IMAGE]']

            selected_index = st.selectbox(
                "ì´ë¯¸ì§€ê°€ ìˆëŠ” í•­ëª© ì„ íƒ",
                options=image_items['Index'].tolist(),
                format_func=lambda x: f"Index {x}: {image_items.iloc[image_items['Index'].tolist().index(x)]['ë¬¸ì œ/ê°œë…'][:50]}..."
            )

            if selected_index is not None:
                selected_row = st.session_state.chromadb_data.iloc[selected_index]
                image_url = selected_row['ì´ë¯¸ì§€URL'].replace('...', '') if selected_row['ì´ë¯¸ì§€URL'] != 'N/A' else None

                col_img1, col_img2 = st.columns([1, 2])

                with col_img1:
                    if image_url and image_url != 'N/A':
                        try:
                            st.image(image_url, caption="ì €ì¥ëœ ì´ë¯¸ì§€", width=200)
                        except Exception as e:
                            st.error(f"[ERROR] ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
                            st.write(f"**ì´ë¯¸ì§€ URL**: {image_url}")
                    else:
                        st.info("[INFO] ì´ë¯¸ì§€ URLì´ ì—†ìŠµë‹ˆë‹¤")

                with col_img2:
                    st.write(f"**ë¬¸ì œ/ê°œë…**: {selected_row['ë¬¸ì œ/ê°œë…']}")
                    st.write(f"**íƒ€ì…**: {selected_row['íƒ€ì…']}")
                    st.write(f"**ê³¼ëª©**: {selected_row['ê³¼ëª©']}")

                    if selected_row.get('ì´ë¯¸ì§€ë¶„ì„') == '[ANALYZED]':
                        st.write("**[ANALYSIS] ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ**")
                        st.write(f"**ì£¼ìš” ê°ì²´**: {selected_row.get('ì£¼ìš”ê°ì²´', 'N/A')}")
                        st.write(f"**ì˜ë£Œ íƒœê·¸**: {selected_row.get('ì˜ë£Œíƒœê·¸', 'N/A')}")
                    elif selected_row.get('ì •ë‹µ'):
                        st.write(f"**ì •ë‹µ**: {selected_row.get('ì •ë‹µ', 'N/A')}")
        else:
            st.info("[INFO] ì´ë¯¸ì§€ê°€ í¬í•¨ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")

        # Export option
        csv = st.session_state.chromadb_data.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="[EXPORT] CSVë¡œ ë‹¤ìš´ë¡œë“œ",
            data=csv,
            file_name=f"{collection_name}_data.csv",
            mime="text/csv"
        )

        # Individual deletion
        st.divider()
        st.subheader("[DELETE] ê°œë³„ ë°ì´í„° ì‚­ì œ")

        # Select items to delete
        indices_to_delete = st.multiselect(
            "ì‚­ì œí•  í•­ëª© ì„ íƒ (Index ë²ˆí˜¸)",
            options=st.session_state.chromadb_data['Index'].tolist(),
            format_func=lambda x: f"Index {x}: {st.session_state.chromadb_data.iloc[x]['ë¬¸ì œ'][:50] if 'ë¬¸ì œ' in st.session_state.chromadb_data.columns else st.session_state.chromadb_data.iloc[x].get('ì œëª©/ì§ˆë¬¸', 'N/A')[:50]}..."
        )

        if st.button("[DELETE SELECTED] ì„ íƒ í•­ëª© ì‚­ì œ"):
            if indices_to_delete:
                try:
                    from rag_engine_multi_domain import multi_domain_rag_engine
                    collection = multi_domain_rag_engine.chroma_client.get_or_create_collection(collection_name)

                    # Get IDs to delete
                    ids_to_delete = [st.session_state.chromadb_ids[i] for i in indices_to_delete]

                    # Delete selected documents
                    collection.delete(ids=ids_to_delete)
                    st.success(f"[SUCCESS] {len(ids_to_delete)}ê°œ í•­ëª© ì‚­ì œ ì™„ë£Œ!")

                    # Clear session state to refresh
                    st.session_state.chromadb_data = None
                    st.session_state.chromadb_ids = []
                    st.rerun()

                except Exception as e:
                    st.error(f"[ERROR] ì„ íƒ í•­ëª© ì‚­ì œ ì‹¤íŒ¨: {e}")
            else:
                st.warning("[WARNING] ì‚­ì œí•  í•­ëª©ì„ ì„ íƒí•˜ì„¸ìš”.")

    # Collection statistics
    st.divider()
    st.subheader("[STATS] ì»¬ë ‰ì…˜ í†µê³„")

    try:
        stats_data = []

        for coll_name in ["nursing_questions", "nursing_concepts", "medical_concepts"]:
            try:
                collection = multi_domain_rag_engine.chroma_client.get_or_create_collection(coll_name)
                count = collection.count()
                stats_data.append({
                    'ì»¬ë ‰ì…˜': coll_name,
                    'ë°ì´í„° ìˆ˜': count,
                    'ìƒíƒœ': '[ACTIVE]' if count > 0 else '[EMPTY]'
                })
            except:
                stats_data.append({
                    'ì»¬ë ‰ì…˜': coll_name,
                    'ë°ì´í„° ìˆ˜': 0,
                    'ìƒíƒœ': '[ERROR]'
                })

        stats_df = pd.DataFrame(stats_data)
        st.dataframe(stats_df, use_container_width=True)

    except Exception as e:
        st.error(f"[ERROR] í†µê³„ ë¡œë“œ ì‹¤íŒ¨: {e}")


if __name__ == "__main__":
    main()
