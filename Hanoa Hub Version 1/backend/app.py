"""
Hanoa RAG System - Streamlit Main Application (Simplified Version)
"""
import json
import os
import uuid
from datetime import datetime
from pathlib import Path
from utils.datetime_utils import get_iso_timestamp
from utils.firebase_utils import ensure_created_at_iso
from storage.firebase_storage import FirebaseStorage

import streamlit as st
import pandas as pd

# Streamlit í­ ê´€ë ¨ íŒŒë¼ë¯¸í„° ë³€ê²½(ì„ì‹œ í˜¸í™˜ ì…”íŒ€): use_container_width -> width
try:
    def _map_ucw(kwargs):
        if 'use_container_width' in kwargs:
            val = kwargs.pop('use_container_width')
            kwargs.setdefault('width', 'stretch' if val else 'content')
        return kwargs

    if hasattr(st, 'button'):
        _orig_button = st.button
        def _button_shim(*args, **kwargs):
            return _orig_button(*args, **_map_ucw(kwargs))
        st.button = _button_shim

    if hasattr(st, 'form_submit_button'):
        _orig_form_submit_button = st.form_submit_button
        def _form_submit_button_shim(*args, **kwargs):
            return _orig_form_submit_button(*args, **_map_ucw(kwargs))
        st.form_submit_button = _form_submit_button_shim

    if hasattr(st, 'image'):
        _orig_image = st.image
        def _image_shim(*args, **kwargs):
            return _orig_image(*args, **_map_ucw(kwargs))
        st.image = _image_shim

    if hasattr(st, 'dataframe'):
        _orig_dataframe = st.dataframe
        def _dataframe_shim(*args, **kwargs):
            return _orig_dataframe(*args, **_map_ucw(kwargs))
        st.dataframe = _dataframe_shim
except Exception:
    # ì…”íŒ€ ì ìš© ì‹¤íŒ¨ì‹œ ë¬´ì‹œ(ê¸°ë³¸ ë™ì‘ ìœ ì§€)
    pass

from config import (
    validate_config, JOBS_DIR, OBSIDIAN_VAULT_PATH,
    DOMAIN_COLLECTIONS, DEFAULT_DOMAIN, ENABLE_CROSS_DOMAIN_SEARCH,
    ENABLE_IMAGE_VECTORS, GEMINI_API_KEY, OPENAI_API_KEY,
    MAX_IMAGE_SIZE_MB
)
from rag_engine import rag_engine
from rag_engine_multi_domain import multi_domain_rag_engine
from jobs_worker import jobs_worker
from analyzers.problem_analyzer import problem_analyzer
from models.problem_schema import ProblemData, create_sample_problems
from api_usage_tracker import api_tracker
from services.firebase_service import firebase_service
from services.gemini_service import gemini_service
from analyzers.image_hierarchical_analyzer import ImageHierarchicalAnalyzer
# ê¸°ë³¸ ì¤‘ë³µ ì œê±° ì—”ì§„ ë¨¼ì € ì„í¬íŠ¸
from deduplication_engine import deduplication_engine
# ChromaDB ê´€ë¦¬ì ì„í¬íŠ¸
from database.chroma_manager import ChromaManager

# ìƒˆë¡œìš´ AI ì‹œìŠ¤í…œ ì„í¬íŠ¸
from services.model_selector import model_selector
from services.question_type_handler import question_type_handler
from services.image_generator import image_generator
from services.smart_problem_generator import smart_problem_generator
from services.difficulty_classifier import difficulty_classifier

# ê³ ê¸‰ ê¸°ëŠ¥ë“¤ì„ ì•ˆì „í•˜ê²Œ ì„í¬íŠ¸
try:
    import deduplication_engine as _de
    # ê³ ê¸‰ ê¸°ëŠ¥ ê°€ìš©ì„± í™•ì¸
    use_advanced_deduplication = getattr(_de, 'use_advanced_deduplication', None)
    ADVANCED_DEDUP_AVAILABLE = bool(getattr(_de, 'ADVANCED_DEDUP_AVAILABLE', False)) and callable(use_advanced_deduplication)
    if not ADVANCED_DEDUP_AVAILABLE:
        # Fallback: ê³ ê¸‰ ì—”ì§„ ë¯¸ê°€ìš© ì‹œ ê¸°ë³¸ ì—”ì§„ìœ¼ë¡œ ìœ„ì„
        def use_advanced_deduplication(documents, domain='medical', **kwargs):
            return deduplication_engine.deduplicate(
                documents,
                domain=domain,
                return_pairs=kwargs.get('return_pairs', True)
            )
        ADVANCED_DEDUP_AVAILABLE = False
    pass  # ê³ ê¸‰ ì¤‘ë³µ ì œê±° ê¸°ëŠ¥ ì„í¬íŠ¸ ì„±ê³µ
except ImportError as e:
    pass  # ê³ ê¸‰ ì¤‘ë³µ ì œê±° ì„í¬íŠ¸ ì‹¤íŒ¨, ê¸°ë³¸ ì—”ì§„ ì‚¬ìš©
    # í´ë°± í•¨ìˆ˜ ì •ì˜
    def use_advanced_deduplication(documents, domain='medical', **kwargs):
        return deduplication_engine.deduplicate(
            documents,
            domain=domain,
            return_pairs=kwargs.get('return_pairs', True)
        )
    ADVANCED_DEDUP_AVAILABLE = False
from PIL import Image
import io
import os
import hashlib
import base64
import asyncio
from ai_batch_generator import BatchQuestionGenerator
from question_types import QuestionType

# ==============================
# ChromaDB ê´€ë¦¬ ìœ í‹¸ í•¨ìˆ˜ (imports ì´í›„)
# ==============================
def delete_image_file(image_url: str) -> None:
    """
    ì´ë¯¸ì§€ íŒŒì¼ ì‚­ì œ (í™•ì¥ì ìë™ ê°ì§€ í¬í•¨)

    Args:
        image_url: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ (í™•ì¥ì ëˆ„ë½ ê°€ëŠ¥)
    """
    import os

    try:
        if not image_url:
            return

        # UIì—ì„œ ì˜ë¼ë‚¸ '...' ì œê±°
        image_url = image_url.replace('...', '')

        # í™•ì¥ì ìë™ ê°ì§€
        if not os.path.exists(image_url):
            base_path = image_url.rstrip('.')
            possible_exts = ['.webp', '.jpg', '.jpeg', '.png']
            for ext in possible_exts:
                test_path = base_path + ext
                if os.path.exists(test_path):
                    image_url = test_path
                    break

        # íŒŒì¼ ì‚­ì œ
        if os.path.exists(image_url):
            os.remove(image_url)
            print(f"[DELETE] ì´ë¯¸ì§€ íŒŒì¼ ì‚­ì œ: {image_url}")
        else:
            print(f"[SKIP] ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ: {image_url}")

    except Exception as e:
        print(f"[ERROR] ì´ë¯¸ì§€ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")


def delete_chromadb_item(row_data, collection_name: str) -> bool:
    """
    ChromaDBì—ì„œ ë‹¨ì¼ í•­ëª© ì‚­ì œ (ì„ íƒ í–‰ ê¸°ë°˜)

    Args:
        row_data: st.dataframeì—ì„œ ì„ íƒëœ í–‰ ë°ì´í„° (Series)
        collection_name: í˜„ì¬ ì„ íƒëœ ì»¬ë ‰ì…˜ ì´ë¦„

    Returns:
        bool: ì‚­ì œ ì„±ê³µ ì—¬ë¶€
    """
    try:
        # Indexë¥¼ í†µí•´ ì‹¤ì œ ID ë§¤í•‘
        idx = None
        try:
            idx = int(row_data.get('Index')) if hasattr(row_data, 'get') else int(row_data['Index'])
        except Exception:
            pass

        if idx is None:
            st.error("í•­ëª© Indexë¥¼ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return False

        full_ids = st.session_state.get('chromadb_ids', [])
        if not full_ids or idx >= len(full_ids):
            st.error("ì„¸ì…˜ì— ì €ì¥ëœ ID ëª©ë¡ì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
            return False

        item_id = full_ids[idx]

        # ì»¬ë ‰ì…˜ ì ‘ê·¼: ê¸°ì¡´ ì—”ì§„ì˜ chroma_client ì‚¬ìš©
        collection = multi_domain_rag_engine.chroma_client.get_or_create_collection(collection_name)
        collection.delete(ids=[item_id])

        # ì´ë¯¸ì§€ íŒŒì¼ ì‚­ì œ (ì˜µì…˜)
        # ë‹¤ì–‘í•œ í‚¤ ì‹œë„ (ë¡œì»¬ë¼ì´ì§• ëŒ€ì‘)
        image_url = None
        for k in ['ì´ë¯¸ì§€URL', 'imageUrl', 'image_url', 'ï¿½Ì¹ï¿½ï¿½ï¿½URL']:
            try:
                if k in row_data and row_data[k] and row_data[k] != 'N/A':
                    image_url = str(row_data[k])
                    break
            except Exception:
                # pandas Series .get ì‚¬ìš© ê°€ëŠ¥ ì‹œë„
                v = getattr(row_data, 'get', lambda _k, _d=None: None)(k, None)
                if v and v != 'N/A':
                    image_url = str(v)
                    break

        if image_url:
            delete_image_file(image_url)

        st.success(f"âœ… í•­ëª© ì‚­ì œ ì™„ë£Œ: {item_id}")

        # ìƒˆë¡œê³ ì¹¨ì„ ìœ„í•´ ì„¸ì…˜ ì´ˆê¸°í™”
        st.session_state.chromadb_data = None
        st.session_state.chromadb_ids = []
        st.rerun()
        return True

    except Exception as e:
        st.error(f"âŒ ì‚­ì œ ì‹¤íŒ¨: {e}")
        return False


def fix_broken_image_paths():
    """
    ëª¨ë“  ì»¬ë ‰ì…˜ì˜ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ê²€ì‚¬í•˜ì—¬ í™•ì¥ìê°€ ëˆ„ë½ëœ í•­ëª©ì„ ë³µêµ¬
    """
    try:
        import os

        collections = [
            'nursing_questions',
            'ai_questions',
            'medical_concepts',
            'fitness_concepts',
            'lingumo_knowledge',
        ]

        fixed_count = 0

        for coll_name in collections:
            try:
                collection = multi_domain_rag_engine.chroma_client.get_or_create_collection(coll_name)
                all_data = collection.get()
                if not all_data or not all_data.get('ids'):
                    continue

                for i, item_id in enumerate(all_data['ids']):
                    metadata = all_data['metadatas'][i] if i < len(all_data.get('metadatas', [])) else {}
                    image_url = None
                    if isinstance(metadata, dict):
                        image_url = metadata.get('imageUrl') or metadata.get('image_url')

                    if image_url and not os.path.exists(image_url):
                        base_path = image_url.rstrip('.')
                        for ext in ['.webp', '.jpg', '.jpeg', '.png']:
                            test_path = base_path + ext
                            if os.path.exists(test_path):
                                # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
                                metadata = dict(metadata or {})
                                metadata['imageUrl'] = test_path
                                collection.update(ids=[item_id], metadatas=[metadata])
                                fixed_count += 1
                                break
            except Exception as e:
                print(f"[ERROR] {coll_name} ë³µêµ¬ ì‹¤íŒ¨: {e}")
                continue

        st.success(f"âœ… {fixed_count}ê°œ ì´ë¯¸ì§€ ê²½ë¡œ ë³µêµ¬ ì™„ë£Œ")
        st.rerun()
    except Exception as e:
        st.error(f"âŒ ë³µêµ¬ ì‹¤íŒ¨: {e}")


def cleanup_orphan_files():
    """
    ChromaDBì— ë“±ë¡ë˜ì§€ ì•Šì€ ê³ ì•„ ì´ë¯¸ì§€ íŒŒì¼ ì •ë¦¬
    """
    from pathlib import Path
    import os

    try:
        image_dir = Path("uploaded_images/concepts")
        if not image_dir.exists():
            st.info("ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤")
            return

        all_files = set(image_dir.glob("*.*"))

        registered_files = set()
        for coll_name in ['nursing_questions', 'ai_questions', 'medical_concepts', 'fitness_concepts', 'lingumo_knowledge']:
            try:
                collection = multi_domain_rag_engine.chroma_client.get_or_create_collection(coll_name)
                data = collection.get()
                if not data or not data.get('ids'):
                    continue

                for i, _ in enumerate(data['ids']):
                    md = data['metadatas'][i] if i < len(data.get('metadatas', [])) else {}
                    image_url = None
                    if isinstance(md, dict):
                        image_url = md.get('imageUrl') or md.get('image_url')
                    if image_url:
                        base = image_url.rstrip('.')
                        for ext in ['.webp', '.jpg', '.jpeg', '.png']:
                            test = Path(base + ext)
                            if test.exists():
                                registered_files.add(test)
                                break
            except Exception:
                continue

        orphan_files = all_files - registered_files
        if orphan_files:
            st.warning(f"âš ï¸ {len(orphan_files)}ê°œ ê³ ì•„ íŒŒì¼ ë°œê²¬")
            for f in sorted(orphan_files):
                st.write(f"- {f.name}")

            if st.button("ğŸ—‘ï¸ ê³ ì•„ íŒŒì¼ ëª¨ë‘ ì‚­ì œ", key="delete_orphans"):
                for f in orphan_files:
                    try:
                        f.unlink()
                    except Exception as e:
                        print(f"[ERROR] íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {f} - {e}")
                st.success(f"âœ… {len(orphan_files)}ê°œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ")
                st.rerun()
        else:
            st.info("âœ… ê³ ì•„ íŒŒì¼ ì—†ìŒ")
    except Exception as e:
        st.error(f"âŒ ì •ë¦¬ ì‹¤íŒ¨: {e}")

# ï¿½ï¿½ï¿½ï¿½ ï¿½×¸ï¿½ ï¿½ï¿½ï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ Ç¥ï¿½ï¿½ï¿½Ï´ï¿½ ï¿½ï¿½ï¿½ï¿½
# ìœ ì‚¬ í•­ëª© ì—†ìŒ ì‚¬ìœ ë¥¼ ê°„ê²°íˆ í‘œê¸°í•˜ëŠ” í—¬í¼
def show_no_similarity_reason(total_docs: int, n_requested: int) -> None:
    try:
        if total_docs <= 0:
            st.caption(f"ì‚¬ìœ : ìµœì´ˆ ì €ì¥ (ì»¬ë ‰ì…˜ {total_docs}ê±´, ìš”ì²­ n={n_requested})")
        elif total_docs < n_requested:
            st.caption(f"ì‚¬ìœ : ë¹„êµ ëŒ€ìƒ ë¶€ì¡± (ì»¬ë ‰ì…˜ {total_docs}ê±´, ìš”ì²­ n={n_requested})")
        else:
            st.caption(f"ì‚¬ìœ : ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ (ì»¬ë ‰ì…˜ {total_docs}ê±´, ìš”ì²­ n={n_requested})")
    except Exception:
        pass

# Page configuration
st.set_page_config(
    page_title="Hanoa RAG System",
    page_icon="[BOOK]",
    layout="wide",
    initial_sidebar_state="expanded"
)

def main():
    """Main Streamlit application"""

    # Initialize session state
    if 'initialized' not in st.session_state:
        try:
            validate_config()
            st.session_state.initialized = True
        except Exception as e:
            st.error(f"Configuration error: {e}")
            st.stop()

    # Initialize ChromaDB manager
    if 'chroma_manager' not in st.session_state:
        st.session_state.chroma_manager = ChromaManager()

    # Header
    st.title("[BOOK] Hanoa RAG System")
    st.markdown("ê°„í˜¸í•™/ì˜í•™ ë¬¸ì œ ë° ê°œë… ê´€ë¦¬ ì‹œìŠ¤í…œ")

    # Sidebar - System Status
    with st.sidebar:
        st.header("[STATUS] ì‹œìŠ¤í…œ ìƒíƒœ")

        # RAG Stats - Calculate from all collections
        try:
            from rag_engine_multi_domain import multi_domain_rag_engine

            # Count from all ChromaDB collections
            total_questions = 0
            total_concepts = 0

            collections_to_check = [
                ("nursing_questions", "question"),  # ì§ì ‘ ì…ë ¥í•œ ë¬¸ì œ
                ("ai_questions", "question"),  # AIê°€ ìƒì„±í•œ ë¬¸ì œ
                ("medical_problems", "question"),
                ("medical_concepts", "concept"),
                ("fitness_concepts", "concept"),
                ("lingumo_knowledge", "concept")
            ]

            for coll_name, coll_type in collections_to_check:
                try:
                    collection = multi_domain_rag_engine.chroma_client.get_or_create_collection(coll_name)
                    count = collection.count()
                    if coll_type == "question":
                        total_questions += count
                    else:
                        total_concepts += count
                except:
                    pass

            st.metric("ì´ ë¬¸ì œ", total_questions)
            st.metric("ì´ ê°œë…", total_concepts)
            st.metric("ì „ì²´ ë°ì´í„°", total_questions + total_concepts)
        except Exception as e:
            st.error(f"[ERROR] ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")

    # Main content tabs - 6ê°œ íƒ­
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "[DATA] ì˜ë£Œ ë°ì´í„° ì…ë ¥",
        "ğŸ‹ï¸ ìš´ë™/ì˜ì–‘ ì…ë ¥",
        "ğŸŒ ì–¸ì–´ í•™ìŠµ ì…ë ¥",
        "[CHECK] ë°ì´í„° í™•ì¸",
        "[AI] AI ë¬¸ì œ ìƒì„±",
        "[SYSTEM] ì‹œìŠ¤í…œ ê´€ë¦¬"
    ])

    with tab1:
        data_input_tab()

    with tab2:
        fitness_data_input_tab()

    with tab3:
        lingumo_data_input_tab()

    with tab4:
        chromadb_check_tab()

    with tab5:
        ai_generation_tab()

    with tab6:
        system_management_tab()


def data_input_tab():
    """Data input tab for questions and concepts"""
    st.header("[DATA] ì˜ë£Œ ë°ì´í„° ì…ë ¥")

    input_type = st.selectbox("ì…ë ¥ íƒ€ì…", ["ë¬¸ì œ", "ê°œë…"])

    if input_type == "ë¬¸ì œ":
        question_input_form()
    else:
        concept_input_form()


def question_input_form():
    """Manual form for inputting nursing/medical problems without AI analysis"""
    from problem_manual_form import problem_manual_input_form

    # Use the new manual input form
    problem_manual_input_form()


def concept_input_form():
    """Manual form for inputting medical concepts without AI analysis"""
    from concept_manual_form import concept_manual_input_form

    # Use the new manual input form
    concept_manual_input_form()
def ai_generation_tab():
    """AI batch question generation tab"""
    st.header("[AI] AI ë¬¸ì œ ìƒì„±")

    # Display save logs if any
    if 'save_logs' in st.session_state and len(st.session_state.save_logs) > 0:
        with st.expander(f"ğŸ“‹ ì €ì¥ ë¡œê·¸ ({len(st.session_state.save_logs)}ê°œ)", expanded=False):
            for log in reversed(st.session_state.save_logs[-20:]):  # Show last 20 logs, newest first
                if "âœ…" in log:
                    st.success(log)
                elif "âš ï¸" in log:
                    st.warning(log)
                elif "âŒ" in log:
                    st.error(log)
                else:
                    st.info(log)

            if st.button("ğŸ—‘ï¸ ë¡œê·¸ ì§€ìš°ê¸°"):
                st.session_state.save_logs = []
                st.rerun()

    # Simplified tabs - MAIN, HISTORY
    # gen_tab1, gen_tab2 = st.tabs([
    #     "ğŸ¤– í‹€ë¦° ë¬¸ì œ ê¸°ë°˜ ìƒì„±",
    #     "[HISTORY] ìƒì„± ì´ë ¥"
    # ])

    # with gen_tab1:
    #     explanation_requests_section()

    # DISABLED: í‹€ë¦° ë¬¸ì œ ê¸°ë°˜ ìë™ ìƒì„± ê¸°ëŠ¥ (ì¶”í›„ ë‹¤ë¥¸ ê¸°ëŠ¥ ì¶”ê°€ ì˜ˆì •)
    st.info("ğŸš§ ì´ ì„¹ì…˜ì€ í˜„ì¬ ê°œë°œ ì¤‘ì…ë‹ˆë‹¤. ê³§ ìƒˆë¡œìš´ ê¸°ëŠ¥ì´ ì¶”ê°€ë  ì˜ˆì •ì…ë‹ˆë‹¤.")

    gen_tab2 = st.container()
    with gen_tab2:
        generation_history_section()


def auto_learning_plan_section():
    """AI-powered automatic learning plan generation"""
    st.subheader("[AUTO] AI ìë™ í•™ìŠµ ê³„íš - ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§")

    # Tab for monitoring mode
    monitor_tab, manual_tab = st.tabs(["[MONITOR] ìë™ ëª¨ë‹ˆí„°ë§", "[MANUAL] ìˆ˜ë™ ìƒì„±"])

    with monitor_tab:
        st.info("[INFO] í•™ìŠµ ì¤‘ì¸ ì‚¬ìš©ìë¥¼ í™•ì¸í•˜ê³  í•„ìš”í•œ ì‚¬ìš©ìì—ê²Œ ë§ì¶¤ ë¬¸ì œë¥¼ ìƒì„±í•©ë‹ˆë‹¤")

        # Import monitoring service
        from user_monitor_service import monitor_instance

        # Display monitoring status
        col1, col2, col3 = st.columns(3)

        # Get current status
        status = monitor_instance.get_queue_status()

        with col1:
            st.metric("ì²˜ë¦¬ëœ ì‚¬ìš©ì", status['monitored_users'])
        with col2:
            st.metric("ëŒ€ê¸° ì¤‘ì¸ ì‘ì—…", status['pending'])
        with col3:
            st.metric("ì™„ë£Œëœ ì‘ì—…", status['completed'])

        # One-click automation button
        st.divider()
        if st.button("[AUTO] ì „ì²´ ìë™ ì²˜ë¦¬ ì‹¤í–‰", type="primary", use_container_width=True):
            with st.spinner("[PROCESSING] í™œë™ ì‚¬ìš©ì ë¶„ì„ ë° ë¬¸ì œ ìë™ ìƒì„± ì¤‘..."):
                try:
                    import asyncio
                    from learning_plan_engine import LearningPlanEngine

                    # Initialize engine
                    engine = LearningPlanEngine()
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)

                    # Step 1: Get active users
                    st.info("[STEP 1] í™œë™ ì‚¬ìš©ì í™•ì¸ ì¤‘...")
                    active_users = loop.run_until_complete(
                        monitor_instance.get_active_users(hours_back=24)
                    )

                    if not active_users:
                        st.warning("[EMPTY] ìµœê·¼ 24ì‹œê°„ ë™ì•ˆ í™œë™í•œ ì‚¬ìš©ìê°€ ì—†ìŠµë‹ˆë‹¤")
                        loop.close()
                    else:
                        st.success(f"[FOUND] {len(active_users)}ëª…ì˜ í™œë™ ì‚¬ìš©ì ë°œê²¬")

                        # Step 2: Process users who need help
                        users_processed = 0
                        users_helped = 0

                        progress_bar = st.progress(0)
                        status_text = st.empty()

                        for i, user in enumerate(active_users):
                            progress = (i + 1) / len(active_users)
                            progress_bar.progress(progress)
                            status_text.text(f"ì²˜ë¦¬ ì¤‘: {user['user_id']} ({i+1}/{len(active_users)})")

                            # Check if user needs help
                            needs_help = loop.run_until_complete(
                                monitor_instance.check_user_needs_help(user)
                            )

                            if needs_help:
                                st.write(f"[HELP] {user['user_id']} - ì˜¤ë‹µ {user['wrong_count']}ê°œ, ë„ì›€ í•„ìš”")

                                # Step 3: Generate learning plan for this user
                                try:
                                    # Analyze user history
                                    analysis = loop.run_until_complete(
                                        engine.analyze_user_history(user['user_id'], days_back=30)
                                    )

                                    if analysis:
                                        # Generate plan
                                        plan = loop.run_until_complete(
                                            engine.generate_learning_plan(analysis, target_count=10)
                                        )

                                        if plan:
                                            # Execute plan
                                            result = loop.run_until_complete(
                                                engine.execute_plan(plan, save_to_firebase=True)
                                            )

                                            if result['success']:
                                                st.success(f"âœ“ {user['user_id']}: {result['total_generated']}ê°œ ë¬¸ì œ ìƒì„± ì™„ë£Œ")
                                                users_helped += 1
                                            else:
                                                st.warning(f"âœ— {user['user_id']}: ë¬¸ì œ ìƒì„± ì‹¤íŒ¨")
                                        else:
                                            st.warning(f"âœ— {user['user_id']}: ê³„íš ìƒì„± ì‹¤íŒ¨")
                                    else:
                                        st.info(f"- {user['user_id']}: í•™ìŠµ ì´ë ¥ ì—†ìŒ")

                                except Exception as e:
                                    st.error(f"âœ— {user['user_id']}: ì˜¤ë¥˜ - {str(e)}")

                            users_processed += 1

                        loop.close()

                        # Final summary
                        st.divider()
                        st.subheader("[SUMMARY] ì²˜ë¦¬ ê²°ê³¼")
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("ì „ì²´ ì‚¬ìš©ì", len(active_users))
                        with col2:
                            st.metric("ë„ì›€ ì œê³µ", users_helped)
                        with col3:
                            st.metric("ì„±ê³µë¥ ", f"{(users_helped/len(active_users)*100 if active_users else 0):.0f}%")

                except Exception as e:
                    st.error(f"[ERROR] ìë™ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
                    if 'loop' in locals():
                        loop.close()

        # Active users section
        st.divider()
        st.subheader("[ACTIVE] ìµœê·¼ 24ì‹œê°„ í™œë™ ì‚¬ìš©ì")

        if st.button("[REFRESH] í™œë™ ì‚¬ìš©ì ìƒˆë¡œê³ ì¹¨"):
            with st.spinner("[LOADING] í™œë™ ì‚¬ìš©ì í™•ì¸ ì¤‘..."):
                try:
                    import asyncio

                    # Get active users
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    active_users = loop.run_until_complete(
                        monitor_instance.get_active_users(hours_back=24)
                    )
                    loop.close()

                    if active_users:
                        st.success(f"[FOUND] {len(active_users)}ëª…ì˜ í™œë™ ì‚¬ìš©ì ë°œê²¬")

                        # Display active users
                        for user in active_users:
                            with st.expander(f"ì‚¬ìš©ì: {user['user_id']} (ì˜¤ë‹µ {user['wrong_count']}ê°œ)"):
                                col1, col2 = st.columns(2)
                                with col1:
                                    st.write(f"**ë§ˆì§€ë§‰ í™œë™**: {user['last_activity']}")
                                    st.write(f"**ì˜¤ë‹µ ìˆ˜**: {user['wrong_count']}")
                                with col2:
                                    st.write(f"**ê³¼ëª©**: {', '.join(user['subjects'])}")
                                    # Check if needs help
                                    needs_help_loop = asyncio.new_event_loop()
                                    asyncio.set_event_loop(needs_help_loop)
                                    needs_help = needs_help_loop.run_until_complete(
                                        monitor_instance.check_user_needs_help(user)
                                    )
                                    needs_help_loop.close()

                                    if needs_help:
                                        st.error("[ALERT] ë„ì›€ í•„ìš”")
                                        if st.button(f"[GENERATE] ì¦‰ì‹œ ë¬¸ì œ ìƒì„±", key=f"gen_{user['user_id']}"):
                                            # Add to queue
                                            monitor_instance.processing_queue.append({
                                                'user_id': user['user_id'],
                                                'user_data': user,
                                                'timestamp': datetime.now(),
                                                'status': 'pending'
                                            })
                                            st.success("[QUEUED] ì²˜ë¦¬ ëŒ€ê¸°ì—´ì— ì¶”ê°€ë¨")
                                    else:
                                        st.success("[OK] ì–‘í˜¸")
                    else:
                        st.info("[EMPTY] ìµœê·¼ 24ì‹œê°„ ë™ì•ˆ í™œë™í•œ ì‚¬ìš©ìê°€ ì—†ìŠµë‹ˆë‹¤")

                except Exception as e:
                    st.error(f"[ERROR] ì‚¬ìš©ì ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

        # Processing queue section
        if status['queue_length'] > 0:
            st.divider()
            st.subheader("[QUEUE] ì²˜ë¦¬ ëŒ€ê¸°ì—´")

            # Display queue items
            for item in status['queue_details']:
                status_color = {
                    'pending': 'ğŸŸ¡',
                    'processing': 'ğŸ”µ',
                    'completed': 'ğŸŸ¢',
                    'failed': 'ğŸ”´'
                }.get(item['status'], 'âšª')

                with st.container():
                    col1, col2, col3 = st.columns([1, 2, 1])
                    with col1:
                        st.write(f"{status_color} {item['user_id']}")
                    with col2:
                        st.write(f"ìƒíƒœ: {item['status']}")
                    with col3:
                        if item['status'] == 'completed':
                            st.write(f"ìƒì„±: {item.get('questions_generated', 0)}ê°œ")
                        elif item['status'] == 'failed':
                            st.write(f"ì˜¤ë¥˜: {item.get('error', 'Unknown')}")

        # Manual refresh button
        if st.button("[REFRESH] ìˆ˜ë™ ìƒˆë¡œê³ ì¹¨", key="manual_refresh"):
            st.rerun()

    with manual_tab:
        st.info("[INFO] GPT-5-miniê°€ í•™ìŠµ ì´ë ¥ì„ ë¶„ì„í•˜ì—¬ ìµœì ì˜ í•™ìŠµ ê³„íšì„ ìë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤")

        # User input section
        col1, col2 = st.columns(2)

        with col1:
            user_id = st.text_input("ì‚¬ìš©ì ID", value="test_user", help="Flutter ì•±ì˜ ì‚¬ìš©ì ID", key="manual_user_id")
            days_back = st.number_input("ë¶„ì„ ê¸°ê°„ (ì¼)", min_value=7, max_value=90, value=30, key="manual_days")

        with col2:
            target_count = st.number_input("ìƒì„±í•  ë¬¸ì œ ìˆ˜", min_value=5, max_value=50, value=12, key="manual_count")
            focus_weak = st.checkbox("ì•½ì  ì¤‘ì‹¬ í•™ìŠµ", value=True, help="í‹€ë¦° ë¬¸ì œê°€ ë§ì€ ì˜ì—­ ì§‘ì¤‘", key="manual_weak")

        # Display current analysis
        if st.button("[ANALYZE] í•™ìŠµ ì´ë ¥ ë¶„ì„", key="manual_analyze"):
            with st.spinner("[PROCESSING] Firebaseì—ì„œ í•™ìŠµ ì´ë ¥ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
                try:
                    from learning_plan_engine import LearningPlanEngine
                    import asyncio

                    # Initialize engine
                    engine = LearningPlanEngine()

                    # Run async analysis
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)

                    analysis = loop.run_until_complete(
                        engine.analyze_user_history(user_id, days_back)
                    )

                    # Store in session state
                    st.session_state['learning_analysis'] = analysis
                    st.session_state['user_id'] = user_id

                    # Display analysis results
                    if analysis:
                        st.success("[SUCCESS] í•™ìŠµ ì´ë ¥ ë¶„ì„ ì™„ë£Œ")

                        # Show metrics
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("ì´ ë¬¸ì œ í’€ì´", analysis.get('total_attempts', 0))
                        with col2:
                            accuracy = analysis.get('overall_accuracy', 0)
                            st.metric("ì „ì²´ ì •ë‹µë¥ ", f"{accuracy:.1f}%")
                        with col3:
                            st.metric("ë¶„ì„ ê¸°ê°„", f"{days_back}ì¼")

                        # Show weak concepts
                        if analysis.get('weak_concepts'):
                            st.subheader("[WEAK] ì·¨ì•½ ê°œë… Top 5")
                            for concept in analysis['weak_concepts'][:5]:
                                accuracy = concept.get('accuracy', 0)
                                attempts = concept.get('attempts', 0)
                                st.write(f"- **{concept['concept']}**: ì •ë‹µë¥  {accuracy:.1f}% (ì‹œë„ {attempts}íšŒ)")

                        # Show strong concepts
                        if analysis.get('strong_concepts'):
                            with st.expander("[STRONG] ê°•ì  ê°œë… ë³´ê¸°"):
                                for concept in analysis['strong_concepts'][:5]:
                                    accuracy = concept.get('accuracy', 0)
                                    attempts = concept.get('attempts', 0)
                                    st.write(f"- {concept['concept']}: ì •ë‹µë¥  {accuracy:.1f}% (ì‹œë„ {attempts}íšŒ)")

                    else:
                        st.warning("[WARNING] ë¶„ì„í•  í•™ìŠµ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤")

                except Exception as e:
                    st.error(f"[ERROR] ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
                finally:
                    if 'loop' in locals():
                        loop.close()

    # Generate learning plan
    if st.session_state.get('learning_analysis'):
        st.divider()
        st.subheader("[PLAN] AI í•™ìŠµ ê³„íš ìƒì„±")

        if st.button("[GENERATE] GPT-5-minië¡œ ìµœì  í•™ìŠµ ê³„íš ìƒì„±"):
            with st.spinner("[AI] GPT-5-miniê°€ ìµœì  í•™ìŠµ ê³„íšì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
                try:
                    from learning_plan_engine import LearningPlanEngine
                    import asyncio

                    engine = LearningPlanEngine()
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)

                    plan = loop.run_until_complete(
                        engine.generate_learning_plan(
                            st.session_state['learning_analysis'],
                            target_count
                        )
                    )

                    # Store plan
                    st.session_state['learning_plan'] = plan

                    # Display plan
                    if plan:
                        st.success("[SUCCESS] í•™ìŠµ ê³„íš ìƒì„± ì™„ë£Œ")

                        # Show plan overview
                        st.subheader("[OVERVIEW] ê³„íš ê°œìš”")
                        st.write(f"**ì „ëµ**: {plan.get('strategy', 'N/A')}")
                        st.write(f"**ëª©í‘œ**: {plan.get('goal', 'N/A')}")
                        st.write(f"**ì´ ë¬¸ì œ ìˆ˜**: {plan.get('total_questions', 0)}")

                        # Show question distribution
                        if plan.get('question_distribution'):
                            st.subheader("[DISTRIBUTION] ë¬¸ì œ ìœ í˜• ë¶„ë°°")
                            for item in plan['question_distribution']:
                                st.write(f"- **{item['type']}**: {item['count']}ë¬¸ì œ ({item['reason']})")

                        # Show topic focus
                        if plan.get('topic_focus'):
                            st.subheader("[TOPICS] ì£¼ì œ ì´ˆì ")
                            for topic in plan['topic_focus']:
                                st.write(f"- **{topic['topic']}**: {topic['count']}ë¬¸ì œ - {topic['reason']}")

                        # Show difficulty distribution
                        if plan.get('difficulty_distribution'):
                            st.subheader("[DIFFICULTY] ë‚œì´ë„ ë¶„í¬")
                            for diff in plan['difficulty_distribution']:
                                st.write(f"- **{diff['level'].upper()}**: {diff['count']}ë¬¸ì œ ({diff['percentage']}%)")

                    else:
                        st.error("[ERROR] ê³„íš ìƒì„± ì‹¤íŒ¨")

                except Exception as e:
                    st.error(f"[ERROR] ê³„íš ìƒì„± ì˜¤ë¥˜: {str(e)}")
                finally:
                    if 'loop' in locals():
                        loop.close()

    # Execute plan
    if st.session_state.get('learning_plan'):
        st.divider()
        st.subheader("[EXECUTE] ê³„íš ì‹¤í–‰")

        st.warning("[WARNING] ê³„íšì„ ì‹¤í–‰í•˜ë©´ ì‹¤ì œë¡œ ë¬¸ì œê°€ ìƒì„±ë˜ê³  Firebaseì— ì €ì¥ë©ë‹ˆë‹¤")

        if st.button("[EXECUTE] í•™ìŠµ ê³„íš ì‹¤í–‰ (ë¬¸ì œ ìƒì„±)"):
            with st.spinner("[PROCESSING] AIê°€ ë¬¸ì œë¥¼ ìƒì„±í•˜ëŠ” ì¤‘..."):
                try:
                    from learning_plan_engine import LearningPlanEngine
                    import asyncio

                    engine = LearningPlanEngine()
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)

                    result = loop.run_until_complete(
                        engine.execute_plan(
                            st.session_state['learning_plan'],
                            save_to_firebase=True
                        )
                    )

                    # Display execution results
                    if result and result.get('success'):
                        st.success(f"[SUCCESS] {result['total_generated']}ê°œ ë¬¸ì œ ìƒì„± ì™„ë£Œ!")

                        # Show statistics
                        st.subheader("[STATS] ìƒì„± í†µê³„")
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("ìƒì„± ì„±ê³µ", result['total_generated'])
                        with col2:
                            st.metric("ì‹¤í–‰ ì‹œê°„", f"{result.get('execution_time', 0):.1f}ì´ˆ")

                        # Show generated questions preview
                        if result.get('questions'):
                            st.subheader("[PREVIEW] ìƒì„±ëœ ë¬¸ì œ ë¯¸ë¦¬ë³´ê¸°")
                            for i, q in enumerate(result['questions'][:3], 1):
                                with st.expander(f"ë¬¸ì œ {i}: {q.get('type', 'MCQ')}"):
                                    st.write(f"**ë¬¸ì œ**: {q['question_text']}")
                                    st.write("**ì„ íƒì§€**:")
                                    for j, choice in enumerate(q['choices'], 1):
                                        st.write(f"  {j}. {choice}")
                                    st.write(f"**ì •ë‹µ**: {q['correct_answer']}")
                    else:
                        st.error("[ERROR] ì‹¤í–‰ ì‹¤íŒ¨")

                except Exception as e:
                    st.error(f"[ERROR] ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
                finally:
                    if 'loop' in locals():
                        loop.close()


def generation_history_section():
    """Display generation history"""
    st.subheader("[HISTORY] AI ë¬¸ì œ ìƒì„± ì´ë ¥")

    # Time period selection
    col1, col2 = st.columns(2)
    with col1:
        period = st.selectbox("ê¸°ê°„ ì„ íƒ", ["ì˜¤ëŠ˜", "ìµœê·¼ 7ì¼", "ìµœê·¼ 30ì¼", "ì „ì²´"], key="history_period")
    with col2:
        if st.button("[REFRESH] ì´ë ¥ ìƒˆë¡œê³ ì¹¨", key="refresh_history"):
            st.rerun()

    # Get generation history from Firebase
    with st.spinner("[LOADING] Firebaseì—ì„œ ìƒì„± ì´ë ¥ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
        try:
            import firebase_admin
            from firebase_admin import credentials, firestore
            from datetime import datetime, timedelta

            # Initialize Firebase if not already done
            if not firebase_admin._apps:
                cred = credentials.Certificate('firebase-service-account.json')
                firebase_admin.initialize_app(cred)

            db = firestore.client()

            # Calculate date range
            now = datetime.now()
            if period == "ì˜¤ëŠ˜":
                start_date = now.replace(hour=0, minute=0, second=0, microsecond=0)
            elif period == "ìµœê·¼ 7ì¼":
                start_date = now - timedelta(days=7)
            elif period == "ìµœê·¼ 30ì¼":
                start_date = now - timedelta(days=30)
            else:  # ì „ì²´
                start_date = datetime(2024, 1, 1)  # Arbitrary old date

            # Query generation logs from Firebase
            generation_logs = []

            # Get from nursing_problems collection (recently generated problems)
            problems_ref = db.collection('nursing_problems')
            query = problems_ref.where('generated_by', 'in', ['gpt-5-mini', 'gpt-5', 'gemini-2.5-flash'])

            if period != "ì „ì²´":
                query = query.where('timestamp', '>=', start_date)

            query = query.order_by('timestamp', direction=firestore.Query.DESCENDING).limit(100)

            docs = query.stream()

            for doc in docs:
                data = doc.to_dict()
                if data.get('generated_by'):
                    generation_logs.append({
                        'id': doc.id,
                        'timestamp': data.get('timestamp', ''),
                        'type': data.get('type', 'MCQ'),
                        'model': data.get('generated_by', 'Unknown'),
                        'difficulty': data.get('difficulty', 'medium'),
                        'subject': data.get('subject', 'nursing'),
                        'created_by': data.get('created_by', 'ai_batch_generator')
                    })

            # Also check for batch generation logs if we have a separate collection
            try:
                batch_logs_ref = db.collection('generation_logs')
                batch_query = batch_logs_ref

                if period != "ì „ì²´":
                    batch_query = batch_query.where('timestamp', '>=', start_date)

                batch_query = batch_query.order_by('timestamp', direction=firestore.Query.DESCENDING).limit(50)
                batch_docs = batch_query.stream()

                for doc in batch_docs:
                    data = doc.to_dict()
                    generation_logs.append({
                        'id': doc.id,
                        'timestamp': data.get('timestamp', ''),
                        'type': 'Batch Generation',
                        'model': data.get('model_used', 'GPT-5-mini'),
                        'count': data.get('questions_generated', 0),
                        'user': data.get('user_id', 'System'),
                        'status': data.get('status', 'completed')
                    })
            except:
                # If generation_logs collection doesn't exist, continue
                pass

            if generation_logs:
                # Convert to DataFrame
                history_data = []
                for log in generation_logs:
                    # Format timestamp
                    timestamp_str = ""
                    if log.get('timestamp'):
                        try:
                            if isinstance(log['timestamp'], datetime):
                                timestamp_str = log['timestamp'].strftime('%Y-%m-%d %H:%M')
                            elif isinstance(log['timestamp'], str):
                                timestamp_str = log['timestamp'][:16]  # Take first 16 chars (YYYY-MM-DD HH:MM)
                        except:
                            timestamp_str = "N/A"

                    history_data.append({
                        'ì‹œê°„': timestamp_str,
                        'ìœ í˜•': log.get('type', 'MCQ'),
                        'ëª¨ë¸': log.get('model', 'Unknown'),
                        'ë‚œì´ë„': log.get('difficulty', log.get('status', 'N/A')),
                        'ê³¼ëª©': log.get('subject', log.get('user', 'N/A')),
                        'ìƒì„±ì': log.get('created_by', log.get('user', 'System'))
                    })

                df = pd.DataFrame(history_data)

                # Display summary metrics
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("ì´ ìƒì„± ë¬¸ì œ", len(history_data))
                with col2:
                    # Count by model
                    if 'gpt-5-mini' in df['ëª¨ë¸'].values:
                        gpt5_mini_count = len(df[df['ëª¨ë¸'] == 'gpt-5-mini'])
                    else:
                        gpt5_mini_count = 0
                    st.metric("GPT-5-mini", gpt5_mini_count)
                with col3:
                    if 'gpt-5' in df['ëª¨ë¸'].values:
                        gpt5_count = len(df[df['ëª¨ë¸'] == 'gpt-5'])
                    else:
                        gpt5_count = 0
                    st.metric("GPT-5", gpt5_count)
                with col4:
                    if 'gemini-2.5-flash' in df['ëª¨ë¸'].values:
                        gemini_count = len(df[df['ëª¨ë¸'] == 'gemini-2.5-flash'])
                    else:
                        gemini_count = 0
                    st.metric("Gemini", gemini_count)

                # Display the dataframe
                st.dataframe(df, width='stretch')

                # Model usage chart
                if len(df) > 0:
                    st.subheader("[CHART] ëª¨ë¸ë³„ ì‚¬ìš© í†µê³„")
                    model_counts = df['ëª¨ë¸'].value_counts()
                    st.bar_chart(model_counts)

            else:
                st.info("[EMPTY] ì„ íƒí•œ ê¸°ê°„ì— ìƒì„± ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤")

        except Exception as e:
            error_msg = str(e)

            # Check if it's a Firebase index error
            if "requires an index" in error_msg or "400" in error_msg:
                st.error("[ERROR] Firebase ì¸ë±ìŠ¤ê°€ í•„ìš”í•©ë‹ˆë‹¤")
                st.warning("""
                ### í•´ê²° ë°©ë²•:
                1. ì•„ë˜ ë§í¬ë¥¼ í´ë¦­í•˜ì—¬ Firebase Consoleì—ì„œ ì¸ë±ìŠ¤ ìƒì„±
                2. ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ í›„ (1-5ë¶„ ì†Œìš”) í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨

                **ë˜ëŠ”** ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì‚­ì œí•˜ì„¸ìš”:
                ```bash
                cd backend
                python delete_sample_data.py
                ```
                """)

                # Extract index creation link if available
                if "https://" in error_msg:
                    import re
                    urls = re.findall(r'https://[^\s]+', error_msg)
                    if urls:
                        st.markdown(f"**ì¸ë±ìŠ¤ ìƒì„± ë§í¬**: {urls[0]}")

                # Show helpful info instead of sample data
                st.info("""
                [INFO] í˜„ì¬ ai_generation_history ì»¬ë ‰ì…˜ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.

                AI ë¬¸ì œ ìƒì„±ì´ ì™„ë£Œë˜ë©´ ì—¬ê¸°ì— ì´ë ¥ì´ í‘œì‹œë©ë‹ˆë‹¤.
                """)
            else:
                st.error(f"[ERROR] ì´ë ¥ ì¡°íšŒ ì‹¤íŒ¨: {error_msg}")

                # Show helpful message for empty data
                st.info("[INFO] ìƒì„± ì´ë ¥ì´ ì—†ê±°ë‚˜ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")


def system_management_tab():
    """System management and settings tab"""
    st.header("[SYSTEM] ì‹œìŠ¤í…œ ê´€ë¦¬")

    # Create subtabs for system management
    mgmt_tab1, mgmt_tab2 = st.tabs(["[SETTINGS] ì‹œìŠ¤í…œ ì„¤ì •", "[API] API ì‚¬ìš©ëŸ‰"])

    with mgmt_tab1:
        st.subheader("[SETTINGS] ì‹œìŠ¤í…œ ì„¤ì •")

        col1, col2 = st.columns(2)

        with col1:
            st.info("[PATH] Jobs ë””ë ‰í„°ë¦¬")
            st.code(str(JOBS_DIR))

            st.info("[PATH] ChromaDB ê²½ë¡œ")
            st.code("database/chroma_db/")

        with col2:
            st.info("[MODEL] AI ëª¨ë¸ ì„¤ì •")
            st.code("Embedding: gemini-embedding-001 (768d)")
            st.code("Primary: GPT-4o Mini")
            st.code("Advanced: GPT-4o")

        # Environment check
        st.subheader("[CHECK] í™˜ê²½ í™•ì¸")

        try:
            validate_config()
            st.success("[OK] ëª¨ë“  ì„¤ì •ì´ ì˜¬ë°”ë¦…ë‹ˆë‹¤")
        except Exception as e:
            st.error(f"[ERROR] ì„¤ì • ì˜¤ë¥˜: {e}")

    with mgmt_tab2:
        st.subheader("[API] API ì‚¬ìš©ëŸ‰ ì¶”ì ")

        # API Usage Overview
        st.info("[INFO] OpenAI ë° Gemini API ì‚¬ìš©ëŸ‰ ë° ë¹„ìš© ì¶”ì ")

        # Time period selection
        period = st.selectbox("ê¸°ê°„ ì„ íƒ", ["ì˜¤ëŠ˜", "ì´ë²ˆ ì£¼", "ì´ë²ˆ ë‹¬"])

        try:
            # Get usage data based on period
            if period == "ì˜¤ëŠ˜":
                usage_data = api_tracker.get_daily_usage()
                st.subheader(f"[TODAY] ì˜¤ëŠ˜ ì‚¬ìš©ëŸ‰ ({datetime.now().strftime('%Y-%m-%d')})")
            elif period == "ì´ë²ˆ ì£¼":
                usage_data = api_tracker.get_weekly_usage()
                st.subheader("[WEEK] ìµœê·¼ 7ì¼ ì‚¬ìš©ëŸ‰")
            else:  # ì´ë²ˆ ë‹¬
                now = datetime.now()
                usage_data = api_tracker.get_monthly_usage(now.year, now.month)
                st.subheader(f"[MONTH] {now.year}ë…„ {now.month}ì›” ì‚¬ìš©ëŸ‰")

            # Display metrics
            col1, col2, col3 = st.columns(3)

            total_cost = usage_data.get('total_cost', 0) if usage_data else 0
            total_tokens = usage_data.get('total_tokens', 0) if usage_data else 0

            with col1:
                st.metric("ì´ í† í° ì‚¬ìš©ëŸ‰", f"{total_tokens:,}")
            with col2:
                st.metric("ì´ ë¹„ìš©", f"${total_cost:.4f}")
            with col3:
                st.metric("ì›í™” í™˜ì‚° (1,400ì›/$)", f"â‚©{total_cost * 1400:.0f}")

            # Model-wise breakdown
            if usage_data and usage_data.get('by_model'):
                st.subheader("[MODEL] ëª¨ë¸ë³„ ì‚¬ìš©ëŸ‰")

                model_data = []
                for model, stats in usage_data['by_model'].items():
                    model_data.append({
                        'ëª¨ë¸': model,
                        'ì…ë ¥ í† í°': f"{stats.get('input_tokens', 0):,}",
                        'ì¶œë ¥ í† í°': f"{stats.get('output_tokens', 0):,}",
                        'ìš”ì²­ íšŸìˆ˜': stats.get('requests', 0),
                        'ë¹„ìš© (USD)': f"${stats.get('cost', 0):.4f}"
                    })

                if model_data:
                    model_df = pd.DataFrame(model_data)
                    st.dataframe(model_df, width='stretch')
            else:
                st.info("[INFO] í•´ë‹¹ ê¸°ê°„ì˜ ì‚¬ìš© ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤")

        except Exception as e:
            st.error(f"[ERROR] API ì‚¬ìš©ëŸ‰ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            st.info("[INFO] api_usage_trackerê°€ ì œëŒ€ë¡œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")

        # Model pricing reference
        with st.expander("[PRICE] ëª¨ë¸ë³„ ê°€ê²©í‘œ"):
            pricing_data = [
                {'ëª¨ë¸': 'GPT-5', 'ì…ë ¥ (1M tokens)': '$1.25', 'ì¶œë ¥ (1M tokens)': '$10.00'},
                {'ëª¨ë¸': 'GPT-5 Mini', 'ì…ë ¥ (1M tokens)': '$0.65', 'ì¶œë ¥ (1M tokens)': '$5.00'},
                {'ëª¨ë¸': 'GPT-5 Nano', 'ì…ë ¥ (1M tokens)': '$0.40', 'ì¶œë ¥ (1M tokens)': '$2.50'},
                {'ëª¨ë¸': 'Gemini 2.5 Pro', 'ì…ë ¥ (1M tokens)': '$1.25', 'ì¶œë ¥ (1M tokens)': '$10.00'},
                {'ëª¨ë¸': 'Gemini 2.5 Flash', 'ì…ë ¥ (1M tokens)': '$0.10', 'ì¶œë ¥ (1M tokens)': '$0.40'},
            ]
            pricing_df = pd.DataFrame(pricing_data)
            st.dataframe(pricing_df, width='stretch')


def chromadb_check_tab():
    """ChromaDB data check tab with deletion capability"""
    st.subheader("[CHECK] ChromaDB ë°ì´í„° í™•ì¸ ë° ê´€ë¦¬")

    # Collection selection
    collection_name = st.selectbox(
        "ì»¬ë ‰ì…˜ ì„ íƒ",
        [
            "nursing_questions",  # ì§ì ‘ ì…ë ¥í•œ ë¬¸ì œ
            "ai_questions",  # AIê°€ ìƒì„±í•œ ë¬¸ì œ
            "medical_concepts",
            "fitness_concepts",
            "lingumo_knowledge"
        ]
    )

    # Store data in session state
    if 'chromadb_data' not in st.session_state:
        st.session_state.chromadb_data = None
        st.session_state.chromadb_ids = []

    # Get collection data
    col1, col2, col3 = st.columns([1, 1, 2])
    with col1:
        if st.button("[LOAD] ë°ì´í„° ì¡°íšŒ"):
            try:
                from rag_engine_multi_domain import multi_domain_rag_engine

                # Get or create collection
                collection = multi_domain_rag_engine.chroma_client.get_or_create_collection(collection_name)

                # Get all data
                results = collection.get()

                if results and results['ids']:
                    st.success(f"[SUCCESS] {len(results['ids'])}ê°œ ë°ì´í„° ë°œê²¬")

                    # Store full IDs for deletion
                    st.session_state.chromadb_ids = results['ids']

                    # Create DataFrame for display
                    data_list = []
                    for i, doc_id in enumerate(results['ids']):
                        metadata = results['metadatas'][i] if i < len(results['metadatas']) else {}
                        document = results['documents'][i] if i < len(results['documents']) else ""

                        # Extract full question data from document and metadata
                        question_display = metadata.get('questionText', metadata.get('description', metadata.get('title', '')))
                        if not question_display and document:
                            # Try to extract from document if not in metadata
                            first_line = document.split('\n')[0] if document else ''
                            # Remove common prefixes
                            for prefix in ['ë¬¸ì œ: ', 'ì„¤ëª…: ', 'ê°œë…: ', 'í‚¤ì›Œë“œ: ', 'ë¶„ì•¼: ', 'íƒœê·¸: ']:
                                first_line = first_line.replace(prefix, '')
                            question_display = first_line[:100]

                        # Check if data has image
                        has_image = metadata.get('hasImage', False)
                        image_url = metadata.get('imageUrl', '')

                        data_item = {
                            'Index': i,
                            'ID': doc_id[:8] + '...',  # Display shortened ID
                            'ë¬¸ì œ/ê°œë…': question_display[:80] + '...' if len(question_display) > 80 else question_display,
                            'íƒ€ì…': metadata.get('type', 'N/A'),
                            'ê³¼ëª©': metadata.get('subject', metadata.get('category', 'N/A')),
                            'ë‚œì´ë„': metadata.get('difficulty', 'N/A'),
                            'íƒœê·¸': metadata.get('tags', metadata.get('keywords', 'N/A')),
                            'ì´ë¯¸ì§€': '[IMAGE]' if has_image else 'N/A',
                            'ì´ë¯¸ì§€URL': image_url[:50] + '...' if len(image_url) > 50 else image_url if image_url else 'N/A'
                        }

                        # Add specific fields based on type
                        if metadata.get('type') == 'problem':
                            # Handle choices - can be array or individual fields
                            choices = metadata.get('choices', [])
                            if isinstance(choices, list) and len(choices) >= 2:
                                choice1 = choices[0][:30] if len(choices) > 0 else 'N/A'
                                choice2 = choices[1][:30] if len(choices) > 1 else 'N/A'
                                choice3 = choices[2][:30] if len(choices) > 2 else 'N/A'
                            else:
                                choice1 = metadata.get('choice1', 'N/A')[:30]
                                choice2 = metadata.get('choice2', 'N/A')[:30]
                                choice3 = metadata.get('choice3', 'N/A')[:30]

                            data_item.update({
                                'ì •ë‹µ': metadata.get('correctAnswer', metadata.get('correctanswer', 'N/A'))[:50],
                                'ì„ íƒì§€1': choice1,
                                'ì„ íƒì§€2': choice2,
                                'ì„ íƒì§€3': choice3,
                            })
                        elif metadata.get('type') == 'concept':
                            data_item.update({
                                'ì´ë¯¸ì§€ë¶„ì„': '[ANALYZED]' if metadata.get('imageMainObjects') else 'N/A',
                                'ì£¼ìš”ê°ì²´': metadata.get('imageMainObjects', 'N/A')[:50],
                                'ì˜ë£Œíƒœê·¸': metadata.get('imageMedicalTags', 'N/A')[:50]
                            })

                        data_list.append(data_item)

                    st.session_state.chromadb_data = pd.DataFrame(data_list)
                else:
                    st.info(f"[INFO] {collection_name} ì»¬ë ‰ì…˜ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                    st.session_state.chromadb_data = None
                    st.session_state.chromadb_ids = []

            except Exception as e:
                st.error(f"[ERROR] ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")

    with col2:
        # Delete all button
        if st.button("[DELETE ALL] ì „ì²´ ì‚­ì œ", type="secondary"):
            if st.session_state.chromadb_ids:
                try:
                    from rag_engine_multi_domain import multi_domain_rag_engine
                    collection = multi_domain_rag_engine.chroma_client.get_or_create_collection(collection_name)

                    # Delete all documents
                    collection.delete(ids=st.session_state.chromadb_ids)
                    st.success(f"[SUCCESS] {len(st.session_state.chromadb_ids)}ê°œ ë°ì´í„° ì‚­ì œ ì™„ë£Œ!")

                    # Clear session state
                    st.session_state.chromadb_data = None
                    st.session_state.chromadb_ids = []
                    st.rerun()

                except Exception as e:
                    st.error(f"[ERROR] ì „ì²´ ì‚­ì œ ì‹¤íŒ¨: {e}")
            else:
                st.warning("[WARNING] ì‚­ì œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì¡°íšŒí•˜ì„¸ìš”.")

    # Display data if available
    if st.session_state.chromadb_data is not None:
        st.divider()

        # ğŸ“‹ ì¼ê´„ ì‘ì—… ì„¹ì…˜
        st.subheader("ğŸ“‹ ì¼ê´„ ì‘ì—…")
        col_bulk1, col_bulk2, col_bulk3 = st.columns(3)

        with col_bulk1:
            if st.button("ğŸ—‘ï¸ ì„ íƒ í•­ëª© ì‚­ì œ", key="bulk_delete_toggle"):
                st.session_state['show_bulk_delete'] = not st.session_state.get('show_bulk_delete', False)

            if st.session_state.get('show_bulk_delete', False):
                # ê°„ë‹¨í•œ ì„ íƒ/í™•ì¸ UI ì œê³µ
                indices_for_bulk = st.multiselect(
                    "ì‚­ì œí•  Index ì„ íƒ",
                    options=st.session_state.chromadb_data['Index'].tolist(),
                    key="bulk_delete_indices"
                )
                if st.button("âœ… ì˜ˆ, ì‚­ì œí•©ë‹ˆë‹¤", key="bulk_delete_confirm"):
                    if indices_for_bulk:
                        try:
                            collection = multi_domain_rag_engine.chroma_client.get_or_create_collection(collection_name)
                            ids_to_delete = [st.session_state.chromadb_ids[i] for i in indices_for_bulk]
                            collection.delete(ids=ids_to_delete)
                            st.success(f"[SUCCESS] {len(ids_to_delete)}ê°œ í•­ëª© ì‚­ì œ ì™„ë£Œ!")
                            st.session_state.chromadb_data = None
                            st.session_state.chromadb_ids = []
                            st.session_state['show_bulk_delete'] = False
                            st.rerun()
                        except Exception as e:
                            st.error(f"[ERROR] ì¼ê´„ ì‚­ì œ ì‹¤íŒ¨: {e}")
                    else:
                        st.info("ì„ íƒëœ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤")

        with col_bulk2:
            if st.button("ğŸ”„ ê¹¨ì§„ ì´ë¯¸ì§€ ê²½ë¡œ ë³µêµ¬", key="fix_img_paths"):
                fix_broken_image_paths()

        with col_bulk3:
            if st.button("ğŸ§¹ ê³ ì•„ íŒŒì¼ ì •ë¦¬", key="cleanup_orphans"):
                cleanup_orphan_files()

        # Show data table
        st.dataframe(st.session_state.chromadb_data, width='stretch')

        # Image preview section
        st.divider()
        st.subheader("[IMAGE] ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°")

        # Select item for image preview
        if '[IMAGE]' in st.session_state.chromadb_data['ì´ë¯¸ì§€'].values:
            image_items = st.session_state.chromadb_data[st.session_state.chromadb_data['ì´ë¯¸ì§€'] == '[IMAGE]']

            selected_index = st.selectbox(
                "ì´ë¯¸ì§€ê°€ ìˆëŠ” í•­ëª© ì„ íƒ",
                options=image_items['Index'].tolist(),
                format_func=lambda x: f"Index {x}: {image_items.iloc[image_items['Index'].tolist().index(x)]['ë¬¸ì œ/ê°œë…'][:50]}..."
            )

            if selected_index is not None:
                selected_row = st.session_state.chromadb_data.iloc[selected_index]
                image_url = selected_row['ì´ë¯¸ì§€URL'].replace('...', '') if selected_row['ì´ë¯¸ì§€URL'] != 'N/A' else None

                col_img1, col_img2 = st.columns([1, 2])

                # ì˜¤ë¥¸ìª½ íŒ¨ë„ì— ê°œë³„ ì‚­ì œ ë²„íŠ¼ (ë¯¸ë¦¬ë³´ê¸° ì˜†)
                with col_img2:
                    if st.button("ğŸ—‘ï¸ ì´ í•­ëª© ì‚­ì œ", key=f"delete_{selected_index}"):
                        st.warning("ì •ë§ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
                        col_confirm1, col_confirm2 = st.columns(2)
                        with col_confirm1:
                            if st.button("âœ… ì˜ˆ, ì‚­ì œí•©ë‹ˆë‹¤", key=f"confirm_delete_{selected_index}"):
                                delete_chromadb_item(selected_row, collection_name)
                        with col_confirm2:
                            if st.button("âŒ ì·¨ì†Œ", key=f"cancel_delete_{selected_index}"):
                                st.info("ì‚­ì œ ì·¨ì†Œ")

                with col_img1:
                    if image_url and image_url != 'N/A':
                        try:
                            # í™•ì¥ì ìë™ ê°ì§€ ë° ì¶”ê°€
                            import os
                            import glob
                            if not os.path.exists(image_url):
                                # í™•ì¥ì ì—†ê±°ë‚˜ ì˜ëª»ëœ ê²½ìš° (ëì´ .ìœ¼ë¡œ ëë‚˜ëŠ” ê²½ìš°)
                                base_path = image_url.rstrip('.')  # ë§ˆì§€ë§‰ ì  ì œê±°
                                possible_exts = ['.webp', '.jpg', '.jpeg', '.png']
                                for ext in possible_exts:
                                    test_path = base_path + ext
                                    if os.path.exists(test_path):
                                        image_url = test_path
                                        break
                            st.image(image_url, caption="ì €ì¥ëœ ì´ë¯¸ì§€", width=200)
                        except Exception as e:
                            st.error(f"[ERROR] ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
                            st.write(f"**ì´ë¯¸ì§€ URL**: {image_url}")
                    else:
                        st.info("[INFO] ì´ë¯¸ì§€ URLì´ ì—†ìŠµë‹ˆë‹¤")

                with col_img2:
                    st.write(f"**ë¬¸ì œ/ê°œë…**: {selected_row['ë¬¸ì œ/ê°œë…']}")
                    st.write(f"**íƒ€ì…**: {selected_row['íƒ€ì…']}")
                    st.write(f"**ê³¼ëª©**: {selected_row['ê³¼ëª©']}")

                    if selected_row.get('ì´ë¯¸ì§€ë¶„ì„') == '[ANALYZED]':
                        st.write("**[ANALYSIS] ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ**")
                        st.write(f"**ì£¼ìš” ê°ì²´**: {selected_row.get('ì£¼ìš”ê°ì²´', 'N/A')}")
                        st.write(f"**ì˜ë£Œ íƒœê·¸**: {selected_row.get('ì˜ë£Œíƒœê·¸', 'N/A')}")
                    elif selected_row.get('ì •ë‹µ'):
                        st.write(f"**ì •ë‹µ**: {selected_row.get('ì •ë‹µ', 'N/A')}")
        else:
            st.info("[INFO] ì´ë¯¸ì§€ê°€ í¬í•¨ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")

        # Export option
        csv = st.session_state.chromadb_data.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="[EXPORT] CSVë¡œ ë‹¤ìš´ë¡œë“œ",
            data=csv,
            file_name=f"{collection_name}_data.csv",
            mime="text/csv"
        )

        # Individual deletion
        st.divider()
        st.subheader("[DELETE] ê°œë³„ ë°ì´í„° ì‚­ì œ")

        # Select items to delete
        indices_to_delete = st.multiselect(
            "ì‚­ì œí•  í•­ëª© ì„ íƒ (Index ë²ˆí˜¸)",
            options=st.session_state.chromadb_data['Index'].tolist(),
            format_func=lambda x: f"Index {x}: {st.session_state.chromadb_data.iloc[x]['ë¬¸ì œ'][:50] if 'ë¬¸ì œ' in st.session_state.chromadb_data.columns else st.session_state.chromadb_data.iloc[x].get('ì œëª©/ì§ˆë¬¸', 'N/A')[:50]}..."
        )

        if st.button("[DELETE SELECTED] ì„ íƒ í•­ëª© ì‚­ì œ"):
            if indices_to_delete:
                try:
                    from rag_engine_multi_domain import multi_domain_rag_engine
                    collection = multi_domain_rag_engine.chroma_client.get_or_create_collection(collection_name)

                    # Get IDs to delete
                    ids_to_delete = [st.session_state.chromadb_ids[i] for i in indices_to_delete]

                    # Delete selected documents
                    collection.delete(ids=ids_to_delete)
                    st.success(f"[SUCCESS] {len(ids_to_delete)}ê°œ í•­ëª© ì‚­ì œ ì™„ë£Œ!")

                    # Clear session state to refresh
                    st.session_state.chromadb_data = None
                    st.session_state.chromadb_ids = []
                    st.rerun()

                except Exception as e:
                    st.error(f"[ERROR] ì„ íƒ í•­ëª© ì‚­ì œ ì‹¤íŒ¨: {e}")
            else:
                st.warning("[WARNING] ì‚­ì œí•  í•­ëª©ì„ ì„ íƒí•˜ì„¸ìš”.")

    # Collection statistics
    st.divider()
    st.subheader("[STATS] ì»¬ë ‰ì…˜ í†µê³„")

    try:
        from services.firebase_service import firebase_service
        from rag_engine_multi_domain import multi_domain_rag_engine

        stats_data = []

        # ChromaDB collections to check
        collections_info = [
            ("nursing_questions", "ê°„í˜¸ ë¬¸ì œ"),
            ("medical_problems", "ì˜í•™ ë¬¸ì œ"),
            ("medical_concepts", "ì˜í•™ ê°œë…"),
            ("fitness_concepts", "ìš´ë™/ì˜ì–‘"),
            ("lingumo_knowledge", "ì–¸ì–´ í•™ìŠµ")
        ]

        # Get ChromaDB stats
        for coll_name, display_name in collections_info:
            try:
                collection = multi_domain_rag_engine.chroma_client.get_or_create_collection(coll_name)

                # fitness_conceptsëŠ” ìš´ë™/ì˜ì–‘/ê±´ê°• ë¶„ë¦¬
                if coll_name == "fitness_concepts":
                    results = collection.get()
                    if results and results['metadatas']:
                        # ìš´ë™ ê°œë…
                        exercise_count = sum(1 for m in results['metadatas'] if m.get('category') == 'ìš´ë™')
                        stats_data.append({
                            'ë°ì´í„°ë² ì´ìŠ¤': 'ChromaDB',
                            'ì»¬ë ‰ì…˜': 'ìš´ë™',
                            'ë°ì´í„° ìˆ˜': exercise_count,
                            'ìƒíƒœ': '[ACTIVE]' if exercise_count > 0 else '[EMPTY]'
                        })

                        # ì˜ì–‘ ê°œë…
                        nutrition_count = sum(1 for m in results['metadatas'] if m.get('category') == 'ì˜ì–‘')
                        stats_data.append({
                            'ë°ì´í„°ë² ì´ìŠ¤': 'ChromaDB',
                            'ì»¬ë ‰ì…˜': 'ì˜ì–‘',
                            'ë°ì´í„° ìˆ˜': nutrition_count,
                            'ìƒíƒœ': '[ACTIVE]' if nutrition_count > 0 else '[EMPTY]'
                        })

                        # ê±´ê°• ê°œë…
                        health_count = sum(1 for m in results['metadatas'] if m.get('category') == 'ê±´ê°•')
                        stats_data.append({
                            'ë°ì´í„°ë² ì´ìŠ¤': 'ChromaDB',
                            'ì»¬ë ‰ì…˜': 'ê±´ê°•',
                            'ë°ì´í„° ìˆ˜': health_count,
                            'ìƒíƒœ': '[ACTIVE]' if health_count > 0 else '[EMPTY]'
                        })
                    else:
                        stats_data.append({
                            'ë°ì´í„°ë² ì´ìŠ¤': 'ChromaDB',
                            'ì»¬ë ‰ì…˜': 'ìš´ë™',
                            'ë°ì´í„° ìˆ˜': 0,
                            'ìƒíƒœ': '[EMPTY]'
                        })
                        stats_data.append({
                            'ë°ì´í„°ë² ì´ìŠ¤': 'ChromaDB',
                            'ì»¬ë ‰ì…˜': 'ì˜ì–‘',
                            'ë°ì´í„° ìˆ˜': 0,
                            'ìƒíƒœ': '[EMPTY]'
                        })
                        stats_data.append({
                            'ë°ì´í„°ë² ì´ìŠ¤': 'ChromaDB',
                            'ì»¬ë ‰ì…˜': 'ê±´ê°•',
                            'ë°ì´í„° ìˆ˜': 0,
                            'ìƒíƒœ': '[EMPTY]'
                        })
                else:
                    count = collection.count()
                    stats_data.append({
                        'ë°ì´í„°ë² ì´ìŠ¤': 'ChromaDB',
                        'ì»¬ë ‰ì…˜': display_name,
                        'ë°ì´í„° ìˆ˜': count,
                        'ìƒíƒœ': '[ACTIVE]' if count > 0 else '[EMPTY]'
                    })
            except Exception as e:
                if coll_name == "fitness_concepts":
                    stats_data.append({
                        'ë°ì´í„°ë² ì´ìŠ¤': 'ChromaDB',
                        'ì»¬ë ‰ì…˜': 'ìš´ë™',
                        'ë°ì´í„° ìˆ˜': 0,
                        'ìƒíƒœ': '[ERROR]'
                    })
                    stats_data.append({
                        'ë°ì´í„°ë² ì´ìŠ¤': 'ChromaDB',
                        'ì»¬ë ‰ì…˜': 'ì˜ì–‘',
                        'ë°ì´í„° ìˆ˜': 0,
                        'ìƒíƒœ': '[ERROR]'
                    })
                    stats_data.append({
                        'ë°ì´í„°ë² ì´ìŠ¤': 'ChromaDB',
                        'ì»¬ë ‰ì…˜': 'ê±´ê°•',
                        'ë°ì´í„° ìˆ˜': 0,
                        'ìƒíƒœ': '[ERROR]'
                    })
                else:
                    stats_data.append({
                        'ë°ì´í„°ë² ì´ìŠ¤': 'ChromaDB',
                        'ì»¬ë ‰ì…˜': display_name,
                        'ë°ì´í„° ìˆ˜': 0,
                        'ìƒíƒœ': '[ERROR]'
                    })


        # Display statistics
        if stats_data:
            stats_df = pd.DataFrame(stats_data)

            # Summary metrics
            col1, col2, col3 = st.columns(3)

            with col1:
                total_problems = sum(row['ë°ì´í„° ìˆ˜'] for row in stats_data if 'ë¬¸ì œ' in row['ì»¬ë ‰ì…˜'])
                st.metric("[PROBLEMS] ì´ ë¬¸ì œ", f"{total_problems:,}")

            with col2:
                total_concepts = sum(row['ë°ì´í„° ìˆ˜'] for row in stats_data if 'ê°œë…' in row['ì»¬ë ‰ì…˜'] or row['ì»¬ë ‰ì…˜'] in ['ìš´ë™', 'ì˜ì–‘', 'ê±´ê°•'])
                st.metric("[CONCEPTS] ì´ ê°œë…", f"{total_concepts:,}")

            with col3:
                total_chromadb = sum(row['ë°ì´í„° ìˆ˜'] for row in stats_data)
                st.metric("[TOTAL] ì „ì²´ ë°ì´í„°", f"{total_chromadb:,}")

            # Detailed table
            st.dataframe(
                stats_df.style.highlight_max(subset=['ë°ì´í„° ìˆ˜'], color='lightgreen'),
                width='stretch'
            )

            # Last update time
            st.caption(f"[UPDATE] ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    except Exception as e:
        st.error(f"[ERROR] í†µê³„ ë¡œë“œ ì‹¤íŒ¨: {e}")


def fitness_data_input_tab():
    """Fitness and nutrition data input tab"""
    from fitness_manual_form import fitness_concept_input_form

    st.header("ğŸ‹ï¸ ìš´ë™/ì˜ì–‘ ê°œë… ì…ë ¥")
    st.markdown("ìš´ë™ ë°©ë²•, í¼ ê°€ì´ë“œ, ì˜ì–‘ ì •ë³´ ë“±ì„ ì…ë ¥í•˜ì—¬ Areumfit RAG ì‹œìŠ¤í…œì— ì €ì¥í•©ë‹ˆë‹¤.")

    fitness_concept_input_form()


def lingumo_data_input_tab():
    """Language learning data input tab"""
    from lingumo_manual_form import lingumo_content_input_form

    st.header("ğŸŒ ì–¸ì–´ í•™ìŠµ ì½˜í…ì¸  ì…ë ¥")
    st.markdown("ë‹¨ì–´, ë¬¸ì¥, ë¬¸ë²• ë“±ì„ ì…ë ¥í•˜ì—¬ Lingumo RAG ì‹œìŠ¤í…œì— ì €ì¥í•©ë‹ˆë‹¤.")

    lingumo_content_input_form()


def explanation_requests_section():
    """Generate problems based on wrong answers using GPT-4o mini"""
    st.subheader("ğŸ¤– í‹€ë¦° ë¬¸ì œ ê¸°ë°˜ ìë™ ìƒì„±")
    st.markdown("í•™ìƒë“¤ì´ í‹€ë¦° ë¬¸ì œì˜ ê°œë…ì„ ë¶„ì„í•˜ì—¬ GPT-4o minië¡œ ìœ ì‚¬ ë¬¸ì œë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤.")

    try:
        # Check Firebase connection
        if not firebase_service.initialized:
            st.error("âŒ Firebase ì—°ê²° ì‹¤íŒ¨. ì„œë¹„ìŠ¤ ê³„ì • í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            st.info("ğŸ’¡ firebase-service-account.json íŒŒì¼ì„ backend í´ë”ì— ë°°ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.")
            return

        # Fetch wrong answers from SRS events (rating = 'again')
        srs_events = firebase_service.db.collection('srs_events').where('rating', '==', 'again').limit(50).stream()

        wrong_problems = []
        seen_cards = set()

        for event in srs_events:
            data = event.to_dict()
            card_id = data.get('cardId')

            # Avoid duplicates
            if card_id in seen_cards:
                continue
            seen_cards.add(card_id)

            # Get problem details
            try:
                problem_doc = firebase_service.db.collection('nursing_problems').document(card_id).get()
                if problem_doc.exists:
                    problem_data = problem_doc.to_dict()
                    problem_data['id'] = card_id
                    problem_data['userId'] = data.get('userId')
                    problem_data['wrongAt'] = data.get('timestamp')

                    # Skip ë³´ê±´ì˜ë£Œë²•ê·œ (laws change yearly, no need to maintain)
                    if problem_data.get('subject') == 'ë³´ê±´ì˜ë£Œë²•ê·œ':
                        continue

                    wrong_problems.append(problem_data)
            except:
                pass

        if not wrong_problems:
            st.info("ğŸ“­ ìµœê·¼ í‹€ë¦° ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.caption("ğŸ’¡ í•™ìƒì´ ë¬¸ì œë¥¼ í‹€ë¦¬ë©´ ìë™ìœ¼ë¡œ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.")
            return

        # Initialize processed problems tracking
        if 'processed_wrong_problems' not in st.session_state:
            st.session_state.processed_wrong_problems = set()

        # Filter out processed problems
        unprocessed_problems = [p for p in wrong_problems if p['id'] not in st.session_state.processed_wrong_problems]

        st.metric("í‹€ë¦° ë¬¸ì œ ìˆ˜", f"{len(unprocessed_problems)} / {len(wrong_problems)}")
        if len(unprocessed_problems) < len(wrong_problems):
            st.caption(f"âœ… {len(wrong_problems) - len(unprocessed_problems)}ê°œ ë¬¸ì œ ì²˜ë¦¬ ì™„ë£Œ")
        st.divider()

        if not unprocessed_problems:
            st.success("ğŸ‰ ëª¨ë“  í‹€ë¦° ë¬¸ì œë¥¼ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤!")
            if st.button("ğŸ”„ ëª©ë¡ ì´ˆê¸°í™”"):
                st.session_state.processed_wrong_problems = set()
                st.rerun()
            return

        # Display wrong problems and generate similar ones (all, sorted by time)
        for prob in unprocessed_problems:  # Show all unprocessed problems
            with st.expander(f"ğŸ”¹ {prob.get('subject', 'N/A')} - {prob.get('field', 'N/A')}"):
                st.markdown(f"**ë¬¸ì œ:** {prob.get('questionText', 'N/A')}")

                # Display choices
                choices = prob.get('choices', [])
                if choices:
                    st.markdown("**ë³´ê¸°:**")
                    for i, choice in enumerate(choices, 1):
                        st.markdown(f"{i}. {choice}")

                # Get correct answer (check both field names and calculate from index if needed)
                correct_answer = prob.get('correctAnswer') or prob.get('correctanswer')
                if not correct_answer and choices:
                    answer_idx = prob.get('answer')
                    if answer_idx is not None and 0 <= answer_idx < len(choices):
                        correct_answer = choices[answer_idx]

                st.markdown(f"**ì •ë‹µ:** {correct_answer or 'N/A'}")
                st.markdown(f"**ë‚œì´ë„:** {prob.get('difficulty', 'N/A')}")

                if prob.get('keywords'):
                    st.markdown(f"**í‚¤ì›Œë“œ:** {', '.join(prob.get('keywords', []))}")

                st.divider()

                # AI ìë™ ë¶„ì„ ì•ˆë‚´
                st.caption("ğŸ’¡ AIê°€ ì›ë³¸ ë¬¸ì œë¥¼ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ë¬¸ì œ ìœ í˜•ê³¼ ì¶œì œ ìŠ¤íƒ€ì¼ì„ ìë™ ì„ íƒí•©ë‹ˆë‹¤")


                if st.button("ğŸ¤– AIê°€ ë¶„ì„ í›„ ìë™ ìƒì„±", key=f"gen_{prob['id']}", type="primary", use_container_width=True):
                        with st.spinner("AIê°€ ë¬¸ì œë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                            try:
                                # AI ìë™ ë¶„ì„ - ìœ í˜• ë° í˜ë¥´ì†Œë‚˜ ì„ íƒ
                                question_type, persona = question_type_handler.analyze_and_select(prob)

                                # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                                type_icons = {
                                    "MCQ": "ğŸ“", "Matching": "ğŸ”—", "Procedure": "ğŸ“‹",
                                    "Scenario": "ğŸ¥", "Image": "ğŸ–¼ï¸"
                                }
                                persona_icons = {
                                    "í•™ìˆ ì „ë¬¸ê°€": "ğŸ“š", "ì„ìƒì „ë¬¸ê°€": "ğŸ¥",
                                    "ì‹œí—˜ì „ë¬¸ê°€": "ğŸ“", "ìµœê·¼í•©ê²©ì": "ğŸ“"
                                }
                                st.info(f"ğŸ“Š AI ë¶„ì„ ê²°ê³¼: {type_icons.get(question_type, 'ğŸ“')} {question_type} ìœ í˜• | {persona_icons.get(persona, 'ğŸ“')} {persona} ìŠ¤íƒ€ì¼")

                                # Generate problems using GPT-4o mini
                                from openai import OpenAI
                                client = OpenAI(api_key=OPENAI_API_KEY)

                                # Build detailed original problem context
                                original_choices = prob.get('choices', [])
                                choices_text = "\n".join([f"ì„ íƒì§€ {i+1}: {choice}" for i, choice in enumerate(original_choices)])

                                # Get correct answer (check both field names and calculate from index if needed)
                                original_correct_answer = prob.get('correctAnswer') or prob.get('correctanswer')
                                if not original_correct_answer and original_choices:
                                    answer_idx = prob.get('answer')
                                    if answer_idx is not None and 0 <= answer_idx < len(original_choices):
                                        original_correct_answer = original_choices[answer_idx]

                                # ë‚œì´ë„ ë¶„í¬ ê²°ì • (ê· í˜•í˜•)
                                target_difficulties = ['í•˜', 'ì¤‘', 'ì¤‘', 'ìƒ', 'í•˜']  # 5ê°œ ìƒì„±

                                st.info(f"ğŸ¯ ë‚œì´ë„ ë¶„í¬: í•˜ 2ê°œ, ì¤‘ 2ê°œ, ìƒ 1ê°œ")

                                # ìŠ¤ë§ˆíŠ¸ ë¬¸ì œ ìƒì„± ì‹œìŠ¤í…œ ì‚¬ìš©
                                generated_problems_list, generation_stats = smart_problem_generator.generate_with_difficulty_control(
                                    original_problem=prob,
                                    target_difficulties=target_difficulties,
                                    question_type=question_type,
                                    persona=persona
                                )

                                # ìƒì„± í†µê³„ í‘œì‹œ
                                st.success(f"âœ… ìƒì„± ì™„ë£Œ: {generation_stats['total_generated']}ê°œ / {generation_stats['total_requested']}ê°œ")
                                st.info(f"ğŸ“Š ëª¨ë¸ ì‚¬ìš©: {', '.join([f'{k}({v}ê°œ)' for k, v in generation_stats['models_used'].items()])}")
                                st.info(f"âœ”ï¸ ë‚œì´ë„ ê²€ì¦: í†µê³¼ {generation_stats['validation_passed']}ê°œ / ìˆ˜ì • {generation_stats['difficulty_corrections']}ê°œ")

                                # ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                                generated_problems = generated_problems_list

                                # ChromaDB-based duplicate checker (uses semantic similarity)
                                def is_duplicate_problem_chromadb(new_question, new_answer):
                                    """Check if problem is duplicate using ChromaDB semantic search"""
                                    chroma = st.session_state.chroma_manager
                                    if not chroma or not chroma.problems_collection:
                                        return False, 0.0

                                    try:
                                        # Combine question + answer for search
                                        combined_text = f"{new_question} {new_answer}"

                                        # Query ChromaDB for similar problems
                                        results = chroma.problems_collection.query(
                                            query_texts=[combined_text],
                                            n_results=1  # Get top 1 most similar
                                        )

                                        if results and results['distances'] and len(results['distances'][0]) > 0:
                                            # ChromaDB returns distance (lower = more similar)
                                            # Convert to similarity score (0-1, higher = more similar)
                                            distance = results['distances'][0][0]
                                            similarity = 1.0 - (distance / 2.0)  # Normalize to 0-1

                                            # Threshold: 0.85 = very similar
                                            if similarity > 0.85:
                                                return True, similarity
                                            return False, similarity
                                        return False, 0.0
                                    except Exception as e:
                                        st.warning(f"ChromaDB ê²€ìƒ‰ ì‹¤íŒ¨, ì¤‘ë³µ ì²´í¬ ìŠ¤í‚µ: {e}")
                                        return False, 0.0

                                # Store in session state for approval workflow
                                if 'pending_problems' not in st.session_state:
                                    st.session_state.pending_problems = {}

                                # Validate and prepare for approval with duplicate retry
                                valid_problems = []
                                skipped_count = 0
                                duplicate_count = 0
                                MAX_RETRY = 5  # Maximum retry per problem

                                progress_text = st.empty()
                                for idx, gen_prob in enumerate(generated_problems):
                                    progress_text.info(f"ë¬¸ì œ {idx+1}/{len(generated_problems)} ê²€ì¦ ì¤‘...")

                                    # Retry loop for duplicate problems
                                    retry_count = 0
                                    current_problem = gen_prob

                                    while retry_count <= MAX_RETRY:
                                        # Check for semantic duplicate using ChromaDB
                                        is_dup, similarity_score = is_duplicate_problem_chromadb(
                                            current_problem.get('questionText', ''),
                                            current_problem.get('correctanswer', '')
                                        )

                                        if is_dup and retry_count < MAX_RETRY:
                                            duplicate_count += 1
                                            retry_count += 1
                                            progress_text.warning(f"ë¬¸ì œ {idx+1}: ì¤‘ë³µ ê°ì§€ (ìœ ì‚¬ë„: {similarity_score:.2f}) - ì¬ìƒì„± ì‹œë„ {retry_count}/{MAX_RETRY}")

                                        # ì¤‘ë³µ ê°ì§€ ì‹œ ì¬ìƒì„±
                                        if is_dup and retry_count < MAX_RETRY:
                                            # Regenerate single problem
                                            try:
                                                regenerate_prompt = f"""ì´ì „ì— ìƒì„±í•œ ë¬¸ì œê°€ ê¸°ì¡´ ë¬¸ì œì™€ ë„ˆë¬´ ìœ ì‚¬í•©ë‹ˆë‹¤.
ë‹¤ë¥¸ ê°ë„ì—ì„œ ì ‘ê·¼í•˜ì—¬ ìƒˆë¡œìš´ ë¬¸ì œë¥¼ 1ê°œë§Œ ìƒì„±í•´ì£¼ì„¸ìš”.

[ì›ë³¸ ë¬¸ì œ]
ì§ˆë¬¸: {prob.get('questionText')}
ì •ë‹µ: {original_correct_answer}
ë‚œì´ë„: {prob.get('difficulty', 'ì¤‘')}

[ìƒì„± ìš”êµ¬ì‚¬í•­]
- ì™„ì „íˆ ë‹¤ë¥¸ ì„ìƒ ìƒí™© ì‚¬ìš©
- ë‹¤ë¥¸ ë‚˜ì´ëŒ€, ë‹¤ë¥¸ ì¦ìƒ, ë‹¤ë¥¸ ì‹œë‚˜ë¦¬ì˜¤
- í•˜ì§€ë§Œ ê°™ì€ ê°œë…ì„ í…ŒìŠ¤íŠ¸
- ì„ íƒì§€ 5ê°œ í•„ìˆ˜
- í•´ì„¤ ì—†ìŒ
- ë‚œì´ë„ëŠ” ì›ë³¸ê³¼ ë™ì¼í•˜ê±°ë‚˜ ì•½ê°„ ì‰½ê²Œ

JSON í˜•ì‹:
{{
  "questionText": "...",
  "choices": ["...", "...", "...", "...", "..."],
  "answer": 0,
  "correctanswer": "...",
  "difficulty": "{prob.get('difficulty', 'ì¤‘')}"
}}"""

                                                regen_response = client.chat.completions.create(
                                                    model="gpt-4o-mini",
                                                    messages=[
                                                        {"role": "system", "content": system_prompt},
                                                        {"role": "user", "content": regenerate_prompt}
                                                    ],
                                                    temperature=0.9  # Higher temperature for more variety
                                                )

                                                regen_content = regen_response.choices[0].message.content.strip()
                                                if regen_content.startswith('```json'):
                                                    regen_content = regen_content[7:]
                                                if regen_content.endswith('```'):
                                                    regen_content = regen_content[:-3]

                                                current_problem = json.loads(regen_content.strip())
                                                continue  # Retry duplicate check

                                            except Exception as regen_error:
                                                progress_text.error(f"ì¬ìƒì„± ì‹¤íŒ¨: {regen_error}")
                                                break

                                        elif is_dup and retry_count >= MAX_RETRY:
                                            # Give up after MAX_RETRY attempts
                                            progress_text.error(f"ë¬¸ì œ {idx+1}: {MAX_RETRY}íšŒ ì¬ì‹œë„ í›„ì—ë„ ì¤‘ë³µ - ê±´ë„ˆë›°ê¸°")
                                            current_problem = None
                                            break
                                        else:
                                            # Not duplicate, proceed
                                            problem_difficulty = current_problem.get('difficulty', 'ì¤‘')

                                            # ë‚œì´ë„ ê²€ì¦ì€ smart_problem_generatorì—ì„œ ì´ë¯¸ ì™„ë£Œë¨
                                            validation_details = current_problem.get('_validation_details', {})
                                            if not validation_details.get('is_valid', True):
                                                progress_text.info(f"ë¬¸ì œ {idx+1}: ë‚œì´ë„ ìë™ ìˆ˜ì • ({validation_details.get('claimed')} â†’ {validation_details.get('actual')})")

                                            break

                                    # Skip if couldn't generate unique problem
                                    if current_problem is None:
                                        skipped_count += 1
                                        continue

                                    # Validate 5 choices
                                    choices = current_problem.get('choices', [])
                                    if len(choices) != 5:
                                        progress_text.warning(f"âš ï¸ ë¬¸ì œ {idx+1}: ì„ íƒì§€ê°€ {len(choices)}ê°œ (5ê°œ í•„ìˆ˜) - ê±´ë„ˆë›°ê¸°")
                                        skipped_count += 1
                                        continue

                                    # Validate answer index
                                    answer = current_problem.get('answer', 0)
                                    if not (0 <= answer <= 4):
                                        progress_text.warning(f"âš ï¸ ë¬¸ì œ {idx+1}: ì •ë‹µ ë²ˆí˜¸ ì˜¤ë¥˜ - ê±´ë„ˆë›°ê¸°")
                                        skipped_count += 1
                                        continue

                                    # AI ëª¨ë¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (smart_problem_generatorì—ì„œ ìƒì„±)
                                    generation_model = current_problem.get('_generated_by', 'unknown')
                                    verification_model = None  # ê²€ì¦ì€ ë‚œì´ë„ ë¶„ë¥˜ê¸°ê°€ ìˆ˜í–‰

                                    new_problem = {
                                        'questionText': current_problem['questionText'],
                                        'choices': choices,
                                        'answer': answer,
                                        'correctanswer': current_problem['correctanswer'],
                                        # No explanation - students can request it separately

                                        # Tag-based system (Proposal 1)
                                        'subject': None,  # AI-generated problems have no fixed subject
                                        'relatedSubjects': [prob.get('subject')],  # Related subjects array
                                        'relatedConcepts': prob.get('keywords', []),  # Concept-based

                                        'field': prob.get('field'),
                                        'difficulty': current_problem.get('difficulty', 'ì¤‘'),  # Use AI-generated difficulty
                                        'keywords': prob.get('keywords', []),

                                        # AI model tracking
                                        'aiModels': {
                                            'generation': generation_model,
                                            'verification': verification_model,
                                            'questionType': question_type,
                                            'persona': persona
                                        },

                                        # Priority & metadata
                                        'priority': 2,  # 1=manual, 2=AI-generated
                                        'source': 'ai-generated',
                                        'generatedFrom': prob['id'],
                                        'generatedBy': f"{generation_model}{'+' + verification_model if verification_model else ''}",
                                        'createdAt': get_iso_timestamp()
                                    }

                                    valid_problems.append(new_problem)
                                    progress_text.success(f"ë¬¸ì œ {idx+1}: âœ… ê²€ì¦ ì™„ë£Œ")

                                progress_text.empty()

                                # Store for approval
                                problem_key = f"{prob['id']}_generated"
                                st.session_state.pending_problems[problem_key] = valid_problems

                                if len(valid_problems) > 0:
                                    st.success(f"âœ… {len(valid_problems)}ê°œ ë¬¸ì œ ìƒì„± ì™„ë£Œ! ì•„ë˜ì—ì„œ ê²€í†  í›„ ìŠ¹ì¸í•´ì£¼ì„¸ìš”.")
                                if duplicate_count > 0:
                                    st.info(f"â„¹ï¸ {duplicate_count}ê°œ ë¬¸ì œëŠ” ì˜ë¯¸ì  ì¤‘ë³µìœ¼ë¡œ ìŠ¤í‚µí–ˆìŠµë‹ˆë‹¤. (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ > 0.85)")
                                if skipped_count > 0:
                                    st.info(f"â„¹ï¸ {skipped_count}ê°œ ë¬¸ì œëŠ” ê²€ì¦ ì‹¤íŒ¨ë¡œ ìƒì„±í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

                                # Display generated problems for approval
                                st.divider()
                                st.subheader("ğŸ” ìƒì„±ëœ ë¬¸ì œ ê²€í† ")

                                # Initialize saved/rejected tracking
                                if 'saved_problems' not in st.session_state:
                                    st.session_state.saved_problems = set()
                                if 'rejected_problems' not in st.session_state:
                                    st.session_state.rejected_problems = set()
                                # Initialize save logs tracking
                                if 'save_logs' not in st.session_state:
                                    st.session_state.save_logs = []

                                # Count processed problems for this original problem
                                processed_count = sum(1 for idx in range(len(valid_problems))
                                                     if f"{prob['id']}_{idx}" in st.session_state.saved_problems or
                                                        f"{prob['id']}_{idx}" in st.session_state.rejected_problems)

                                # If all problems processed, mark original as complete
                                if processed_count == len(valid_problems):
                                    st.session_state.processed_wrong_problems.add(prob['id'])
                                    st.success(f"âœ… ëª¨ë“  ìƒì„± ë¬¸ì œ ì²˜ë¦¬ ì™„ë£Œ! ì´ ì›ë³¸ ë¬¸ì œê°€ ëª©ë¡ì—ì„œ ì œê±°ë©ë‹ˆë‹¤.")
                                    st.rerun()

                                # Bulk actions - show only if there are unprocessed problems
                                unprocessed_indices = [idx for idx in range(len(valid_problems))
                                                      if f"{prob['id']}_{idx}" not in st.session_state.saved_problems and
                                                         f"{prob['id']}_{idx}" not in st.session_state.rejected_problems]

                                if unprocessed_indices:
                                    col1, col2, col3 = st.columns([2, 1, 1])
                                    with col1:
                                        st.caption(f"ë¯¸ì²˜ë¦¬ ë¬¸ì œ: {len(unprocessed_indices)}ê°œ")
                                    with col2:
                                        if st.button("âœ… ëª¨ë‘ ìŠ¹ì¸", key=f"approve_all_{prob['id']}", type="primary"):
                                            st.write(f"DEBUG: valid_problems ê°œìˆ˜ = {len(valid_problems)}")
                                            st.write(f"DEBUG: unprocessed_indices = {unprocessed_indices}")

                                            saved_count = 0
                                            chroma = st.session_state.chroma_manager
                                            fs = FirebaseStorage()

                                            # Progress tracking
                                            total_count = len(unprocessed_indices)
                                            progress_placeholder = st.empty()
                                            status_placeholder = st.empty()

                                            for idx_num, idx in enumerate(unprocessed_indices, 1):
                                                st.write(f"DEBUG: ì²˜ë¦¬ ì¤‘ idx={idx}, valid_problems[{idx}] exists = {idx < len(valid_problems)}")
                                                prob_hash = f"{prob['id']}_{idx}"

                                                # Update progress
                                                progress_placeholder.progress(idx_num / total_count)
                                                status_placeholder.info(f"[{idx_num}/{total_count}] ë¬¸ì œ ì €ì¥ ì¤‘...")

                                                try:
                                                    # === STEP 1: ì¤‘ë³µ ê²€ì‚¬ ===
                                                    status_placeholder.info(f"[{idx_num}/{total_count}] STEP 1: ì¤‘ë³µ ê²€ì‚¬ ì¤‘...")

                                                    # TODO: ì¤‘ë³µ ê²€ì‚¬ ë¡œì§ ì¶”ê°€ (í˜„ì¬ëŠ” ìŠ¤í‚µ)
                                                    is_duplicate = False
                                                    max_similarity = 0.0

                                                    log_entry = f"âœ… [{idx_num}/{total_count}] STEP 1: ì¤‘ë³µ ê²€ì‚¬ ì™„ë£Œ (ìœ ì‚¬ë„: {max_similarity:.3f})"
                                                    st.session_state.save_logs.append(log_entry)

                                                    # === STEP 2: ChromaDB ì €ì¥ ===
                                                    status_placeholder.info(f"[{idx_num}/{total_count}] STEP 2: ChromaDB ì €ì¥ ì¤‘...")

                                                    # Generate unique ID
                                                    problem_id = str(uuid.uuid4())

                                                    if chroma and chroma.problems_collection:
                                                        try:
                                                            chroma_data = {
                                                                'id': problem_id,
                                                                'question_text': valid_problems[idx].get('questionText', ''),
                                                                'choices': valid_problems[idx].get('choices', []),
                                                                'correct_answer': valid_problems[idx].get('correctanswer', ''),
                                                                'subject': prob.get('subject', ''),
                                                                'difficulty': valid_problems[idx].get('difficulty', ''),
                                                                'keywords': valid_problems[idx].get('keywords', []),
                                                                'concepts': valid_problems[idx].get('relatedConcepts', []),
                                                                'created_at': str(valid_problems[idx].get('createdAt', ''))
                                                            }
                                                            chroma.add_problem(chroma_data)

                                                            # Log ChromaDB save
                                                            log_entry = f"âœ… [{idx_num}/{total_count}] STEP 2: ChromaDB ì €ì¥ ì™„ë£Œ (ID: {problem_id[:8]}...)"
                                                            st.session_state.save_logs.append(log_entry)
                                                        except Exception as chroma_error:
                                                            # Log ChromaDB failure
                                                            log_entry = f"âš ï¸ [{idx_num}/{total_count}] STEP 2: ChromaDB ì‹¤íŒ¨: {str(chroma_error)[:50]}..."
                                                            st.session_state.save_logs.append(log_entry)
                                                            raise  # Re-raise to skip Firebase save

                                                    # === STEP 3: Firebase ì €ì¥ ===
                                                    status_placeholder.info(f"[{idx_num}/{total_count}] STEP 3: Firebase ì €ì¥ ì¤‘...")

                                                    # Prepare data for Firebase (convert datetime to string)
                                                    problem_data = valid_problems[idx].copy()
                                                    problem_data['id'] = problem_id  # Use same ID as ChromaDB
                                                    problem_data = ensure_created_at_iso(problem_data)

                                                    # Save to Firebase via storage adapter
                                                    save_result = fs.save_problem('nursing_problems', problem_data)
                                                    if not save_result.get('success'):
                                                        raise RuntimeError(save_result.get('message', 'Firebase save failed'))

                                                    status_placeholder.success(f"[{idx_num}/{total_count}] âœ… ì „ì²´ ì €ì¥ ì™„ë£Œ (ID: {problem_id[:8]}...)")

                                                    # Log Firebase save
                                                    log_entry = f"âœ… [{idx_num}/{total_count}] STEP 3: Firebase ì €ì¥ ì™„ë£Œ (ID: {problem_id[:8]}...)"
                                                    st.session_state.save_logs.append(log_entry)

                                                    st.session_state.saved_problems.add(prob_hash)
                                                    saved_count += 1
                                                except Exception as save_error:
                                                    status_placeholder.error(f"[{idx_num}/{total_count}] âŒ ë¬¸ì œ ì €ì¥ ì‹¤íŒ¨: {save_error}")

                                                    # Log save failure
                                                    log_entry = f"âŒ [{idx_num}/{total_count}] ì €ì¥ ì‹¤íŒ¨: {str(save_error)[:50]}..."
                                                    st.session_state.save_logs.append(log_entry)

                                            # Clear progress indicators and show final message
                                            progress_placeholder.empty()

                                            # Only rerun if at least one problem was successfully saved
                                            if saved_count > 0:
                                                status_placeholder.success(f"âœ… {saved_count}/{total_count}ê°œ ë¬¸ì œë¥¼ Firebase + ChromaDBì— ì €ì¥í–ˆìŠµë‹ˆë‹¤!")

                                                # Verify data was saved by checking ChromaDB count
                                                try:
                                                    verify_count = chroma.problems_collection.count() if chroma and chroma.problems_collection else 0
                                                    st.info(f"ğŸ“Š í˜„ì¬ ai_questions ì´ ë¬¸ì œ ìˆ˜: {verify_count}")
                                                except Exception as e:
                                                    st.warning(f"âš ï¸ ê²€ì¦ ì‹¤íŒ¨: {e}")

                                                # ìë™ ìƒˆë¡œê³ ì¹¨ì„ í”¼í•˜ê³  ì‚¬ìš©ìì—ê²Œ ê²°ê³¼ë¥¼ ë‚¨ê¹ë‹ˆë‹¤.
                                                # í•„ìš” ì‹œ ì‚¬ìš©ìê°€ ìˆ˜ë™ìœ¼ë¡œ ìƒˆë¡œê³ ì¹¨í•˜ê±°ë‚˜ ë‹¤ìŒ ì‘ì—…ì„ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                                            else:
                                                status_placeholder.error(f"âŒ {total_count}ê°œ ë¬¸ì œ ì €ì¥ ëª¨ë‘ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ìœ„ì˜ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

                                    with col3:
                                        if st.button("âŒ ëª¨ë‘ ê±°ë¶€", key=f"reject_all_{prob['id']}"):
                                            for idx in unprocessed_indices:
                                                prob_hash = f"{prob['id']}_{idx}"
                                                st.session_state.rejected_problems.add(prob_hash)
                                            st.info(f"âŒ {len(unprocessed_indices)}ê°œ ë¬¸ì œë¥¼ ê±°ë¶€í–ˆìŠµë‹ˆë‹¤.")
                                            st.rerun()

                                    st.divider()

                                for idx, new_prob in enumerate(valid_problems):
                                    prob_hash = f"{prob['id']}_{idx}"

                                    # Skip if already processed
                                    if prob_hash in st.session_state.saved_problems:
                                        st.success(f"âœ… ë¬¸ì œ {idx+1}: Firebaseì— ì €ì¥ ì™„ë£Œ")
                                        continue
                                    if prob_hash in st.session_state.rejected_problems:
                                        st.info(f"âŒ ë¬¸ì œ {idx+1}: ê±°ë¶€ë¨")
                                        continue

                                    with st.expander(f"ğŸ“ ìƒì„± ë¬¸ì œ {idx+1}", expanded=True):
                                        # AI ëª¨ë¸ ì •ë³´ í‘œì‹œ
                                        ai_models = new_prob.get('aiModels', {})
                                        gen_model = ai_models.get('generation', 'unknown')
                                        ver_model = ai_models.get('verification')
                                        q_type = ai_models.get('questionType', 'unknown')
                                        persona_used = ai_models.get('persona', 'unknown')

                                        model_info = f"AI: {gen_model}"
                                        if ver_model:
                                            model_info += f" + {ver_model}"
                                        model_info += f" | {q_type} | {persona_used}"

                                        st.caption(f"ğŸ¤– {model_info}")

                                        st.markdown(f"**ì§ˆë¬¸:** {new_prob['questionText']}")
                                        st.markdown("**ë³´ê¸°:**")
                                        for i, choice in enumerate(new_prob['choices'], 1):
                                            st.markdown(f"{i}. {choice}")
                                        st.markdown(f"**ì •ë‹µ:** {new_prob['correctanswer']}")
                                        st.markdown(f"**ë‚œì´ë„:** {new_prob.get('difficulty', 'ì¤‘')}")
                                        st.caption("ğŸ’¡ í•´ì„¤ì€ í•™ìƒì´ ë¬¸ì œë¥¼ í‹€ë ¸ì„ ë•Œ ìš”ì²­í•˜ë©´ ìƒì„±ë©ë‹ˆë‹¤.")

                                        col1, col2 = st.columns(2)
                                        with col1:
                                            if st.button("âœ… ìŠ¹ì¸ (ì €ì¥)", key=f"approve_{prob_hash}", type="primary"):
                                                try:
                                                    # Prepare data for Firebase (convert datetime to string)
                                                    problem_data = ensure_created_at_iso(new_prob.copy())

                                                    # Save to Firebase via storage adapter
                                                    fs = FirebaseStorage()
                                                    save_result = fs.save_problem('nursing_problems', problem_data)
                                                    if not save_result.get('success'):
                                                        raise RuntimeError(save_result.get('message', 'Firebase save failed'))
                                                    problem_id = save_result.get('id')

                                                    # Save to ChromaDB for semantic search
                                                    chroma = st.session_state.chroma_manager
                                                    if chroma and chroma.problems_collection:
                                                        try:
                                                            chroma_data = {
                                                                'id': problem_id,
                                                                'question_text': new_prob.get('questionText', ''),
                                                                'choices': new_prob.get('choices', []),
                                                                'correct_answer': new_prob.get('correctanswer', ''),
                                                                'subject': prob.get('subject', ''),
                                                                'difficulty': new_prob.get('difficulty', ''),
                                                                'keywords': new_prob.get('keywords', []),
                                                                'concepts': new_prob.get('relatedConcepts', []),
                                                                'created_at': str(new_prob.get('createdAt', ''))
                                                            }
                                                            chroma.add_problem(chroma_data)
                                                        except Exception as chroma_error:
                                                            st.warning(f"ChromaDB ì €ì¥ ì‹¤íŒ¨ (ê²€ìƒ‰ì—ë§Œ ì˜í–¥): {chroma_error}")

                                                    st.session_state.saved_problems.add(prob_hash)
                                                    st.success("âœ… Firebase + ChromaDBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                                                    st.rerun()
                                                except Exception as save_error:
                                                    st.error(f"âŒ ì €ì¥ ì‹¤íŒ¨: {save_error}")

                                        with col2:
                                            if st.button("âŒ ê±°ë¶€", key=f"reject_{prob_hash}"):
                                                st.session_state.rejected_problems.add(prob_hash)
                                                st.info("ë¬¸ì œë¥¼ ê±°ë¶€í–ˆìŠµë‹ˆë‹¤.")
                                                st.rerun()

                            except Exception as e:
                                st.error(f"âŒ ë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {e}")

    except Exception as e:
        st.error(f"âŒ í‹€ë¦° ë¬¸ì œ ë¡œë“œ ì‹¤íŒ¨: {e}")


if __name__ == "__main__":
    main()




