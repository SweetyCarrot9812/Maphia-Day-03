"""
Lingumo Manual Input Form - Language Learning Content (Words and Sentences)
"""
import streamlit as st
import uuid
from datetime import datetime


def handle_lingumo_audio_upload():
    """Handle audio file upload or TTS generation for language learning content"""
    st.subheader("ğŸ”Š ì˜¤ë””ì˜¤ ì„¤ì • (ì„ íƒì‚¬í•­)")

    audio_col1, audio_col2 = st.columns(2)

    with audio_col1:
        auto_generate_tts = st.checkbox(
            "TTS ìë™ ìƒì„±",
            value=False,
            help="ì €ì¥ ì‹œ Google TTS/ElevenLabsë¡œ ìë™ ìƒì„± (API í‚¤ í•„ìš”)",
            key="auto_generate_tts"
        )

        if auto_generate_tts:
            st.info("ğŸ’¡ ì €ì¥ ì‹œ ìë™ìœ¼ë¡œ ìŒì„±ì´ ìƒì„±ë©ë‹ˆë‹¤ (API í‚¤ ì„¤ì • í•„ìš”)")

    with audio_col2:
        if not auto_generate_tts:
            uploaded_audio = st.file_uploader(
                "ì˜¤ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ",
                type=['mp3', 'wav', 'ogg', 'm4a'],
                help="MP3, WAV, OGG, M4A í˜•ì‹ ì§€ì›",
                key="lingumo_audio"
            )

            if uploaded_audio:
                audio_bytes = uploaded_audio.getvalue()
                file_size = len(audio_bytes)

                st.success(f"âœ… ì—…ë¡œë“œë¨: {uploaded_audio.name} ({file_size / 1024:.1f} KB)")

                # Preview audio
                st.audio(audio_bytes, format=f'audio/{uploaded_audio.name.split(".")[-1]}')

                st.session_state.lingumo_audio_file = {
                    'original_name': uploaded_audio.name,
                    'audio_bytes': audio_bytes,
                    'file_size': file_size,
                    'file_ext': uploaded_audio.name.split('.')[-1]
                }

            if 'lingumo_audio_file' in st.session_state and not uploaded_audio:
                audio_data = st.session_state.lingumo_audio_file
                st.info(f"[READY] {audio_data['original_name']}")
        else:
            st.info("ğŸ“¢ ë‹¨ì–´: Google TTS\nğŸ™ï¸ ë¬¸ì¥: ElevenLabs")

    return st.session_state.get('lingumo_audio_file', None)


def handle_lingumo_image_upload():
    """Handle image upload for language learning content"""
    st.subheader("[IMAGE] ì´ë¯¸ì§€ ì—…ë¡œë“œ (ì„ íƒì‚¬í•­)")

    uploaded_images = st.file_uploader(
        "ì–¸ì–´ í•™ìŠµ ê´€ë ¨ ì´ë¯¸ì§€ (ì—¬ëŸ¬ ê°œ ì„ íƒ ê°€ëŠ¥)",
        type=['png', 'jpg', 'jpeg', 'webp'],
        accept_multiple_files=True,
        help="ë‹¨ì–´ ì´ë¯¸ì§€, ë¬¸ë²• ì°¨íŠ¸ ë“±ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (PNG, JPG, JPEG, WebP ì§€ì›)",
        key="lingumo_images"
    )

    if uploaded_images:
        from image_utils import image_processor

        st.success(f"[AUTO] {len(uploaded_images)}ê°œ ì´ë¯¸ì§€ ìë™ ì••ì¶• ì¤‘...")

        with st.spinner("[PROCESSING] ì´ë¯¸ì§€ ì••ì¶• ì¤‘..."):
            compressed_images = []
            for idx, uploaded_file in enumerate(uploaded_images):
                compressed_bytes, file_ext = image_processor.compress_image(uploaded_file)

                if compressed_bytes:
                    original_size = len(uploaded_file.getvalue())
                    compressed_size = len(compressed_bytes)
                    compression_ratio = (1 - compressed_size / original_size) * 100

                    compressed_images.append({
                        'original_name': uploaded_file.name,
                        'compressed_bytes': compressed_bytes,
                        'file_ext': file_ext,
                        'original_size': original_size,
                        'compressed_size': compressed_size,
                        'compression_ratio': compression_ratio
                    })

        if compressed_images:
            st.success(f"[SUCCESS] {len(compressed_images)}ê°œ ì´ë¯¸ì§€ ì••ì¶• ì™„ë£Œ!")

            cols = st.columns(min(len(compressed_images), 3))
            for idx, img_data in enumerate(compressed_images[:3]):
                with cols[idx % 3]:
                    st.image(img_data['compressed_bytes'],
                            caption=f"{img_data['original_name']}\nì••ì¶•ë¥ : {img_data['compression_ratio']:.1f}%",
                            width=150)

            if len(compressed_images) > 3:
                st.info(f"[INFO] ì¶”ê°€ {len(compressed_images)-3}ê°œ ì´ë¯¸ì§€")

            st.session_state.lingumo_compressed_images = compressed_images
            st.info("[INFO] ì´ë¯¸ì§€ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. ë‚´ìš©ì„ ì…ë ¥í•˜ê³  [SAVE] ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ì €ì¥ë©ë‹ˆë‹¤.")
        else:
            st.error("[ERROR] ì´ë¯¸ì§€ ì••ì¶•ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")

    if 'lingumo_compressed_images' in st.session_state and not uploaded_images:
        compressed_images = st.session_state.lingumo_compressed_images
        st.info(f"[READY] {len(compressed_images)}ê°œ ì••ì¶•ëœ ì´ë¯¸ì§€ê°€ ì €ì¥ ëŒ€ê¸° ì¤‘ì…ë‹ˆë‹¤")

    return st.session_state.get('lingumo_compressed_images', [])


def lingumo_content_input_form():
    """Manual form for inputting language learning content (words and sentences)"""
    st.subheader("ğŸŒ ì–¸ì–´ í•™ìŠµ ì½˜í…ì¸  ìˆ˜ë™ ì…ë ¥")

    handle_lingumo_audio_upload()

    st.divider()

    handle_lingumo_image_upload()

    st.divider()

    with st.form("lingumo_manual_form"):

        st.subheader("[INPUT] í•™ìŠµ ë‚´ìš© ì§ì ‘ ì…ë ¥")

        col1, col2 = st.columns(2)

        with col1:
            content_type = st.selectbox(
                "ì½˜í…ì¸  ìœ í˜• *",
                options=["ë‹¨ì–´", "ë¬¸ì¥", "ë¬¸ë²•"],
                help="í•™ìŠµ ì½˜í…ì¸  ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”",
                key="lingumo_content_type"
            )

            language = st.selectbox(
                "ì–¸ì–´ *",
                options=["ì˜ì–´", "ì¼ë³¸ì–´", "ì¤‘êµ­ì–´", "ìŠ¤í˜ì¸ì–´", "í”„ë‘ìŠ¤ì–´", "ë…ì¼ì–´", "ê¸°íƒ€"],
                help="í•™ìŠµí•  ì–¸ì–´ë¥¼ ì„ íƒí•˜ì„¸ìš”",
                key="lingumo_language"
            )

            content_text = st.text_area(
                "ë‚´ìš© (ë‹¨ì–´/ë¬¸ì¥/ë¬¸ë²•)",
                height=100,
                help="í•™ìŠµí•  ë‹¨ì–´, ë¬¸ì¥ ë˜ëŠ” ë¬¸ë²•ì„ ì…ë ¥í•˜ì„¸ìš”",
                key="lingumo_content_text"
            )

            translation = st.text_area(
                "ë²ˆì—­/ì˜ë¯¸",
                height=100,
                help="í•œêµ­ì–´ ë²ˆì—­ ë˜ëŠ” ì˜ë¯¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
                key="lingumo_translation"
            )

        with col2:
            difficulty = st.selectbox(
                "ë‚œì´ë„",
                options=["ì´ˆê¸‰", "ì¤‘ê¸‰", "ê³ ê¸‰", "ì›ì–´ë¯¼"],
                help="í•™ìŠµ ë‚œì´ë„ë¥¼ ì„ íƒí•˜ì„¸ìš”",
                key="lingumo_difficulty"
            )

            if content_type == "ë‹¨ì–´":
                pronunciation = st.text_input(
                    "ë°œìŒ",
                    help="ë°œìŒ í‘œê¸° (ì˜ˆ: /prÉ™ËŒnÊŒnsiËˆeÉªÊƒn/)",
                    key="lingumo_pronunciation"
                )

                part_of_speech = st.selectbox(
                    "í’ˆì‚¬",
                    options=["ëª…ì‚¬", "ë™ì‚¬", "í˜•ìš©ì‚¬", "ë¶€ì‚¬", "ì „ì¹˜ì‚¬", "ì ‘ì†ì‚¬", "ê¸°íƒ€"],
                    help="í’ˆì‚¬ë¥¼ ì„ íƒí•˜ì„¸ìš”",
                    key="lingumo_pos"
                )

            example_sentence = st.text_area(
                "ì˜ˆë¬¸ (ì„ íƒì‚¬í•­)",
                height=80,
                help="ì˜ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”",
                key="lingumo_example"
            )

            tags = st.text_input(
                "íƒœê·¸",
                help="íƒœê·¸ë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ì…ë ¥ (ì˜ˆ: TOEIC, ë¹„ì¦ˆë‹ˆìŠ¤, ì—¬í–‰)",
                key="lingumo_tags"
            )

        duplicate_threshold = st.slider(
            "ì¤‘ë³µ ìœ ì‚¬ë„ ì„ê³„ê°’",
            min_value=0.70,
            max_value=0.99,
            value=0.92,
            step=0.01,
            help="ì´ ê°’ ì´ìƒì˜ ìœ ì‚¬ë„ë¥¼ ê°€ì§„ ì½˜í…ì¸ ê°€ ìˆìœ¼ë©´ ì¤‘ë³µìœ¼ë¡œ íŒë‹¨ (ê¶Œì¥: 0.92-0.95)",
            key="lingumo_duplicate_threshold"
        )

        st.info("""
        **ìœ ì‚¬ë„ ê¸°ì¤€:**
        - 0.95+ : ê±°ì˜ ë™ì¼
        - 0.90-0.95 : ë§¤ìš° ìœ ì‚¬ (ê¶Œì¥ ì¤‘ë³µ ê¸°ì¤€)
        - 0.85-0.90 : ìœ ì‚¬í•œ ì£¼ì œ
        - 0.85 ë¯¸ë§Œ : ë‹¤ë¥¸ ì½˜í…ì¸ 
        """)

        submitted = st.form_submit_button("[SAVE] ì½˜í…ì¸  ì €ì¥")

        if submitted:
            # Handle audio (upload or auto-generate)
            audio_file = st.session_state.get('lingumo_audio_file', None)
            auto_generate = st.session_state.get('auto_generate_tts', False)
            audio_url = None

            # Option 1: Manual upload
            if audio_file and not auto_generate:
                st.info(f"[UPLOAD] ì˜¤ë””ì˜¤ íŒŒì¼ì„ Firebase Storageì— ì—…ë¡œë“œ ì¤‘...")
                try:
                    from firebase_service import firebase_service

                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    unique_id = str(uuid.uuid4())[:8]
                    file_name = f"audio/lingumo/lingumo_{timestamp}_{unique_id}.{audio_file['file_ext']}"

                    audio_url = firebase_service.upload_audio_to_storage(
                        audio_file['audio_bytes'],
                        file_name,
                        f'audio/{audio_file["file_ext"]}'
                    )

                    if audio_url:
                        st.success(f"[SUCCESS] ì˜¤ë””ì˜¤ Firebase ì—…ë¡œë“œ ì™„ë£Œ!")
                    else:
                        st.warning("[WARNING] ì˜¤ë””ì˜¤ ì—…ë¡œë“œ ì‹¤íŒ¨")

                except Exception as e:
                    st.error(f"[ERROR] ì˜¤ë””ì˜¤ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")

            # Option 2: Auto-generate TTS
            elif auto_generate and content_text.strip():
                st.info(f"[TTS] ì˜¤ë””ì˜¤ ìë™ ìƒì„± ì¤‘...")
                try:
                    from audio_utils import audio_generator

                    provider = "google" if content_type == "ë‹¨ì–´" else "elevenlabs"
                    content_id = str(uuid.uuid4())

                    audio_metadata = audio_generator.generate_and_upload_audio(
                        text=content_text.strip(),
                        language=language,
                        voice_name="en-US-Neural2-A (ë¯¸êµ­ ì—¬ì„±1)",  # ê¸°ë³¸ ìŒì„±
                        provider=provider,
                        content_id=content_id
                    )

                    if audio_metadata:
                        audio_url = audio_metadata['audio_url']
                        st.success(f"[SUCCESS] TTS ì˜¤ë””ì˜¤ ìƒì„± ë° ì—…ë¡œë“œ ì™„ë£Œ!")
                    else:
                        st.warning("[WARNING] TTS ìƒì„± ì‹¤íŒ¨ (API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”)")

                except Exception as e:
                    st.warning(f"[WARNING] TTS ìƒì„± ì‹¤íŒ¨: {e}")

            # Handle image upload
            compressed_images = st.session_state.get('lingumo_compressed_images', [])

            processed_images = []
            if compressed_images:
                st.info(f"[UPLOAD] {len(compressed_images)}ê°œ ì´ë¯¸ì§€ë¥¼ Firebase Storageì— ì—…ë¡œë“œ ì¤‘...")
                from image_utils import image_processor

                for img_data in compressed_images:
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    unique_id = str(uuid.uuid4())[:8]
                    file_name = f"lingumo_{timestamp}_{unique_id}.{img_data['file_ext']}"

                    local_path = image_processor.save_to_local(img_data['compressed_bytes'], file_name)

                    public_url = image_processor.upload_to_firebase_storage(
                        img_data['compressed_bytes'],
                        file_name,
                        'image/webp'
                    )

                    processed_images.append({
                        'original_name': img_data['original_name'],
                        'file_name': file_name,
                        'public_url': public_url if public_url else None,
                        'local_path': local_path if local_path else None,
                        'content_type': 'image/webp',
                        'original_size': img_data['original_size'],
                        'compressed_size': img_data['compressed_size'],
                        'compression_ratio': img_data['compression_ratio'],
                        'uploaded_at': datetime.now().isoformat()
                    })

                if processed_images:
                    st.success(f"[SUCCESS] {len(processed_images)}ê°œ ì´ë¯¸ì§€ Firebase ì—…ë¡œë“œ ì™„ë£Œ!")

            missing_fields = []
            has_content = bool(content_text.strip()) or bool(translation.strip()) or bool(processed_images)

            if not has_content:
                st.error("[ERROR] ë‚´ìš©, ë²ˆì—­, ë˜ëŠ” ì´ë¯¸ì§€ ì¤‘ í•˜ë‚˜ëŠ” ë°˜ë“œì‹œ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤")
            else:
                content_data = {
                    'id': str(uuid.uuid4()),
                    'type': 'lingumo_content',
                    'content_type': content_type,
                    'language': language,
                    'content_text': content_text.strip() if content_text else '',
                    'translation': translation.strip() if translation else '',
                    'difficulty': difficulty,
                    'example_sentence': example_sentence.strip() if example_sentence else '',
                    'tags': [t.strip() for t in tags.split(',') if t.strip()] if tags else [],
                    'created_at': datetime.now().isoformat(),
                    'hasImage': bool(processed_images),
                    'images': processed_images if processed_images else [],
                    'has_audio': bool(audio_url),
                    'audio_url': audio_url if audio_url else '',
                    'createdBy': 'streamlit_user'
                }

                if content_type == "ë‹¨ì–´":
                    content_data['pronunciation'] = pronunciation.strip() if pronunciation else ''
                    content_data['part_of_speech'] = part_of_speech

                # === Step 1: Duplicate Check ===
                st.header("[STEP 1] ì¤‘ë³µ ê²€ì‚¬")

                with st.spinner("[SEARCH] ìœ ì‚¬ ì½˜í…ì¸  ê²€ìƒ‰ ì¤‘..."):
                    try:
                        from rag_engine_multi_domain import multi_domain_rag_engine

                        collection_name = 'lingumo_knowledge'
                        collection = multi_domain_rag_engine.chroma_client.get_or_create_collection(
                            collection_name,
                            metadata={
                                "description": "Language learning content base",
                                "domain": "lingumo",
                                "embedding_model": "models/text-embedding-004",
                                "embedding_dim": 768
                            }
                        )

                        search_parts = []
                        if content_text.strip():
                            search_parts.append(content_text)
                        if translation.strip():
                            search_parts.append(translation)
                        search_text = ' '.join(search_parts) if search_parts else "lingumo content"

                        results = collection.query(
                            query_texts=[search_text],
                            n_results=5,
                            where={"type": "lingumo_content"}
                        )

                        max_similarity = 0.0
                        is_duplicate = False

                        if results.get('distances') and results['distances'][0]:
                            distances = results['distances'][0]
                            # ChromaDB uses L2 distance: smaller = more similar
                            # Convert to similarity score: 1/(1+distance)
                            similarities = [1 / (1 + d) for d in distances]
                            max_similarity = max(similarities) if similarities else 0.0

                            if max_similarity >= duplicate_threshold:
                                is_duplicate = True
                                st.warning(f"[DUPLICATE] ì¤‘ë³µ ê°€ëŠ¥ì„± ë†’ìŒ (ìµœëŒ€ ìœ ì‚¬ë„: {max_similarity:.3f})")
                            else:
                                st.success(f"[UNIQUE] ìƒˆë¡œìš´ ì½˜í…ì¸  (ìµœëŒ€ ìœ ì‚¬ë„: {max_similarity:.3f})")

                            if results.get('documents') and results['documents'][0]:
                                with st.expander("[DETAILS] ìœ ì‚¬ ì½˜í…ì¸  ê²°ê³¼", expanded=False):
                                    for i, (doc, sim) in enumerate(zip(results['documents'][0][:3], similarities[:3])):
                                        st.write(f"**{i+1}ìœ„** (ìœ ì‚¬ë„: {sim:.3f})")
                                        st.write(doc[:200] + "..." if len(doc) > 200 else doc)
                                        st.divider()
                        else:
                            st.info("[INFO] ì²« ë²ˆì§¸ ì½˜í…ì¸ ì…ë‹ˆë‹¤.")

                    except Exception as e:
                        st.error(f"[ERROR] ì¤‘ë³µ ê²€ì‚¬ ì‹¤íŒ¨: {e}")
                        max_similarity = 0.0
                        is_duplicate = False

                # === Step 2: TTS Audio Generation (if enabled) ===
                audio_metadata = None
                if st.session_state.get('enable_tts', False) and content_text.strip():
                    st.header("[STEP 2] TTS ì˜¤ë””ì˜¤ ìƒì„±")

                    with st.spinner("[TTS] ìŒì„± íŒŒì¼ ìƒì„± ë° ì—…ë¡œë“œ ì¤‘..."):
                        try:
                            from audio_utils import audio_generator

                            tts_voice = st.session_state.get('tts_voice', None)
                            if content_type == "ë‹¨ì–´":
                                provider = "google"
                            else:
                                provider = "elevenlabs"

                            if tts_voice:
                                audio_metadata = audio_generator.generate_and_upload_audio(
                                    text=content_text.strip(),
                                    language=language,
                                    voice_name=tts_voice,
                                    provider=provider,
                                    content_id=content_data['id']
                                )

                                if audio_metadata:
                                    st.success(f"âœ… TTS ì˜¤ë””ì˜¤ ìƒì„± ì™„ë£Œ!")
                                    st.success(f"ğŸ”— Firebase URL: {audio_metadata['audio_url'][:50]}...")
                                else:
                                    st.warning("âš ï¸ TTS ì˜¤ë””ì˜¤ ìƒì„± ì‹¤íŒ¨ (ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤)")
                            else:
                                st.warning("âš ï¸ ìŒì„±ì´ ì„ íƒë˜ì§€ ì•ŠìŒ")

                        except Exception as e:
                            st.warning(f"âš ï¸ TTS ì˜¤ë””ì˜¤ ìƒì„± ì‹¤íŒ¨: {e}")
                            import traceback
                            st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")

                # === Step 3: Direct Embedding & Save ===
                if not is_duplicate or st.checkbox("ì¤‘ë³µì´ì–´ë„ ì €ì¥í•˜ê¸°"):
                    st.header("[STEP 3] ì„ë² ë”© ë° ì €ì¥")

                    with st.spinner("[SAVE] ë²¡í„° ì„ë² ë”© ë° ì €ì¥ ì¤‘..."):
                        try:
                            doc_parts = []
                            doc_parts.append(f"ì–¸ì–´: {content_data['language']}")
                            doc_parts.append(f"ìœ í˜•: {content_data['content_type']}")
                            if content_data['content_text']:
                                doc_parts.append(f"ë‚´ìš©: {content_data['content_text']}")
                            if content_data['translation']:
                                doc_parts.append(f"ë²ˆì—­: {content_data['translation']}")
                            doc_parts.append(f"ë‚œì´ë„: {content_data['difficulty']}")

                            if content_type == "ë‹¨ì–´" and content_data.get('pronunciation'):
                                doc_parts.append(f"ë°œìŒ: {content_data['pronunciation']}")
                                doc_parts.append(f"í’ˆì‚¬: {content_data['part_of_speech']}")

                            if content_data['example_sentence']:
                                doc_parts.append(f"ì˜ˆë¬¸: {content_data['example_sentence']}")
                            if content_data['tags']:
                                doc_parts.append(f"íƒœê·¸: {', '.join(content_data['tags'])}")
                            if content_data['hasImage']:
                                doc_parts.append(f"ì´ë¯¸ì§€: {len(content_data['images'])}ê°œ ì²¨ë¶€")

                            full_document = '\n'.join(doc_parts)

                            title_text = content_data['content_text'] or content_data['translation'] or f"{content_data['language']} {content_data['content_type']}"
                            desc_text = f"{content_data['content_text']} - {content_data['translation']}"

                            image_url = ""
                            image_urls = ""
                            local_image_path = ""

                            if content_data['hasImage'] and content_data['images']:
                                first_image = content_data['images'][0]
                                image_url = first_image.get('public_url') or first_image.get('local_path', '')

                                all_urls = []
                                for img in content_data['images']:
                                    url = img.get('public_url') or img.get('local_path', '')
                                    if url:
                                        all_urls.append(url)
                                image_urls = ', '.join(all_urls)

                                local_image_path = first_image.get('local_path', '')

                            metadata = {
                                'title': title_text[:100],
                                'description': desc_text[:500],
                                'language': content_data['language'],
                                'content_type': content_data['content_type'],
                                'difficulty': content_data['difficulty'],
                                'tags': ', '.join(content_data['tags']),
                                'has_audio': content_data['has_audio'],
                                'audio_url': content_data['audio_url'],
                                'createdBy': content_data['createdBy'],
                                'createdAt': content_data['created_at'],
                                'hasImage': content_data['hasImage'],
                                'imageUrl': image_url,
                                'imageUrls': image_urls,
                                'localImagePath': local_image_path,
                                'imageCount': len(content_data['images']) if content_data['images'] else 0,
                                'type': 'lingumo_content'
                            }

                            if content_type == "ë‹¨ì–´":
                                metadata['pronunciation'] = content_data.get('pronunciation', '')
                                metadata['part_of_speech'] = content_data.get('part_of_speech', '')

                            collection.add(
                                ids=[content_data['id']],
                                documents=[full_document],
                                metadatas=[metadata]
                            )

                            st.success(f"[SUCCESS] ChromaDB ì €ì¥ ì™„ë£Œ!")
                            st.success(f"[SUCCESS] ë¬¸ì„œ ID: {content_data['id']}")

                            # === Step 4: Firebase Save ===
                            st.subheader("[STEP 4] Firebase ì €ì¥")

                            try:
                                from firebase_service import firebase_service

                                firebase_data = {
                                    'id': content_data['id'],
                                    'type': 'lingumo_content',
                                    'content_type': content_data['content_type'],
                                    'language': content_data['language'],
                                    'content_text': content_data['content_text'],
                                    'translation': content_data['translation'],
                                    'difficulty': content_data['difficulty'],
                                    'example_sentence': content_data['example_sentence'],
                                    'tags': content_data['tags'],
                                    'createdAt': content_data['created_at'],
                                    'createdBy': content_data['createdBy'],
                                    'hasImage': content_data['hasImage'],
                                    'images': content_data['images'],
                                    'similarity_check': {
                                        'max_similarity': max_similarity,
                                        'is_duplicate': is_duplicate
                                    }
                                }

                                # Add audio to Firebase
                                firebase_data['has_audio'] = content_data['has_audio']
                                firebase_data['audio_url'] = content_data['audio_url']

                                if content_type == "ë‹¨ì–´":
                                    firebase_data['pronunciation'] = content_data.get('pronunciation', '')
                                    firebase_data['part_of_speech'] = content_data.get('part_of_speech', '')

                                upload_result = firebase_service.add_lingumo_content(firebase_data)

                                if upload_result.get('success'):
                                    st.success(f"[SUCCESS] Firebase ì €ì¥ ì™„ë£Œ!")
                                    st.success(f"[SUCCESS] ë¬¸ì„œ ID: {upload_result.get('id', 'N/A')}")
                                else:
                                    st.warning(f"[WARNING] Firebase ì €ì¥ ì‹¤íŒ¨: {upload_result.get('message', 'Unknown error')}")

                            except Exception as e:
                                st.warning(f"[WARNING] Firebase ì €ì¥ ì‹¤íŒ¨: {e}")
                                import traceback
                                st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")

                            st.balloons()
                            st.success("[COMPLETE] ì–¸ì–´ í•™ìŠµ ì½˜í…ì¸  ì €ì¥ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

                            # Clean up session state
                            if 'lingumo_compressed_images' in st.session_state:
                                del st.session_state.lingumo_compressed_images
                            if 'lingumo_audio_file' in st.session_state:
                                del st.session_state.lingumo_audio_file

                        except Exception as e:
                            st.error(f"[ERROR] ì €ì¥ ì‹¤íŒ¨: {e}")
                            import traceback
                            st.error(f"[ERROR] ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
                else:
                    st.info("[INFO] ì¤‘ë³µìœ¼ë¡œ ì¸í•´ ì €ì¥ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    lingumo_content_input_form()
