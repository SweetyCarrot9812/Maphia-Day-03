"""
Manual Concept Input Form - Simplified Version without AI Analysis
"""
import streamlit as st
import uuid
from datetime import datetime


def get_image_library():
    """Fetch all images from ChromaDB collections"""
    try:
        from rag_engine_multi_domain import multi_domain_rag_engine

        all_images = []
        collections = ['nursing_questions', 'medical_problems', 'fitness_concepts', 'medical_concepts']

        for coll_name in collections:
            try:
                collection = multi_domain_rag_engine.chroma_client.get_collection(coll_name)
                results = collection.get(
                    where={"hasImage": True},
                    include=['metadatas']
                )

                if results and results.get('metadatas'):
                    for metadata in results['metadatas']:
                        if metadata.get('imageUrl') or metadata.get('imageUrls'):
                            image_urls = metadata.get('imageUrls', '').split(', ') if metadata.get('imageUrls') else [metadata.get('imageUrl', '')]

                            for url in image_urls:
                                if url:
                                    all_images.append({
                                        'url': url,
                                        'title': metadata.get('title', '')[:100],
                                        'subject': metadata.get('subject', ''),
                                        'field': metadata.get('field', ''),
                                        'collection': coll_name,
                                        'created_at': metadata.get('createdAt', '')
                                    })
            except:
                continue

        return all_images
    except Exception as e:
        st.warning(f"[WARNING] ì´ë¯¸ì§€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”© ì‹¤íŒ¨: {e}")
        return []


def handle_image_upload():
    """Handle image upload with automatic compression"""
    st.subheader("[IMAGE] ì´ë¯¸ì§€ ê´€ë¦¬")

    # Image source selection
    image_source = st.radio(
        "ì´ë¯¸ì§€ ì„ íƒ ë°©ì‹:",
        ["ğŸ“ ê¸°ì¡´ ì´ë¯¸ì§€ ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ì„ íƒ", "ğŸ“¤ ìƒˆ ì´ë¯¸ì§€ ì—…ë¡œë“œ"],
        horizontal=True,
        key="concept_image_source"
    )

    if image_source == "ğŸ“ ê¸°ì¡´ ì´ë¯¸ì§€ ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ì„ íƒ":
        st.info("[LIBRARY] ê¸°ì¡´ì— ì—…ë¡œë“œëœ ì´ë¯¸ì§€ë¥¼ ê²€ìƒ‰í•˜ê³  ì„ íƒí•˜ì„¸ìš”")

        # Get all images from library
        with st.spinner("[LOADING] ì´ë¯¸ì§€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”© ì¤‘..."):
            image_library = get_image_library()

        if not image_library:
            st.warning("[EMPTY] ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ìƒˆ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
            return []

        # Search and filter
        col1, col2 = st.columns([2, 1])
        with col1:
            search_query = st.text_input(
                "ê²€ìƒ‰ì–´",
                placeholder="ì œëª©, ê³¼ëª©, ë¶„ì•¼ë¡œ ê²€ìƒ‰...",
                key="concept_library_search"
            )
        with col2:
            filter_field = st.selectbox(
                "ë¶„ì•¼ í•„í„°",
                ["ì „ì²´", "ê°„í˜¸", "ì˜í•™", "fitness"],
                key="concept_library_filter"
            )

        # Filter images based on search
        filtered_images = image_library
        if search_query:
            filtered_images = [
                img for img in filtered_images
                if search_query.lower() in img['title'].lower() or
                   search_query.lower() in img['subject'].lower()
            ]

        if filter_field != "ì „ì²´":
            filtered_images = [img for img in filtered_images if img['field'] == filter_field]

        st.info(f"[RESULTS] {len(filtered_images)}ê°œ ì´ë¯¸ì§€ ë°œê²¬")

        if filtered_images:
            # Display images in grid with checkboxes
            selected_images = []

            # Create grid (3 columns)
            num_cols = 3
            for i in range(0, len(filtered_images[:12]), num_cols):  # Show max 12
                cols = st.columns(num_cols)
                for col_idx, img_data in enumerate(filtered_images[i:i+num_cols]):
                    with cols[col_idx]:
                        try:
                            st.image(img_data['url'], width=150, use_container_width=True)
                        except:
                            st.write("ğŸ–¼ï¸ [ì´ë¯¸ì§€]")

                        selected = st.checkbox(
                            f"{img_data['subject']} - {img_data['title'][:30]}...",
                            key=f"select_concept_library_img_{i+col_idx}"
                        )

                        if selected:
                            selected_images.append(img_data)

            if len(filtered_images) > 12:
                st.info(f"[MORE] +{len(filtered_images) - 12}ê°œ ì´ë¯¸ì§€ê°€ ë” ìˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ì–´ë¡œ ì¢í˜€ë³´ì„¸ìš”.")

            # Store selected images in session state
            if selected_images:
                st.success(f"[SELECTED] {len(selected_images)}ê°œ ì´ë¯¸ì§€ ì„ íƒë¨")
                # Convert to compressed image format for compatibility
                compressed_images = []
                for img in selected_images:
                    compressed_images.append({
                        'original_name': img['title'],
                        'compressed_bytes': None,  # Already uploaded
                        'file_ext': 'webp',
                        'original_size': 0,
                        'compressed_size': 0,
                        'compression_ratio': 0,
                        'from_library': True,
                        'public_url': img['url']
                    })
                st.session_state.compressed_images = compressed_images
                return compressed_images

        return []

    else:  # ìƒˆ ì´ë¯¸ì§€ ì—…ë¡œë“œ
        uploaded_images = st.file_uploader(
            "ê°œë… ê´€ë ¨ ì´ë¯¸ì§€ (ì—¬ëŸ¬ ê°œ ì„ íƒ ê°€ëŠ¥)",
            type=['png', 'jpg', 'jpeg', 'webp'],
            accept_multiple_files=True,
            help="ê°œë…ê³¼ ê´€ë ¨ëœ ì˜ë£Œ ì´ë¯¸ì§€, ë„ì‹, ì°¨íŠ¸ ë“±ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (PNG, JPG, JPEG, WebP ì§€ì›)",
            key="concept_images"
        )

    processed_images = []

    if uploaded_images:
        from image_utils import image_processor
        import hashlib

        st.success(f"[AUTO] {len(uploaded_images)}ê°œ ì´ë¯¸ì§€ ìë™ ì••ì¶• ì¤‘...")

        # Auto-process images immediately
        with st.spinner("[PROCESSING] ì´ë¯¸ì§€ ì••ì¶• ë° ì¤‘ë³µ ê²€ì‚¬ ì¤‘..."):
            # Compress images only (no Firebase upload yet)
            compressed_images = []

            for idx, uploaded_file in enumerate(uploaded_images):
                # Generate hash for duplicate detection
                image_bytes = uploaded_file.getvalue()
                image_hash = hashlib.sha256(image_bytes).hexdigest()

                # Compress image
                compressed_bytes, file_ext = image_processor.compress_image(uploaded_file)

                if compressed_bytes:
                    # Calculate compression info
                    original_size = len(uploaded_file.getvalue())
                    compressed_size = len(compressed_bytes)
                    compression_ratio = (1 - compressed_size / original_size) * 100

                    # Store compressed data in memory (no Firebase upload yet)
                    compressed_images.append({
                        'original_name': uploaded_file.name,
                        'compressed_bytes': compressed_bytes,
                        'file_ext': file_ext,
                        'original_size': original_size,
                        'compressed_size': compressed_size,
                        'compression_ratio': compression_ratio,
                        'image_hash': image_hash
                    })

        if compressed_images:
            st.success(f"[SUCCESS] {len(compressed_images)}ê°œ ì´ë¯¸ì§€ ì••ì¶• ì™„ë£Œ!")

            # Show preview
            cols = st.columns(min(len(compressed_images), 3))
            for idx, img_data in enumerate(compressed_images[:3]):
                with cols[idx % 3]:
                    st.image(img_data['compressed_bytes'],
                            caption=f"{img_data['original_name']}\nì••ì¶•ë¥ : {img_data['compression_ratio']:.1f}%",
                            width=150)

            if len(compressed_images) > 3:
                st.info(f"[INFO] ì¶”ê°€ {len(compressed_images)-3}ê°œ ì´ë¯¸ì§€")

            # Store in session state for later Firebase upload
            st.session_state.compressed_images = compressed_images
            st.info("[INFO] ì´ë¯¸ì§€ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. ê°œë… ì •ë³´ë¥¼ ì…ë ¥í•˜ê³  [SAVE] ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ì €ì¥ë©ë‹ˆë‹¤.")
        else:
            st.error("[ERROR] ì´ë¯¸ì§€ ì••ì¶•ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")

    # Check if there are compressed images in session state
    if 'compressed_images' in st.session_state and not uploaded_images:
        compressed_images = st.session_state.compressed_images
        st.info(f"[READY] {len(compressed_images)}ê°œ ì••ì¶•ëœ ì´ë¯¸ì§€ê°€ ì €ì¥ ëŒ€ê¸° ì¤‘ì…ë‹ˆë‹¤")
        processed_images = compressed_images

    return st.session_state.get('compressed_images', [])


def concept_manual_input_form():
    """Manual form for inputting medical concepts without AI analysis"""
    st.subheader("[MANUAL] ì˜í•™ ê°œë… ìˆ˜ë™ ì…ë ¥")

    # Handle image upload outside of form
    handle_image_upload()

    st.divider()

    with st.form("concept_manual_form"):

        # Manual input fields based on user requirements
        st.subheader("[INPUT] ê°œë… ì •ë³´ ì§ì ‘ ì…ë ¥")

        col1, col2 = st.columns(2)

        with col1:
            concept_text = st.text_area(
                "ê°œë… ì›ë¬¸",
                height=150,
                help="ê°œë…ì— ëŒ€í•œ ìƒì„¸í•œ ì„¤ëª…ì„ ì…ë ¥í•˜ì„¸ìš” (ì„ íƒì‚¬í•­)",
                key="concept_original_text"
            )

            keywords = st.text_input(
                "keywords",
                help="í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ì…ë ¥ (ì˜ˆ: ë¬´ê· ìˆ , ê°ì—¼ê´€ë¦¬, ìˆ˜ìˆ )",
                key="concept_keywords"
            )


            related_concepts = st.text_input(
                "related_concepts",
                help="ì—°ê´€ ê°œë…ì„ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ì…ë ¥ (ì„ íƒì‚¬í•­)",
                key="concept_related_concepts"
            )

        with col2:
            concepts = st.text_input(
                "concepts",
                help="ê´€ë ¨ ê°œë… ëª©ë¡ì„ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ì…ë ¥ (ì„ íƒì‚¬í•­)",
                key="concept_concepts"
            )

            tags = st.text_input(
                "tags",
                help="íƒœê·¸ë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ì…ë ¥ (ì„ íƒì‚¬í•­)",
                key="concept_tags"
            )

            category = st.selectbox(
                "category *",
                options=["ê°„í˜¸", "ì˜í•™", "ê³µí†µ", "ê¸°íƒ€"],
                help="ê°œë…ì´ ì†í•˜ëŠ” ë¶„ì•¼ë¥¼ ì„ íƒí•˜ì„¸ìš”",
                key="concept_category"
            )

        # Duplicate check settings
        duplicate_threshold = st.slider(
            "ì¤‘ë³µ ìœ ì‚¬ë„ ì„ê³„ê°’",
            min_value=0.70,
            max_value=0.99,
            value=0.92,
            step=0.01,
            help="ì´ ê°’ ì´ìƒì˜ ìœ ì‚¬ë„ë¥¼ ê°€ì§„ ê°œë…ì´ ìˆìœ¼ë©´ ì¤‘ë³µìœ¼ë¡œ íŒë‹¨ (ê¶Œì¥: 0.92-0.95)",
            key="concept_duplicate_threshold"
        )

        st.info("""
        **ìœ ì‚¬ë„ ê¸°ì¤€:**
        - 0.95+ : ê±°ì˜ ë™ì¼
        - 0.90-0.95 : ë§¤ìš° ìœ ì‚¬ (ê¶Œì¥ ì¤‘ë³µ ê¸°ì¤€)
        - 0.85-0.90 : ìœ ì‚¬í•œ ì£¼ì œ
        - 0.85 ë¯¸ë§Œ : ë‹¤ë¥¸ ê°œë…
        """)

        submitted = st.form_submit_button("[SAVE] ê°œë… ì €ì¥")

        if submitted:
            # Get compressed images from session state
            compressed_images = st.session_state.get('compressed_images', [])

            # Upload compressed images to Firebase Storage now
            processed_images = []
            if compressed_images:
                from image_utils import image_processor

                # Separate library images from new uploads
                library_images = [img for img in compressed_images if img.get('from_library')]
                new_uploads = [img for img in compressed_images if not img.get('from_library')]

                if library_images:
                    st.info(f"[REUSE] {len(library_images)}ê°œ ì´ë¯¸ì§€ë¥¼ ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ì¬ì‚¬ìš©")
                    for img_data in library_images:
                        processed_images.append({
                            'original_name': img_data['original_name'],
                            'file_name': img_data['original_name'],
                            'public_url': img_data['public_url'],
                            'local_path': None,
                            'content_type': 'image/webp',
                            'original_size': 0,
                            'compressed_size': 0,
                            'compression_ratio': 0,
                            'uploaded_at': datetime.now().isoformat(),
                            'from_library': True
                        })

                if new_uploads:
                    st.info(f"[UPLOAD] {len(new_uploads)}ê°œ ìƒˆ ì´ë¯¸ì§€ë¥¼ Firebase Storageì— ì—…ë¡œë“œ ì¤‘...")

                    for img_data in new_uploads:
                        # Generate unique filename with hash
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        image_hash_short = img_data.get('image_hash', str(uuid.uuid4()))[:8]
                        file_name = f"concept_{timestamp}_{image_hash_short}.{img_data['file_ext']}"

                        # Save to local first
                        local_path = image_processor.save_to_local(img_data['compressed_bytes'], file_name)

                        # Upload to Firebase Storage
                        public_url = image_processor.upload_to_firebase_storage(
                            img_data['compressed_bytes'],
                            file_name,
                            'image/webp'
                        )

                        processed_images.append({
                            'original_name': img_data['original_name'],
                            'file_name': file_name,
                            'public_url': public_url if public_url else None,
                            'local_path': local_path if local_path else None,
                            'content_type': 'image/webp',
                            'original_size': img_data['original_size'],
                            'compressed_size': img_data['compressed_size'],
                            'compression_ratio': img_data['compression_ratio'],
                            'uploaded_at': datetime.now().isoformat(),
                            'image_hash': img_data.get('image_hash')
                        })

                if processed_images:
                    st.success(f"[SUCCESS] ì´ {len(processed_images)}ê°œ ì´ë¯¸ì§€ ì¤€ë¹„ ì™„ë£Œ! (ì¬ì‚¬ìš©: {len(library_images)}, ì‹ ê·œ: {len(new_uploads)})")

            # Validate required fields - allow saving with just images or keywords
            missing_fields = []
            has_content = bool(concept_text.strip()) or bool(keywords.strip()) or bool(processed_images)

            if not has_content:
                st.error("[ERROR] ê°œë… ì›ë¬¸, keywords, ë˜ëŠ” ì´ë¯¸ì§€ ì¤‘ í•˜ë‚˜ëŠ” ë°˜ë“œì‹œ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤")
            else:
                # Create concept data structure
                concept_data = {
                    'id': str(uuid.uuid4()),
                    'type': 'concept',
                    'original_text': concept_text.strip() if concept_text else '',
                    'keywords': [k.strip() for k in keywords.split(',') if k.strip()] if keywords else [],
                    'related_concepts': [r.strip() for r in related_concepts.split(',') if r.strip()] if related_concepts else [],
                    'concepts': [c.strip() for c in concepts.split(',') if c.strip()] if concepts else [],
                    'tags': [t.strip() for t in tags.split(',') if t.strip()] if tags else [],
                    'category': category,
                    'created_at': datetime.now().isoformat(),
                    'hasImage': bool(processed_images),
                    'images': processed_images if processed_images else [],
                    'createdBy': 'streamlit_user'
                }

                # === Step 1: Duplicate Check ===
                st.header("[STEP 1] ì¤‘ë³µ ê²€ì‚¬")

                with st.spinner("[SEARCH] ìœ ì‚¬ ê°œë… ê²€ìƒ‰ ì¤‘..."):
                    try:
                        from rag_engine_multi_domain import multi_domain_rag_engine
                        from rag_engine import rag_engine

                        # Select collection based on category
                        category_lower = concept_data['category'].lower()
                        if category_lower in ['ê°„í˜¸', 'ì˜í•™', 'ê³µí†µ', 'ê¸°íƒ€']:
                            collection_name = 'medical_concepts'
                        elif category_lower in ['ìš´ë™', 'ì˜ì–‘', 'ê±´ê°•']:
                            collection_name = 'fitness_concepts'
                        else:
                            collection_name = 'medical_concepts'  # Default

                        collection = multi_domain_rag_engine.chroma_client.get_or_create_collection(collection_name)

                        # Search for similar concepts
                        search_parts = []
                        if concept_text.strip():
                            search_parts.append(concept_text)
                        if concept_data['keywords']:
                            search_parts.append(' '.join(concept_data['keywords']))
                        search_text = ' '.join(search_parts) if search_parts else "concept"
                        search_embedding = rag_engine.generate_embedding(search_text)
                        results = collection.query(
                            query_embeddings=[search_embedding],
                            n_results=5,
                            where={"type": "concept"}
                        )

                        max_similarity = 0.0
                        is_duplicate = False

                        if results.get('distances') and results['distances'][0]:
                            distances = results['distances'][0]
                            # ChromaDB uses L2 distance: smaller = more similar
                            # Convert to similarity score: 1/(1+distance)
                            similarities = [1 / (1 + d) for d in distances]
                            max_similarity = max(similarities) if similarities else 0.0

                            if max_similarity >= duplicate_threshold:
                                is_duplicate = True
                                st.warning(f"[DUPLICATE] ì¤‘ë³µ ê°€ëŠ¥ì„± ë†’ìŒ (ìµœëŒ€ ìœ ì‚¬ë„: {max_similarity:.3f})")
                            else:
                                st.success(f"[UNIQUE] ìƒˆë¡œìš´ ê°œë… (ìµœëŒ€ ìœ ì‚¬ë„: {max_similarity:.3f})")

                            # Show top results
                            if results.get('documents') and results['documents'][0]:
                                with st.expander("[DETAILS] ìœ ì‚¬ ê°œë… ê²°ê³¼", expanded=False):
                                    for i, (doc, sim) in enumerate(zip(results['documents'][0][:3], similarities[:3])):
                                        st.write(f"**{i+1}ìœ„** (ìœ ì‚¬ë„: {sim:.3f})")
                                        st.write(doc[:200] + "..." if len(doc) > 200 else doc)
                                        st.divider()
                        else:
                            st.info("[INFO] ì²« ë²ˆì§¸ ê°œë…ì…ë‹ˆë‹¤.")

                    except Exception as e:
                        st.error(f"[ERROR] ì¤‘ë³µ ê²€ì‚¬ ì‹¤íŒ¨: {e}")
                        max_similarity = 0.0
                        is_duplicate = False

                # === Step 2: Direct Embedding & Save ===
                if not is_duplicate or st.checkbox("ì¤‘ë³µì´ì–´ë„ ì €ì¥í•˜ê¸°"):
                    st.header("[STEP 2] ì„ë² ë”© ë° ì €ì¥")

                    with st.spinner("[SAVE] ë²¡í„° ì„ë² ë”© ë° ì €ì¥ ì¤‘..."):
                        try:
                            # Select correct collection for saving
                            from rag_engine_multi_domain import multi_domain_rag_engine
                            category_lower = concept_data['category'].lower()
                            if category_lower in ['ê°„í˜¸', 'ì˜í•™', 'ê³µí†µ', 'ê¸°íƒ€']:
                                save_collection_name = 'medical_concepts'
                            elif category_lower in ['ìš´ë™', 'ì˜ì–‘', 'ê±´ê°•']:
                                save_collection_name = 'fitness_concepts'
                            else:
                                save_collection_name = 'medical_concepts'  # Default

                            save_collection = multi_domain_rag_engine.chroma_client.get_or_create_collection(save_collection_name)

                            # Create full document for embedding
                            doc_parts = []
                            if concept_data['original_text']:
                                doc_parts.append(f"ê°œë…: {concept_data['original_text']}")
                            if concept_data['keywords']:
                                doc_parts.append(f"í‚¤ì›Œë“œ: {', '.join(concept_data['keywords'])}")
                            if concept_data['related_concepts']:
                                doc_parts.append(f"ì—°ê´€ê°œë…: {', '.join(concept_data['related_concepts'])}")
                            doc_parts.append(f"ë¶„ì•¼: {concept_data['category']}")
                            if concept_data['tags']:
                                doc_parts.append(f"íƒœê·¸: {', '.join(concept_data['tags'])}")
                            if concept_data['hasImage']:
                                doc_parts.append(f"ì´ë¯¸ì§€: {len(concept_data['images'])}ê°œ ì²¨ë¶€")

                            full_document = '\n'.join(doc_parts) if doc_parts else f"ë¶„ì•¼: {concept_data['category']}"

                            # Prepare metadata
                            title_text = concept_data['original_text'] or ', '.join(concept_data['keywords']) or f"{concept_data['category']} ê°œë…"
                            desc_text = concept_data['original_text'] or ', '.join(concept_data['keywords']) or f"{concept_data['category']} ë¶„ì•¼ ê°œë…"

                            # Extract image URLs for metadata
                            image_url = ""
                            image_urls = ""
                            local_image_path = ""

                            if concept_data['hasImage'] and concept_data['images']:
                                # Get first image URL (Firebase or local)
                                first_image = concept_data['images'][0]
                                image_url = first_image.get('public_url') or first_image.get('local_path', '')

                                # Get all image URLs (comma-separated)
                                all_urls = []
                                for img in concept_data['images']:
                                    url = img.get('public_url') or img.get('local_path', '')
                                    if url:
                                        all_urls.append(url)
                                image_urls = ', '.join(all_urls)

                                # Get local path for first image
                                local_image_path = first_image.get('local_path', '')

                            metadata = {
                                'title': title_text[:100],
                                'description': desc_text[:500],
                                'category': concept_data['category'],
                                'keywords': ', '.join(concept_data['keywords']),
                                'tags': ', '.join(concept_data['tags']),
                                'createdBy': concept_data['createdBy'],
                                'createdAt': concept_data['created_at'],
                                'hasImage': concept_data['hasImage'],
                                'imageUrl': image_url,
                                'imageUrls': image_urls,
                                'localImagePath': local_image_path,
                                'imageCount': len(concept_data['images']) if concept_data['images'] else 0,
                                'type': 'concept'
                            }

                            # Generate 768d embedding explicitly with gemini-embedding-001
                            import google.generativeai as genai
                            result = genai.embed_content(
                                model="gemini-embedding-001",
                                content=full_document,
                                output_dimensionality=768
                            )
                            embedding_768d = result['embedding'] if isinstance(result, dict) else result

                            # Save to ChromaDB with explicit 768d embedding
                            save_collection.add(
                                ids=[concept_data['id']],
                                documents=[full_document],
                                embeddings=[embedding_768d],
                                metadatas=[metadata]
                            )

                            st.success(f"[COLLECTION] {save_collection_name}ì— ì €ì¥ë¨")

                            st.success(f"[SUCCESS] ChromaDB ì €ì¥ ì™„ë£Œ!")
                            st.success(f"[SUCCESS] ë¬¸ì„œ ID: {concept_data['id']}")

                            # === Step 3: Firebase Save ===
                            st.subheader("[STEP 3] Firebase ì €ì¥")

                            try:
                                from firebase_service import firebase_service

                                firebase_data = {
                                    'id': concept_data['id'],
                                    'original_text': concept_data['original_text'],
                                    'keywords': concept_data['keywords'],
                                    'related_concepts': concept_data['related_concepts'],
                                    'concepts': concept_data['concepts'],
                                    'tags': concept_data['tags'],
                                    'category': concept_data['category'],
                                    'createdAt': concept_data['created_at'],
                                    'createdBy': concept_data['createdBy'],
                                    'hasImage': concept_data['hasImage'],
                                    'images': concept_data['images'],
                                    'type': 'concept',
                                    'similarity_check': {
                                        'max_similarity': max_similarity,
                                        'is_duplicate': is_duplicate
                                    }
                                }

                                upload_result = firebase_service.add_concept(firebase_data)

                                if upload_result.get('success'):
                                    st.success(f"[SUCCESS] Firebase ì €ì¥ ì™„ë£Œ!")
                                    st.success(f"[SUCCESS] ë¬¸ì„œ ID: {upload_result.get('id', 'N/A')}")
                                else:
                                    st.warning(f"[WARNING] Firebase ì €ì¥ ì‹¤íŒ¨: {upload_result.get('message', 'Unknown error')}")

                            except Exception as e:
                                st.warning(f"[WARNING] Firebase ì €ì¥ ì‹¤íŒ¨: {e}")

                            # Final success message
                            st.balloons()
                            st.success("[COMPLETE] ê°œë… ì €ì¥ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

                            # Clear session state after successful save
                            if 'compressed_images' in st.session_state:
                                del st.session_state.compressed_images

                        except Exception as e:
                            st.error(f"[ERROR] ì €ì¥ ì‹¤íŒ¨: {e}")
                            import traceback
                            st.error(f"[ERROR] ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
                else:
                    st.info("[INFO] ì¤‘ë³µìœ¼ë¡œ ì¸í•´ ì €ì¥ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    concept_manual_input_form()
